{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"E:\\DATA SCIENCE\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://in.indeed.com/jobs?q=Data+Scientist&l=Pune%2C+Maharashtra&radius=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=[]\n",
    "companies=[]\n",
    "locations=[]\n",
    "Hir=[]\n",
    "links =[]\n",
    "reviews=[]\n",
    "salaries = []\n",
    "descriptions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,7):\n",
    "    \n",
    "    jobs = driver.find_elements_by_xpath('//div[contains(@class,\"clickcard\")]')\n",
    "    \n",
    "    for job in jobs:\n",
    "       \n",
    "\n",
    "        try:\n",
    "            review = job.find_element_by_xpath('.//span[@class=\"ratingsContent\"]').text\n",
    "        except:\n",
    "            review = \"None\"\n",
    "        reviews.append(review)\n",
    " \n",
    "        try:\n",
    "            salary = job.find_element_by_xpath('.//span[@class=\"salaryText\"]').text\n",
    "        except:\n",
    "            salary = \"None\"\n",
    "      \n",
    "        salaries.append(salary)\n",
    "        \n",
    "        try:\n",
    "            hir=job.find_element_by_xpath('.//td[@class=\"jobCardShelfItem urgentlyHiring\"]').text\n",
    "        except:\n",
    "            hir=\"none\"\n",
    "            \n",
    "        Hir.append(hir)\n",
    "        \n",
    "        try:\n",
    "            location = job.find_element_by_xpath('.//span[contains(@class,\"location\")]').text\n",
    "        except:\n",
    "            location = \"None\"\n",
    "        \n",
    "        locations.append(location)\n",
    "        \n",
    "        try:\n",
    "            title  = job.find_element_by_xpath('.//h2[@class=\"title\"]//a').text\n",
    "        except:\n",
    "            title = job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"title\")\n",
    "        titles.append(title)\n",
    "        links.append(job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"href\"))\n",
    "        companies.append(job.find_element_by_xpath('.//span[@class=\"company\"]').text)\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('//a[@aria-label={}]//span[@class=\"pn\"]'.format(i+2))\n",
    "        next_page.click()\n",
    "\n",
    "    except:\n",
    "        next_page = driver.find_element_by_xpath('//a[@aria-label=\"Next\"]//span[@class=\"np\"]')\n",
    "        next_page.click()\n",
    "        \n",
    "    \n",
    "    print(\"Page: {}\".format(str(i+2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹8,00,000 a year',\n",
       " 'None',\n",
       " '₹15,000 a month',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹6,00,000 - ₹22,00,000 a year',\n",
       " 'None',\n",
       " '₹5,00,000 a year',\n",
       " 'None',\n",
       " '₹5,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹12,00,000 a year',\n",
       " 'None',\n",
       " '₹2,40,000 - ₹3,60,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹7,00,000 - ₹12,00,000 a year',\n",
       " 'None',\n",
       " '₹2,40,000 - ₹4,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 a year',\n",
       " 'None',\n",
       " '₹5,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹12,00,000 a year',\n",
       " 'None',\n",
       " '₹2,40,000 - ₹3,60,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹7,00,000 - ₹12,00,000 a year',\n",
       " 'None',\n",
       " '₹2,40,000 - ₹4,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹10,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹10,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹10,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹10,00,000 a year',\n",
       " 'None']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions=[]\n",
    "for link in links:\n",
    "    \n",
    "    driver.get(link)\n",
    "    jd = driver.find_element_by_xpath('//div[@id=\"jobDescriptionText\"]').text\n",
    "    descriptions.append(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are looking for Data Scientists to join our Data Services Team in India. If you are a data scientist and looking for driving business strategy through predictive and prescriptive analytics, then lets talk! Send your resume to careers@aretove.com\\n\\nResponsibilities\\nWork with stakeholders from products, merchandising, operations, customer retention to identify opportunities for leveraging in-house and third party data to drive decisions.\\nProcessing, cleansing, and verifying the integrity of various data sets to drive insights on customer, marketing, operations, products and other business strategies.\\nBuild predictive models to enhance customer experiences & retention, spend optimization, campaigns, supply chain and other business outcomes.\\nDevelop visualization/ presentations to clearly articulate and present data insights to various stakeholders\\nDevelop processes and tools to monitor, analyze and report model performance and data accuracy.\\nSkills/Experience\\nBachelors/Masters Degree in computer science, math, engineering, analytics, or related field and five (5) years or more experience\\n2 -5 years of experience using statistical computer languages (R, Python, SQL) to draw insights and foresights using large and heterogeneous data sets\\nExperience with machine learning techniques (clustering, supervised learning and tree based, etc.) under real-word problem statements.\\nExperience on statistical techniques and concepts (regression, properties of distributions, statistical tests, etc.).\\nExperience using business intelligence/visualization tools (Tableau/ Looker/ Power BI/Others)\\nExposure to cloud-based machine learning platforms such as Spark MLlib or Azure ML etc would be an added advantage.\\nAbility to work independently, deal well with ambiguous and undefined problems.\\nAbility to work in a fast-paced and agile environment.',\n",
       " 'Manager - Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nData Analysis and Modelization\\n· The need is understood and formalized in a descriptive datasheet or Cahier des Charges\\n· The methods are clearly selected by their theoretical bases, advantages and drawbacks\\n· The data, its relevance and its source are described and prioritized\\n· The data are prepared (cleansed, enriched, mapped,agregated, …) and the approach is documented.\\n· The analysis is implemented and documented\\n· The results of the analysis or the model are presented to the customers in the form of presentation (PPT or other) indicating the performances and the limits. The source code is delivered and explained if necessary.\\nMarket Watch\\n· Benchmarks other companies and stays aware of the latest trends\\nEnsures the sharing of good practices (internally and externally)',\n",
       " 'AppZen is the leader in AI software for finance teams. Over 1,800 global enterprises use AppZen to automate manual finance processes, reduce expenditures, and gain real-time insights into their business spend trends. Our patented software technology delivers AI deep learning, semantic analysis, and Star Match™, the only automated spend validation that processes intelligence from thousands of data sources, documents, and images to understand financial transactions and make decisions based on finance policies. AppZen is the platform of choice for today’s digital CFO and their teams, including four of the top five banks, four of the top ten media companies, four of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and six of the top ten software providers.\\n\\nWe’ve taken off this year! Since releasing our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor, and have been recognized as one of the fastest-growing technology companies in the market. In 2019 we received $50 million in Series C funding from Lightspeed, Redpoint and other leading venture capital firms.\\n\\nWe are looking for a Data Scientist to come and work on our growing AI stack. You will be working\\nwith a team of highly skilled and motivated data scientists and machine learning engineers. If you\\nare excited about natural language understanding and machine translation, AppZen is the right place\\nfor you to apply and grow your skills.\\nMust-Have:\\nSolid understanding of machine learning fundamentals, and familiarity with standard\\nalgorithms and techniques\\nAbility to analyse a wide variety of data: structured and unstructured, observational and\\nexperimental, to drive system designs and product implementations\\nExpert knowledge of a statistical computing language such as Python. Knowledge of\\nprobability and statistics, including experimental design, predictive modelling, optimization,\\nand causal inference Experience in design and deployment of real-world, large-scale, user-\\nfacing systems\\nEnsure data quality throughout all stages of acquisition and processing, including such areas\\nas data sourcing/collection, ground truth generation, normalization, transformation, cross-\\nlingual alignment/mapping, etc.\\nManage your own process: identify and execute on high impact projects, triage external\\nrequests, and make sure you bring projects to conclusion in time for the results to be useful\\nExcellent written and verbal technical communication skills; communicate proposals and\\nresults in a clear manner backed by data and coupled with actionable conclusions to drive\\nbusiness decisions\\nExperience in developing and productionizing AI/ML models in client facing roles\\nB.E./B.Tech/M.E./M.Tech in Computer Science, Engineering, Statistics, or another relevant\\ntechnical field\\nMust have 1-3 years of industry experience\\nYou are a team player\\nCome as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.',\n",
       " 'Job description\\nResponsibilities for Data Scientist\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\\nDevelop custom data models and algorithms to apply to data sets.\\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\\nDevelop company A/B testing framework and test model quality.\\nCoordinate with different functional teams to implement models and monitor outcomes.\\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\\nQualifications for Data Scientist\\nStrong problem solving skills with an emphasis on product development.\\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nExcellent written and verbal communication skills for coordinating across teams.\\nA drive to learn and master new technologies and techniques.',\n",
       " 'Position - SE/SSE - Python+AI+ML+NLP\\nExperience - 5-15 years\\nWork Timings - 12:30 PM - 09:30 PM\\n\\nPython, Artificial Intelligence, Machine Learning, NLP, NLU, Deep Learning, TensorFlow, Keras, SpaCy, NLTK, Image processing, OpenCV, Tesseract',\n",
       " 'Job Description\\nRole: - Data Scientist\\nLocation: Pune\\nWork Experience of 2-7 years\\n\\nØ Experience in Python & Scrapping using Selenium, Beautiful Soup, and pandas.\\nØ Experience in NLP and NLG using TFIDF, Word2Vec, ELMO, Spacy and BERT & T5.\\nØ Experience in Flask web service and Docker image development.\\nØ Strong problem-solving skills with an emphasis on data transformation.\\nØ Knowledge or experience in RNN, LSTM & CNN.\\nØ Knowledge and experience in statistical and data mining techniques: Regression, Random Forest, Boosting, Trees, ARIMA etc.\\nØ Knowledge in Cloud Services like AWS, Azure.\\nØ Excellent written and verbal communication skills for coordinating across teams.\\nØ Coordinate with different functional teams to implement models and monitor outcomes.\\n\\n2.00-7.00 Years',\n",
       " '5th fastest-growing private company in the Silicon Valley - Series-B funded - EdTech - Computer Networking & AI\\nSecurly, Inc (www.securly.com) was Award by INC 5000 as the 5th fastest-growing private company in the Silicon Valley. Our R&D Engineering team is in Pune, India. Securly is a world-renowned innovator in student safety solutions. We started by building the first cloud-based web filter for schools in 2012 and have continued innovating comprehensive solutions, with AI and machine learning, for student safety - both in school and at home. By pioneering these developments, Securly continues to be a leader in an industry that is continually evolving.\\nIn a few short years, our innovative products and talented people have;\\nEstablished Securly in over 20% of the US market\\nGrown to 11+ products with a presence in EMEA, LATAM, APAC\\nImplemented Securly into 15,000+ schools\\nMonitored more than 5 billion online activities\\nRevolutionized school safety for more than 10 million children\\nSaved the lives of more than 1000+ children\\n\\nSummary\\nAs a Data Scientist/BI Engineer working out of our Pune office and reporting to the Senior Vice President, you will constantly be pushing the boundaries of your role and in the process-you will be redefining what it means to be a \"Business Analyst\".\\nWe will be migrating to a state of the art analytics stack that will being new silos of customer data (product/UI analytics, Ad performance, support analytics, email performance, customer engagement) under your purview. Tools like the ones we are choosing will be the \"norm\" in the Business Intelligence world in the next 3-5 years (many early adopters in Silicon Valley are already moving towards them) and this role will allow you to explore career adjacencies and position yourself for the \"change that is coming\".\\nWhat\\'s in it for you? You will have the opportunity to collaborate with and learn from talented colleagues in our US and India teams. You will have the advantage to work in a very diverse environment that has broader perspectives and deeper ideas.\\nResponsibilities:\\nUse effective text representations to transform natural language into useful features.\\nTrain the developed model and run evaluation experiments.\\nPerform statistical analysis of results and refine models.\\nRemain up-to-date on machine learning research and trends, challenge current best thinking, test theories, evaluate feature concepts and iterate rapidly\\nOwn the full flow of very challenging data problems starting with data discovery/collection/cleaning through the production implementation of resilient models that can perform using noisy real-world data, owning the deliverables and managing the priorities/timelines\\nPosition Requirements\\n4+years experience in a similar role\\nA proven track record of successfully implementing deep learning and machine learning models on real-world structured and unstructured data.\\nSolid fundamentals, knowledge of machine learning / deep learning algorithms, classification, clustering, regression, SVM,CNN, RNN, Bayesian modeling, probability theory , linear algebra, Bayesian statistics, and information retrieval.\\nHands-on experience in NLP tasks such as Sentiment Analysis, Name Entity Recognition, Text Summarization, Intent Detection, Topic Modeling.\\nKnowledge of text representation (e.g. n-grams, bag of words, embeddings etc.),statistics and classification algorithms.\\nFamiliarity with rule-based NLP, including CFG, constituency and dependency parsing, as well as their statistical variants. Experiences using NLTK, spaCy, or Stanford NLP.\\nUnderstanding of Transformers, ELMo, BERT ,OCR is preferred but not required.\\nHands-on experience with Scikit-learn, Tensorflow, Keras, or PyTorch Framework.\\nBachelors Degree, Masters or PhD in Computer Science, Statistics, Applied Math, Engineering with an emphasis on Machine Learning is preferred\\n\\nPreferred Qualifications:\\nSuccess in competitive Machine Learning competitions such as Kaggle Competitions\\nStrong combination of theoretical knowledge and hands-on experience in feature selection, dimensionality reduction, statistical techniques, classification models, machine learning / deep learning algorithms and data visualization.\\nExperience/proficiency in at least one compiled/object oriented programming language e.g. Python\\nExperience in managing and coordinating complex cross-functional software teams and projects\\nHighly motivated team player with an entrepreneurial spirit and strong communication and collaboration skills, self-starter with willingness to learn, master new technologies and clearly communicate results to technical and nontechnical audiences\\nWe are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n\\nAbout Securly\\n2-minute product demo - https://vimeo.com/245108303\\nSecurly\\'s 6 years of student safety disruption - http://bit.ly/Securly_6yr_roadmap\\nSecurly technology & Milestones - http://bit.ly/Securly-Tech-and-Milestones\\nSecurly is the only company offering a unified solution that deploys a unique mix of AI and machine learning in conjunction with expert human analysts on call 24/7 to report bullying and self-harm incidents.\\nHolding many patents and growing rapidly at 969%, Securly serves more than 20% of the primary and secondary student populations across the United States and many global markets. With offices in California, North Carolina, India, UK, and Mexico, Securly offers career opportunities worldwide.\\nOur Mission\\nOur mission is to cultivate a safer digital world for children. We see the internet as a space for learning and exploration and social media as an opportunity to develop emotional intelligence and social competence. The internet brings many benefits to children\\'s development and education but also presents many concerns.\\nOur goal is not to censor the internet but to mitigate the adverse effects on kids. We develop solutions to keep children safe online wherever they are - at school, at home, or out in the world. From tools to help adults create a safer internet to an AI that recognizes signs of bullying and even intuits risks of self-harm, Securly continues to build technology and innovate solutions to support children\\'s online safety and healthy digital lives for children.\\nPre-IPO stock options\\nCompany-sponsored health benefits (Family and Parents are covered)\\n21 days PTO + 10 Holidays\\nFun Company-sponsored events/outings on a Quarterly/Annual basis\\nFree Breakfast every day\\nGame room equipped with X-box, Foosball table, carrom board, Jenga, etc.\\nNewly remodeled Office with beautiful open floor plan\\nOur culture and people value empowerment, continual learning and growth, partnership, and execution\\nRecognized as a Top Places to work',\n",
       " \"About the company:\\nKUKbit Software Lab helps clients manage their cloud environments from initial design through building, deploying, and ongoing management. We apply best practices that are developed over 5+ years in traditional IT and 3+ years as a premier AWS partner to help and ensure that our client's environment is secure, meet compliance requirements and maintain high availability to provide the broadest set of services and security for enterprise-grade apps, across any multi-cloud environment.\\nAbout the internship/job:\\nSelected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data\\nWho can apply:\\nOnly those students or freshers can apply who:\\nare available for full time (in-office) internship\\nhave relevant skills and interests\\ncan start the internship between 10th Dec'20 and 14th Jan'21\\nare available for duration of 6 months\\nhave already graduated or are currently in any year of study\\nFemales willing to start/restart their career may also apply\\nNumber of internships/jobs available: 3\\nCategories: Data Science\",\n",
       " 'Requirements\\nBS/MS degree in Computer science, Maths\\nYou are experienced with data stores such as Mysql, MongoDB, Cassandra, HBase, Hive\\nExperienced with data visualisation tools, such as Tableau, D3.js, GGplot, etc\\nPast experience with Deep Learning/NLP would be an advantage (although not necessary)\\nGood Communication Skills\\nTeam Player\\nWhat We Expect.?\\nYou take pride in your knowledge of design patterns, algorithms and data structures\\nYou are comfortable processing, cleansing, and verifying the integrity of data used for analysis\\nYou understand machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CART, CHAID etc\\nYou understand feature selection, model performance metrics, building and optimizing machine learning models\\nYou are good at doing ad-hoc analysis and presenting results in a clear manner\\nYou are good at creating automated anomaly detection systems and constant performance tracking\\nYou can code comfortably in R & Python (NumPy, sklearn, xgboost)',\n",
       " 'The Company\\n\\nHitachi Vantara, a wholly-owned subsidiary of Hitachi, Ltd., guides our customers from what’s now to what’s next by solving their digital challenges. Working alongside each customer, we apply our unmatched industrial and digital capabilities to their data and applications to benefit both business and society. More than 80% of the Fortune 100 trust Hitachi Vantara to help them develop new revenue streams, unlock competitive advantages, lower costs, enhance customer experiences, and deliver social and environmental value.\\n\\nThe Role\\n\\nWe are seeking Data Scientist\\n\\nResponsibilities\\nRole Overview:\\nExplore large datasets to surface useful trends, signals, and segments.The role drives business and industry solutions focused on Big Data and Advanced Analytics. Domain expertise in Manufacturing/Healthcare/Telecom/Financial Services is a key aspect. The role uses analytics to provide predictive, prescriptive, and decisive insight.\\nJob Description:\\nInteract with customers to understand business objectives and create analytical strategies to help achieve them.\\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\\nProcessing, cleansing, and verifying the integrity of data used for analysis.\\nAnalyze and model structured data using advanced statistical methods.\\nPerform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.\\nAnalyze data using open source packages and commercial/enterprise applications\\nPerform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.\\nSelecting features, building and optimizing classifiers using machine learning techniques.\\nImplement algorithms and software needed to perform analyses.\\nDrive client engagements focused on Big Data and Advanced Business Analytics.\\nDoing ad-hoc analysis and presenting results in a clear manner.\\nCommunicate results and educate others through reports and presentations. Skills Required â€¢ Expertise in Data Mining, Data wrangling, and data munging using one or more of the most commonly used data science tools: R, Python, SAS, SPSS, Weka â€¢ Experience in end-to-end data science and engineering activities.\\nExpertise in client engagement, data science consulting type activities.\\nMust have led a team of data engineers and data scientists in leading data science engagements.\\nExperience with analytics in IT and IoT space is a plus.\\nKnowledge and experience in Hadoop (Map Reduce paradigm) etc.\\nMust be hands-on and must have worked on implementing machine learning and data mining algorithms.\\nPassion for finding meaning in large data sets and identifying actionable results.\\nExcellent communication skills (both written and verbal) and interpersonal skills.\\nExperience working with and transforming large data sets.\\nUnderstanding of business value and how this relates to actionable results.\\nAbility to identify or interpret many inputs and requirements then transforming them into actionable plans.\\nAbility to take vaguely defined data sets and requirements then proactively identify and partner with needed SMEs to provide interpretations tailored to individual client needs.\\nAbility to visualize data results into meaningful workflows including charts and graphs\\nExperience in scripting languages with experience in scripting to integrate software solutions is a plus.\\nAdditional Skills (optional) Scala, Spark, H2O,Mahout, Hive\\nProduct Knowledge: At least 3 of the following: o R, Python (Scikit-learn, numpy, etc), Weka, SAS, SPSS, MATLAB/Octave, Hadoop (Map Reduce programming).\\nAbility to work in a Linux environment, and process large amounts of data in a cloud environment.\\nKnowledge in Search Engine: such as Elastic, Apache Lucene/Solr\\nQualifications\\nBE / B Tech / ME / M Tech\\n\\n\\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.',\n",
       " 'Company Description\\nAutonomIQ is a cloud platform that enables product and IT teams to autonomously test, release and deploy software, thereby increasing velocity of software releases without compromising quality. With pre-built integrations to common web applications and SaaS providers, customers can instantly create test cases, generate test scripts and test data, and execute tests. Using deep-learning and AI algorithms, AutonomIQ detects changes, enables self-healing for test assets and provides advanced diagnostics. In real world situations, AutonomIQ has been shown to provide over ~50% improvement in speed and quality compared to existing tools and techniques.\\n\\nJob Description\\nResponsibilities:\\nDevelop Algorithms in NLP Systems for Intent, Entity detections and contextual understanding\\nWork on solving real world scenarios for user commands and requests, and build scalable systems that solve their problems\\nThink creatively to identify new opportunities and contribute to high quality publications or patents.\\nWork in a highly collaborative environment with teams to deliver systems from prototyping to production level.\\nMust have;\\nHands-on experience on modern NLP Neural Networks e.g. Transformer Models like BERT, RoBERTa, etc to build Intent classification, Named Entity Recognition (NER) and Q&A systems, for both training and inference.\\nExposure to either PyTorch or TensorFlow Deep learning tools and exporting models for inference is preferred.\\nKnowledge of building a robust validation framework for small-sized datasets is a hard requirement.\\n\\nQualifications\\nBE / BTech Only\\n\\nAdditional Information\\nFlexible Working Hours\\nProduct Start Up Culture\\nRemote Work',\n",
       " 'Senior Manager - Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nThe need is understood and formalized in a descriptive datasheet or Cahier des Charges\\nthe methods are clearly selected by their theoretical bases, advantages and disadvantages\\nthe data, its relevance and its source are described and prioritized\\nthe data are aggregated and the approach is documented. (Key or parameter allowing to link the different sources )\\nthe analysis is implemented and documented\\nthe results of the analysis or the model are presented to the customers in the form of presentation (Pt or other) indicating the performances and the limits. The source code is delivered and explained if necessary.\\nthe team has a technical expert who is accessible and available to guide and help others in case of difficulty with an adapted communication. A technical seminar is organized each year\\nthe person in charge of the network Business regularly receives information on the health of the business as well as more or less formalized proposals for improvements',\n",
       " 'Note: Its not work from home internship, If selected candidate must come to office\\nOnly pursuing candidates who are passing out in 2021, 2022 eligible. Experienced candidates need not apply.\\nStipend: Unpaid\\nRoles and Responsibilities\\n1. Create a web application using Python, HTML, CSS, Bootstrap\\n2. Analyze data sets, finding patterns/trends and forecasting\\n3. Run machine learning algorithms, predict and classify data\\n4. Working on data science algorithms and AI concepts\\n5. Report results and compare them with real-time data\\n6. Work on solving complex problems using creative and innovative ideas\\n7. Work with the team to manage, optimize and customize multiple web applications\\n8. Maintain existing code with bugs resolution\\n9. Work on time series database\\nPreferred Skills and Qualifications\\nPython, R, SQL, HTML, CSS, Bootstrap, JSON/ XML, Data Science, deep learning, Machine learning\\nDuration of Internship - 6 months\\nBenefits\\n1.Certificate\\n2.Informal dress code\\n3.5 days a week\\n4.Learn new things and enhance your knowledge\\nContract length: 6 months\\nJob Types: Full-time, Internship\\nSchedule:\\nMonday to Friday\\nExperience:\\nwork: 1 year (Preferred)\\nLocation:\\nPune, Maharashtra (Required)\\nApplication Question:\\nYear of Passing?\\nWork Remotely:\\nNo',\n",
       " \"We are looking for talented Data Scientist with a minimum 5 years of experience in Machine Learning & Data Science to join fast paced software development team.\\nDesired Skills:\\nMinimum 5 years of experience as Data Scientist\\nBachelors/ Masters Degree\\nKey skills:\\nML\\nNLP\\nDeep Learning\\nKeras\\nPython / Java\\nWell versed with Machine Learning algorithms, Deep Learning - RNN, LSTM, CNN, Attention, Language models (Transfer Learning)\\nExpected Start Date: 4/1/2021\\nJob Type: Full-time\\nSalary: ₹600,000.00 - ₹2,200,000.00 per year\\nBenefits:\\nFlexible schedule\\nHealth insurance\\nWork from home\\nSchedule:\\nDay shift\\nFlexible shift\\nExperience:\\nwork: 4 years (Required)\\ntotal work: 5 years (Required)\\nEducation:\\nBachelor's (Required)\",\n",
       " 'Job title\\nSr Data Scientist\\nDepartment\\n53 RAF/STARS\\nReport To\\nDeepthi Devarakonda/Simhan Ramakrishnan\\nNo of yrs. of exp\\n5+\\nWork Location\\nPune\\nNo of Positions\\n1\\nIt’s Time For A Change…\\nYour Future Evolves Here\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.\\nAre we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.\\nPosition summary\\nAs an experienced Data Scientist you’ll join a team of data scientists, analysts, and software engineers working to push the boundaries of data science in health care. We like to experiment, iterate, and innovate with technology, from developing new algorithms specific to health care’s challenges, to bringing the latest machine learning practices and applications developed in other industries into the health care world. We know that algorithms are only valuable when powered by the right data, so we focus on fully understanding the problems we need to solve, and truly understanding the data behind them before launching into solutions – ensuring that the solutions we do land on are impactful and powerful\\nEssential functions\\nResearch, conceptualize, and implement analytical approaches and predictive modeling to evaluate scenarios, predict utilization and clinical outcomes, and recommend actions to impact results.\\nManage and execute on the entire model development process, including scope definition, hypothesis formation, data cleaning and preparation, feature selection, model implementation in production, validation and iteration, using multiple data sources.\\nProvide guidance on necessary data and software infrastructure capabilities to deliver a scalable solution across partners and support the implementation of the team’s algorithms and models into Evolent’s product & platform offerings.\\nContribute to the development and publication in major journals, conferences showcasing Evolent’s leadership in healthcare data science.\\nWork closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals\\nProvide guidance to other Data Scientist and Machine Learning Engineers',\n",
       " \"Job Title: DATA SCIENTIST\\nTotal Experience: 5 TO 10 YEARS\\nJob Location: PUNE (KHARADI)\\nNotice Period: IMMEDIATE TO 30 DAYS.\\nSalary Budget: Upto 45 lacs\\nBelow are the job Details: -\\nIdeal Candidate\\nThe ideal candidate will come with hands-on experience as a Data Scientist having a Data-oriented personality with a good scripting and programming skills. He/she should have hands-on expertise on data science toolkits, specifically in using R for statistical modeling and machine learning.\\nHands-on expertise and exposure in R packages, Shiny for interactive Web applications & machine learning algorithms, model building, statistical modelling, predictive modelling environments. This person will have a proven track record of delivering successful technology solutions to business clients preferably in financial services.\\nRequirements\\n5-10 years of experience in R (preference), Python, or SAS for complex data\\nmanipulation, statistical analysis, and machine learning.\\nExperience with Forecasting, Time Series Analysis, statistical modeling, etc.\\nExperience translating high-level project requirements into technical tasks.\\nData manipulation and data engineering experience involving structured and\\nunstructured data.\\nData manipulation expertise involving data extractions, data matching between multiple systems, transformations, cleansing, and loading.\\nProficient in using Shiny to build interactive web apps straight using R.\\nExperience with big data and cloud platforms especially GCP.\\nExperience in developing predictive, prescriptive, optimization, and forecasting models.\\nExperience in interpreting results from statistical and mathematical models.\\nExperience in advance data visualizations and interpretation.\\nExperience with data visualization tools (e.g., Tableau, Bokeh, D3) or elastic stac (Kibana).\\nExperience with modern machine learning libraries, including Keras, TensorFlow, PyTorch, MXNet.\\nNatural Language Processing (NLP) experience a plus.\\nCollaborative and decisive with strong communication and interpersonal abilities.\\nExpertise in working with large and complex datasets to create dashboards and data visualizations\\nStrong analytics background: Hands on experiences in statistical modeling (e.g. regression model, test and control etc.), machine learning, etc.\\nMultitasker: Good project management and communication skills that can work multiple projects at same time using minimum guidance.\\nResponsibilities\\nUnderstand business requirements to translate business problems into analytics\\nProblems and construct analysis road-map based on the business context\\nManage large volumes of structured and unstructured data, extract & clean data to make it amenable for analysis\\nAnalyse big data using statistics, econometrics, mathematics, operations research, and text mining techniques\\nDevelop good visualization to communicate business insights from analysis and make actionable recommendations\\nHelp deploy analytics solutions and enable tracking of business outcomes to measure return on investment\\nKeep up with cutting edge analytics techniques and tools in the continuously evolving area of decision science\\nPresent/Advise/Interpret/Justify on analytics solutions from a project to Client/Internal Stakeholder\\nJob Type: Full-time\\nSalary: Up to ₹500,000.00 per year\\nSchedule:\\nDay shift\\nEvening shift\\nMorning shift\\nNight shift\\nExperience:\\nTableau, Bokeh, D3) or elastic stack (Kibana): 5 years (Required)\\nBFSI domain experience: 5 years (Required)\\nPython or SAS: 5 years (Preferred)\\nKeras, TensorFlow, PyTorch, MXNet: 5 years (Required)\\nDeep Learning Experience: 5 years (Required)\\nExperience in R: 5 years (Required)\\nNeural Learning Experience: 5 years (Required)\\nEducation:\\nBachelor's (Required)\\nSpeak with the employer\\n+91 9850529592\",\n",
       " 'Business:\\nCCO Tech, HOST\\nOpen positions:\\n1\\n\\nRole Title:\\nManager, Technology Risk & Control Review/CCO\\nGlobal Career Band:\\n5\\n\\nLocation: (Country/City) :\\nIndia/Pune\\nShift Timing:\\nDay job\\n\\nWhy join us? (Overview of Dept./Function)\\n\\nWe are TRaCR (Technology risk and control review) team part of CCO tech, HOST. An agile, responsive and high-quality first line review capability able to deliver a rapid tempo of risk insight to technology to drive continuous improvement in our control environment. TRaCR team offers a world of potential. We are embarking into the journey of Automation and Data analytics with strong focus on Innovation and building new capabilities and solutions.\\nWeencourage our people to dive in, roll up their sleeves and take on the many opportunities bound to come their way. We provide freedom to innovate, code and develop innovative product and solutions. We offer ample opportunities as well as training and development programs that empower you to expand your skills and abilities.\\n\\nThe Opportunity: (Brief Overview of the Role)\\n\\nWe are looking for technical lead with strong hands-on experience in python programming and data analytics to create various capabilities and solutions. The candidate will be passionate about automation and machine learning, artificial intelligence and stay up-to-date with the latest developments in the field.\\n\\nWhat you’ll do: (List out Key Responsibilities)\\n\\nIdentify the opportunity for automation and design/build the end to end solutions.\\nExploring and visualizing data to gain an understanding of it, then identifying pattern in data distribution and generate insights\\nHelp in building key hypothesis and provide data analytics support to generate key insights for technology reviews\\nBuilding machine learning based product leveraging development life cycle –Data preparation, model building, model validation, and model deployment\\nCollaborate with stakeholders and end-users to understand and gather requirements to develop the best automation solutions and data products.\\n\\nWhat you will need to succeed in the role: (Minimum Qualification and Skills Required)\\n\\nFive years’+ software development (either C++/Java/C#/Python) and at least two years solid Python development experience;\\nStrong understanding of machine learning libraries, e.g., Pandas, NumPy, Scikit-learn, Matplotlib, SciPy, PyTorch, TensorFlow;\\nStrong understanding of machine learning and deep learning algorithms, e.g., ensemble models, Naïve Bayes, SVM, Decision Tree, DNN, CNN, RNN\\nGood experience of visualization tool - Tableau/Qlik/Matplotlib\\nGood experience of machine learning development life cycle –Data preparation, model building, model validation, and model deployment\\nGood experience with database, including Relational, Key-value and Search engine\\nGood experience with building and implementing Rest API, API Gateway;\\nFamiliarity with Flask/Django and Docker\\n· Knowledge on Hadoop, Spark, Kafka, NoSQL databases is plus\\n\\nWhat additional skills will be good to have? (List out good to have skills and certifications)\\nGood fundamentals in Computer Science / Software Engineering\\nGood working knowledge in Cloud Platform (prefer GCP)\\nGood understanding of fundamental design principles behind a scalable application\\nGood understanding of Agile, DevOps, CI/CD practice and tooling\\nGood working knowledge of physical IT infrastructures (e.g. Servers, SANs, Networking, etc.)\\nGood experience with Linux systems, e.g. use common shell commands and scripts.\\n\\n\\nThe information contained in this job description is a true and accurate reflection of the job as specified.\\n\\nQualifications\\nBusiness:\\nCCO Tech, HOST\\nOpen positions:\\n1\\n\\nRole Title:\\nManager, Technology Risk & Control Review/CCO\\nGlobal Career Band:\\n5\\n\\nLocation: (Country/City) :\\nIndia/Pune\\nShift Timing:\\nDay job\\n\\nWhy join us? (Overview of Dept./Function)\\n\\nWe are TRaCR (Technology risk and control review) team part of CCO tech, HOST. An agile, responsive and high-quality first line review capability able to deliver a rapid tempo of risk insight to technology to drive continuous improvement in our control environment. TRaCR team offers a world of potential. We are embarking into the journey of Automation and Data analytics with strong focus on Innovation and building new capabilities and solutions.\\nWeencourage our people to dive in, roll up their sleeves and take on the many opportunities bound to come their way. We provide freedom to innovate, code and develop innovative product and solutions. We offer ample opportunities as well as training and development programs that empower you to expand your skills and abilities.\\n\\nThe Opportunity: (Brief Overview of the Role)\\n\\nWe are looking for technical lead with strong hands-on experience in python programming and data analytics to create various capabilities and solutions. The candidate will be passionate about automation and machine learning, artificial intelligence and stay up-to-date with the latest developments in the field.\\n\\nWhat you’ll do: (List out Key Responsibilities)\\n\\nIdentify the opportunity for automation and design/build the end to end solutions.\\nExploring and visualizing data to gain an understanding of it, then identifying pattern in data distribution and generate insights\\nHelp in building key hypothesis and provide data analytics support to generate key insights for technology reviews\\nBuilding machine learning based product leveraging development life cycle –Data preparation, model building, model validation, and model deployment\\nCollaborate with stakeholders and end-users to understand and gather requirements to develop the best automation solutions and data products.\\n\\nWhat you will need to succeed in the role: (Minimum Qualification and Skills Required)\\n\\nFive years’+ software development (either C++/Java/C#/Python) and at least two years solid Python development experience;\\nStrong understanding of machine learning libraries, e.g., Pandas, NumPy, Scikit-learn, Matplotlib, SciPy, PyTorch, TensorFlow;\\nStrong understanding of machine learning and deep learning algorithms, e.g., ensemble models, Naïve Bayes, SVM, Decision Tree, DNN, CNN, RNN\\nGood experience of visualization tool - Tableau/Qlik/Matplotlib\\nGood experience of machine learning development life cycle –Data preparation, model building, model validation, and model deployment\\nGood experience with database, including Relational, Key-value and Search engine\\nGood experience with building and implementing Rest API, API Gateway;\\nFamiliarity with Flask/Django and Docker\\n· Knowledge on Hadoop, Spark, Kafka, NoSQL databases is plus\\n\\nWhat additional skills will be good to have? (List out good to have skills and certifications)\\nGood fundamentals in Computer Science / Software Engineering\\nGood working knowledge in Cloud Platform (prefer GCP)\\nGood understanding of fundamental design principles behind a scalable application\\nGood understanding of Agile, DevOps, CI/CD practice and tooling\\nGood working knowledge of physical IT infrastructures (e.g. Servers, SANs, Networking, etc.)\\nGood experience with Linux systems, e.g. use common shell commands and scripts.\\n\\n\\nThe information contained in this job description is a true and accurate reflection of the job as specified.',\n",
       " 'Job Title Data Science\\nTotal Experience 6 - 8 years\\nJob Location Pune\\nNotice Period IMMEDIATELY / 30 DAYS MAX\\nSalary Budget Total exp into 2x to 2.5x\\nCANDIDATES WHO CAN JOIN IMMEDIATELY / 30 DAYS MAX - MAY ONLY APPLY\\nInterview process\\nLevel 1 - Video Technical discussion thru Monjin Panel\\nLevel 2 - HR discussion (Salary check before setting up the Client Interview)\\nLevel 3 - Technical round with End client\\nBelow are Job details\\nExperience: 6 - 8 years\\nOverall 5+ years of Data Science experience\\nStrong hands on Python, Red Shift, Apache Kafka, Spark / Streaming skills\\nData Engineer will have to solve problems such as efficient ETL from MongoDB, MySQL, ProstreSQL ,\\nData leak technology, batch processing, real time processing, warehousing\"\\nWork on the customer requirement\\nProvide Status updates\\nRaise risks on time\\nAdhere to timelines\\nProvide Value add to the customer and ensure customer issues are addressed\\nJob Type: Full-time\\nSalary: Up to ₹500,000.00 per year\\nSchedule:\\nDay shift\\nEvening shift\\nMorning shift\\nExperience:\\ndata science: 6 years (Required)\\nApache Kafka, Spark: 6 years (Required)\\nRed Shift: 6 years (Required)\\npython: 6 years (Required)\\nEducation:\\nSecondary(10th Pass) (Required)\\nSpeak with the employer\\n+91 9850529592',\n",
       " 'Roles and Responsibilities\\nUnderstand clients business objectives and strategy to ensure that analysis work is focused on the areas where most value can be added.\\nCollaborate with stakeholders/ team leaders in order to understand problem statements and design and execute potential solutions.\\nMentor team members and ensure fault-free execution of projects / solutions.\\nIntegration of multiple sources of data working on BigData platforms.\\nPerform Exploratory Data Analysis on large and complex data sets comprising of structured, semi-structured and unstructured data.\\nWork on multiple unstructured problems to deliver insights/ end-to- end solutions and improve our clients- understanding of their customers using analysis / statistics / machine learning algorithms.\\nKeep abreast of the latest developments in the data science space across industries for potential uses.\\nPlease mail your CV to career@torcai.com',\n",
       " '11/23/2020\\nEcoMetric Consulting is a USA based full service energy consulting firm focusing on energy efficiency, and distributed energy resources including demand response and renewables. EcoMetric is setting up an off-shore office in Pune, India and we are looking for two Energy Engineers to join our team. Opportunities to visit and train in the USA will be provided. EcoMetric Consulting is focused on constructive research to influence energy consumption & behaviors. We provide inspired, forward-thinking advisory services to inform demand-side management decision making. Our core services include energy efficiency program planning and evaluation services for various American utilities, state regulatory boards and other program sponsors. EcoMetric offers competitive compensation packages and an opportunity to learn US standards in energy investments.\\nDuties and Responsibilities\\nExperience importing, cleaning and manipulating large datasets (500,000+ records) using one or more statistical packages (R, Python, STATA) and identifying, summarizing and effectively correcting data inconsistencies. Ability to clearly document and communicate data exploration and cleaning decisions while assessing their effect on resulting data structures and possible analyses.\\nEmploy sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling.\\nBuild scalable and high-performance machine learning algorithms.\\nCreate easily understandable data visualizations of findings (e.g. charts, graphs, infographics).\\nDocument findings visually and/or verbally for memos and reports to clients and/or internal project teams.\\nSupport senior staff with development of presentations and papers.\\nQualifications\\nBachelor’s or Master’s Degree in physics, applied mathematics, economics, statistics, environmental policy, or a related field\\nTwo or more years’ work experience in data management, ideally developing and maintaining databases, data ingestion, cleaning, summarizing, aggregation and manipulation\\nProgramming proficiency with SAS, Stata, Python, and/or R\\nExperience with VBA\\nStrong written and oral presentation skills\\nExperience reading and analyzing IoT data by making API calls is preferred\\nStrong statistical analysis and modeling skills preferably using R or Python\\nExperience conducting econometric modeling or statistical regression analysis\\nExperience with model validation techniques\\nExperience with machine learning methods\\nDemonstrated aptitude with data visualization tools and techniques such as Tableu and Power BI\\nPlease send your resume and a brief cover letter to hiring@ecometricconsulting.com. If you are applying through a job portal such as LinkedIn or Indeed, do not send your materials to the hiring email address.',\n",
       " \"Softnautics is looking for Machine Learning Engineer who is technically strong, possesses hands-on experience in Machine Learning Solutions in domain of Audio, Video, IoT. He/she should have some experience working with complex (SoC / Microprocessor) Embedded Systems is mandatory for this role. The role will be part of Embedded department in which there is a very strong culture of teamwork, cooperation and collaboration\\nResponsibilities\\nMentor and build the team of 2 or more junior engineers\\nDocumentation and Process adherence\\nTechnical ownership for module (s) and / or project (s) and / or domain (s)\\nEffort estimation, planning, customer Interaction\\nRequired Skills:\\n2 - 5 years of experience with Machine Learning Solutions in the domain of Audio, Video, IoT\\n1 - 3 years of experience working with Complex (SoC / Microprocessors) Embedded System\\nStrong at programming, debugging and communication\\nSound knowledge of version control and bug tracking systems – GIT, JIRA, Perforce, CVS etc.\\nHands on experience on Machine Learning Algorithms – Conventional and Deep Learning (must have)\\nHands on experience working on Machine Learning Platforms / Frameworks like TensorFlow, TensorFlow Lite, Keras, Caffe/2, MxNet, pyTorch etc.\\nSound knowledge of Cloud Computing tools’ cognitive ML services – Google cloud, AWS, Azure, IBM Cloud etc.\\nExperience working on Large datasets – Learning, tuning, deployment on Embedded Platform\\nFamiliar with Deep Learning Compilers – CPUs, GPUs, FPGAs\\nShould be able to work in aggressive, high pressure environment\\nExcellent written and verbal communication\\nSelf-starter, problem-solving mentality, and creative thinker\\nDesirable Skills:\\nExperience of mentoring 2 or 3 engineers\\nQuality process – CMMi, Agile Scrum\\nGood knowledge of working with Open source software packages is beneficial and preferred\\nPositive attitude\\nReady to switch between domains based on the project needs\\nApplication Deadline: 31/1/2021\\nExpected Start Date: 15/1/2021\\nJob Type: Full-time\\nSalary: ₹500,000.00 - ₹1,200,000.00 per year\\nBenefits:\\nFlexible schedule\\nHealth insurance\\nPaid time off\\nWork from home\\nSchedule:\\nDay shift\\nMonday to Friday\\nExperience:\\nMachine learning: 3 years (Required)\\ntotal work: 3 years (Required)\\nEducation:\\nBachelor's (Required)\\nApplication Question:\\nCurrent CTC:\\nNotice Period:\\nCurrent Location:\\nEmail ID:\\nWork Remotely:\\nNo\\nCOVID-19 Precaution(s):\\nRemote interview process\\nVirtual meetings\",\n",
       " 'Job Description\\nWe are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.\\nResponsibilities\\nSelecting features, building and optimizing classifiers using machine learning techniques.\\nData mining using state-of-the-art methods.\\nExtending company’s data with third party sources of information when needed.\\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\\nProcessing, cleansing, and verifying the integrity of data used for analysis.\\nDoing ad-hoc analysis and presenting results in a clear manner.\\nCreating automated anomaly detection systems and constant tracking of its performance.\\nRequired Skills\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\nExperience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.\\nExperience with data visualization tools, such as D3.js, GGplot, etc.\\nProficiency in using query languages such as SQL, Hive, Pig.\\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase.\\nExperience with Hadoop or similar distributed computing and storage platforms.\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nGood scripting and programming skills.\\nExceptional analytical abilities,creativity and attention to details.\\nGood organizational and problem solving skills.\\nGood team player who is a self-starter and well organized.\\nStrong oral and written communication skills.\\nRequired Education\\nGraduate degree in Math, Statistics, Computer Science, or other quantitative discipline.\\nPlease email your resume to careers@gtpltech.com',\n",
       " \"A)Should have minimum 1+ years of professional experience in Data Science AI domain\\nB) Should have very good communication skills.\\nC) Should have experience in giving training through online Platform i.e Skype, Webinars, GoToMeeting etc.\\nD)Should have depth knowledge of Data Analytics, Machine Learning, Deep Learning, python, R and NLP Text etc.\\nE)Should have good Presentation and team lead skills\\nF) Expertise in chatbot creation & deployment using NLP, IBM Watson, Google AI tools etc. (optional)\\n*\\nKey skills\\n1. Google dialogue flow\\n2. IBM Watson\\n3. Deep learning\\n4. Python\\n5. NLP\\n6. Computer vision\\n7. Aws or azure deployment knowledge\\n8. Ai Chatbot development\\n9. Machine learning\\n10. Statistics\\n*\\nJob Types: Full-time, Regular / Permanent\\nSalary: ₹240,000.00 - ₹360,000.00 per year\\nSchedule:\\nDay shift\\nMorning shift\\nEducation:\\nBachelor's (Preferred)\\nExperience:\\nData Science: 1 year (Preferred)\\nLanguage:\\nEnglish (Preferred)\\nIndustry:\\nEducation & Instruction\\nWork Remotely:\\nNo\",\n",
       " 'Overview: To be part of with Data Science and Analytics (DSA) team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. It includes simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modelling and machine learning techniques primarily using multiple technologies and big data platforms.\\n\\nRoles and Responsibilities:\\n\\nYour primary role will be to identify and work on high-impact business problems and develop viable solutions through data analysis, predictive modelling, and advanced analytics techniques.\\n\\nExtracts data from multiple sources and creates an analytical data mart.\\n\\nPerforms statistical data analysis on large data sets, resulting in impactful insights and outcomes.\\n\\nLogically integrates information from multiple resources and effectively communicates results to department management.\\n\\nShould have in-depth experience in experimental design, sampling, feature selection, building classifiers, model selection and training, and model interpretation.\\n\\nDevelops ad hoc analyses using standard and advanced statistical techniques (e.g., regression, CHAID, factor analysis, ANOVA, clustering analysis) .\\n\\nCollaborates to implement projects, complete tasks, and fulfil plans to ensure timely and efficient analysis, modelling, evaluation and reporting.\\n\\nTemplatize best in class data-mining processes and reporting.\\n\\nPrepares written analysis and presents findings and recommendations to key business leaders. Communicate changes in business trends to c-level executives and provide guidance as to the overall impact.\\n\\nIdentifies actionable insights, suggests recommendations, and influences the direction of the business by effectively communicating results to cross functional groups.\\n\\nTeam Management:\\n\\nManaged team size of 10 associates with skillsets of data science and analytics\\n\\nQualifying Criteria:\\n\\nBE/B.Tech/M.Sc.,degree in related discipline strongly desired (Mathematics, Statistics, Operations Research)\\n\\n5+ years of relevant experience in analytics, data science and building ML models\\n\\nConceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc.\\n\\nStrong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise\\n\\nExposure to R, Python, Hive, or other open source languages preferable\\n\\nGood programming knowledge in Relational Databases (MySQL,PL/SQL) and NoSQL Databases, along with know-how about database performances.\\nPowered by JazzHR\\n0LVoiYxIZN',\n",
       " 'Two positions are currently available in Pune, India and one position is open in Sunnyvale, CA. Title seniority and salary are set to the experience level of the applicant.\\nRole and Responsibilities\\nExecute data mining projects, training and deploying models over a typical duration of 2 -12 months.\\nThe ideal candidate should be able to innovate, analyze the customer requirement, develop a solution in the time box of the project plan, execute and deploy the solution.\\nIntegrate the data mining projects embedded data mining applications in the FogHorn platform (on Docker or Android).\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications:\\nHave analyzed, trained and deployed at least three data mining models in the past. If the candidate did not directly deploy their own models, they will have worked with others who have put their models into production. The models should have been validated as robust over at least an initial time period.\\nThree years of industry work experience, developing data mining models which were deployed and used.\\nProgramming experience in Python is core using data mining related libraries like Scikit-Learn. Other relevant Python mining libraries include NumPy, SciPy and Pandas.\\nData mining algorithm experience in at least 3 algorithms within any of the bullets below:\\ndeep learning (TensorFlow, Convolutional Neural Nets (CNN) or related),\\nprediction (statistical regression, neural nets, deep learning, decision trees, SVM, ensembles),\\nclustering (k-means, DBSCAN or other) or Bayesian networks\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive:\\nSoft Skills\\nSets expectations, develops project plans and meets expectations.\\nExperience adapting technical dialogue to the right level for the audience (i.e. executives) or specific jargon for a given vertical market and job function.\\nTechnical skills\\nCommonly, candidates have a MS or Ph.D. in Computer Science, Math, Statistics or an engineering technical discipline. BS candidates with experience are considered.\\nHave managed past models in production over their full life cycle until model replacement is needed. Have developed automated model refreshing on newer data. Have developed frameworks for model automation as a prototype for product.\\nTraining or experience in Deep Learning, such as TensorFlow, Keras, PyTorch, ONNX, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network architectures. If you don’t have deep learning experience, we will train you on the job.\\nJava, Android development\\nShrinking deep learning models, optimizing to speed up execution time of scoring or inference.\\nOpenCV or other image processing tools or libraries\\nCloud computing: Google Cloud, Amazon AWS or Microsoft Azure.\\nDecision trees like XGBoost or Random Forests is helpful.\\nComplex Event Processing (CEP) or other streaming data as a data source for data mining analysis\\nTime series algorithms from ARIMA to LSTM to Digital Signal Processing (DSP).\\nBayesian Networks (BN), a.k.a. Bayesian Belief Networks (BBN) or Graphical Belief Networks (GBN)\\nExperience with PMML is of interest (see www.DMG.org).\\nVertical experience in Industrial Internet of Things (IoT) applications:\\nEnergy: Oil and Gas, HVAC energy consumption, Wind Turbines\\nManufacturing: Motors, chemical processes, tools, automotive\\nSmart Cities: Elevators, cameras on population or cars, power grid\\nTransportation: Cars, truck fleets, trains\\nHow To Apply\\nTo apply, submit a resume to careers@foghorn.io, with an email subject of either:\\n“Sunnyvale Data Scientist application <name>”, where <name> is the applicant’s name. No “<>” are needed. This assumes you are near enough to commute to Sunnyvale, CA, USA and have a work permit.\\nor “Pune Data Scientist application <name>”, if you are applying for a job in that location in Pune, India.\\nIf you want to be more competitive, address how you meet all the minimum requirements and any bonus qualifications.\\n\\nAbout FogHorn Systems\\nFogHorn is a leading developer of “edge intelligence” software for industrial and commercial IoT application solutions. FogHorn’s Lightning software platform brings the power of advanced analytics and machine learning to the on-premise edge environment enabling a new class of applications for advanced monitoring and diagnostics, machine performance optimization, proactive maintenance and operational intelligence use cases. FogHorn’s technology is ideally suited for OEMs, systems integrators and end customers in manufacturing, power and water, oil and gas, renewable energy, mining, transportation, healthcare, retail, as well as Smart Grid, Smart City, Smart Building and connected vehicle applications.\\nPress: https://www.foghorn.io/press-room/\\nAwards: https://www.foghorn.io/awards-and-recognition/\\n2020 World Economic Forum Technology Pioneer\\n2020 IoT World Awards, Best Edge Computing Solution\\n2020 Golden Bridge Awards, Most Innovative Company of the Year – AI Category\\n2020 IoT Evolution Edge Computing Excellence Award\\n2019 Edge Computing Company of the Year – Compass Intelligence\\n2019 Internet of Things 50: 10 Coolest Industrial IoT Companies – CRN\\n2018 IoT Planforms Leadership Award & Edge Computing Excellence – IoT Evolution World Magazine\\n2018 10 Hot IoT Startups to Watch – Network World. (Gartner estimated 20 billion connected things in use worldwide by 2020)\\n2018 Winner in Artificial Intelligence and Machine Learning – Globe Awards\\n2018 Ten Edge Computing Vendors to Watch – ZDNet & 451 Research\\n2018 The 10 Most Innovative AI Solution Providers – Insights Success\\n2018 The AI 100 – CB Insights\\n2017 Cool Vendor in IoT Edge Computing – Gartner\\n2017 20 Most Promising AI Service Providers – CIO Review\\nOur Series A round was for $15 million. Our Series B round was for $30 million October 2017. Investors include: Saudi Aramco Energy Ventures, Intel Capital, GE, Dell, Bosch, Honeywell and The Hive.\\nAbout the Data Science Solutions team\\nIn 2018, our Data Science Solutions team grew from 4 to 9. We are growing again from 10 t0 13. We work on revenue-generating projects for clients, such as predictive maintenance, time to failure, manufacturing defects. About half of our projects have been related to vision recognition or deep learning. We are not only working on consulting projects but developing vertical solution applications that run on our Lightning platform, with embedded data mining.\\nOur data scientists like our team because:\\nWe care about “best practices”\\nHave a direct impact on the company’s revenue\\nGive or receive mentoring as part of the collaborative process\\nQuestions and challenging the status quo with data is safe\\nIntellectual curiosity balanced with humility\\nPresent papers or projects in our “Thought Leadership” meeting series, to support continuous learning',\n",
       " \"Vacancy for Machine Learning Engineer\\n*\\nAbout Us:\\nWe are a team of talented and inspired professionals, motivated to change the world by making energy greener, and more affordable. Established in 2011 in London, we are now one of the most recognized artificial intelligence companies in the power sector with recent recognitions from the US Department of Energy and from the CleanTech Group. Our services are trusted by the largest and best performing renewable energy and distribution companies in India. In 2020, we started functioning as an independent subsidiary of the largest renewable energy generator in India, ReNew Power.\\n*\\n*\\nLike most successful start-ups, we started with just a dream: To have a global 100% renewables powered grid, at 10% of the price we pay for our energy today, with 100% reliability of supply for all. We believe that machine learning and other software technologies will be key in enabling this vision. Thus, our mission is to construct the data architecture and design algorithms that give an intelligently powered future to the world. Join us in turning this dream into a reality\\n*\\n*\\nWhat it’s really like to work here:\\nWe recognize the value that company culture plays in the recruitment process. Beyond the standard technical and experience fit, we look for individuals who will become a part of our family. When you join our team, you become a part of a strong network of brilliant and an accomplished legacy from top engineering and business schools in the world such as the Indian Institute of Technology, Oxford University, University of Cambridge, University College of London and many more.\\n*\\n*\\nWe want more people who can thrive in a collaborative team-environment. Our multi-layered support system, comprising a global network of advisors, provides unparalleled opportunities for growth and learning in a friendly environment. We don’t believe in old-fashioned hierarchies. We work in teams and give people at all levels the freedom to lead and implement projects. With flexible hours and merit-based reward systems, we offer tremendous potential for advancement.\\n*\\n*\\nYou are the person for this job, if you have these qualities:\\nResults-oriented. You can meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nCollaboration. You have the ability to work closely with other business teams in a collaborative setting.\\nCommunication skills. You are great at conveying your message to team members and other stakeholders.\\nHonesty. You work diligently and honestly. You have strong moral principles.\\nKnowledgeable. You are constantly researching and always up-to-date with all recent advancements in data sciences. You have a flair for using the right metrics to measure model performance, quality, and reliability.\\nProblem-solver. You proactively identify challenges and risks to the project and offer solutions. You demonstrate the ability to transform theoretical knowledge to practical, real-world situations.\\nCritical-thinker. You have the ability to think critically and conceptually about the role of each feature/development unit in the achievement of the product’s goals\\nExperience. You have previously worked with large databases to access, manipulate and process data.\\nWe are looking for people with knowledge of:\\nPython.\\nLibraries like Numpy, Pandas, sk-learn, tensorflow 2.0, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nMySQL, MongoDB, ElasticSearch or other NoSQL database implementations.\\nAPIs and JSON-REST. Able to access and work with various data APIs.\\nA wide set of machine learning approaches and designing the features and data processing to actually make them work.\\n*\\n*\\nWhat you’ll work on:\\n*\\n*\\nAs an ML Engineer, you will be creating a forecasting model in python for the Solar and Wind Plants by using the various Machine Learning algorithms. Ultimately, through your contribution to the renewable energy revolution, you will be doing your bit to mitigate the effects of climate change. These are a few things you can look forward to working on:\\nDeveloping and testing the forecasting algorithms using large data sets such as load whether historical, grid etc.\\nCollaborating with the team to deploy the developed model as per the client need\\nTaking responsibility for the Model development process, testing, and debugging required for deploying the models\\nCollaborating with the operations team and management to establish strategies.\\nEnsuring tracking of appropriate events/metrics, so that monitoring is timely and rigorous.\\nDriving the response to discovery of regressions or failures, by undertaking various\\nexercises (e.g. debugging, RCA, etc.)\\nStaying up-to-date on evolutions in best practice, tooling, and strategies in the ML space.\\n*\\n*\\nQualifications:\\n1-3 years of experience in the field of Data Sciences or Machine Learning\\n*\\n*\\nWhere you will work:\\nPune, Maharashtra\\nDelhi\\n*\\n*\\nRemuneration:\\nThe remuneration for this position is one of the most competitive in the market\\n*\\n*\\nHow we will select you:\\nWe will parse your CVs and if selected our HR department will connect with you and confirm your interest.\\nThere will be a two-part take home assignment.\\nThere will be three interview rounds, out of which two rounds will be technical assessment and one will be a personal interview.\\n*\\n*\\n*\\n*\\n*\\nJob Type: Full-time\\nSalary: ₹700,000.00 - ₹1,200,000.00 per year\\nSchedule:\\nDay shift\\nExperience:\\nTotal work as Machine Learning Engineer: 2 years (Required)\\nEducation:\\nBachelor's (Preferred)\\nWork Remotely:\\nTemporarily due to COVID-19\",\n",
       " 'We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\\n\\nResponsibilities:\\nDesigning and deploying deep learning algorithms and predictive models\\nDevelop custom data models and algorithms to apply to data sets\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\\nDevelop processes and tools to monitor and analyze model performance and data accuracy\\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\\n\\nQualifications:\\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\\nAbility to drive a project and work both independently and in a team',\n",
       " 'Looking for full time & part time Data Science/Machine Learning Trainers to teach in classroom(offline) in our Viman Nagar branch in Pune.\\nWe are a leading software training institute in Pune with our branches in Pimple Saudagar and Viman Nagar. We have been providing exclusive training on Data Science, Machine Learning & Artificial Intelligence since 2014.\\nIf interested, please send your updated resume to the given email id with the subject line \"Data Science Trainer\".\\nhttps://marsiantech.com/\\nMobile: 7028052110\\nJob Types: Full-time, Part-time, Contract\\nSalary: ₹240,000.00 - ₹400,000.00 per year\\nBenefits:\\nFlexible schedule\\nExperience:\\nAnalytics: 1 year (Required)\\nMachine Learning: 1 year (Required)\\nR: 1 year (Required)\\nPython: 1 year (Required)\\nLocation:\\nPune, Maharashtra (Required)\\nIndustry:\\nEducation & Instruction\\nWork Remotely:\\nNo\\nSpeak with the employer\\n+91 7028052110',\n",
       " 'Experience : 5 - 7 Years\\nJOB DESCRIPTION\\nShould have a Master’s degree in Statistics, Mathematics, Computer Science\\nResponsibilities Include:\\nInteracting with the stakeholders, within the company and the customers, to understand the needs\\nExploratory analysis from the existing data\\nFormulating the questions to be answered and hypotheses to be tested\\nIdentifying additional data to be collected and third-party data sources that will help the analysis\\nDeveloping data presentations, models and algorithms required\\nUsing data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback\\nProviding inputs and support to software / firmware developers to build the required software components, data structures and dashboards\\nInteract with other project team members to adhere to overall project schedules\\nEnsure Adherence to internal development policies and participating in continually improving existing processes\\nMandatory Technical Abilities:\\nStrong problem-solving skills with an emphasis on product development\\nExperience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets\\nExperience of working with and creating data architectures\\nExperience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)\\nExperience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)\\nProficiency in using query languages such as SQL, Hive\\nExperience with NoSql databases (MongoDB, Cassandra…)\\nKnowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications\\nGood written and verbal communication skills for coordinating across teams\\nAbility to learn and master new technologies and techniques',\n",
       " 'Job Location – Pune, India\\nRequired experience – 6-10 Years\\nAbout Innoplexus\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nLead and mentor a small team of data scientists in applying existing learning algorithms and develop new ones\\nDevelop scalable customer-facing solutions over real-world, noisy and unstructured data\\nDevelop highly scalable deep learning algorithms to improve our platform\\nDevelop state-of-the-art machine learning and neural network methodologies to improve our intelligence platform\\nCross-functional collaboration between data science and engineering teams to support the integration of finished algorithms and prototypes into product\\nSupport sales and business development teams to fine-tune client requirements, perform feasibility testing and proposing an approach for solutions\\nWe need you to have:\\nBachelors/Masters/PhD Degree in Computer Science, related Machine Learning field or equivalent from Tier-1 or premier institutes like IIT, IISc, BITS, NIT or globally renowned universities\\nKnowledge On:\\nRelevant Hands-on Experience in any of the below groups:\\nInformation Extraction, Text Mining from Unstructured data\\nComputational Genomics, Bioinformatics\\nStrong in Python programming\\nKnowledge commonly used machine learning tools:, pytorch, scikit-learn, gensim, pandas\\nExperience with major NoSQL products\\nExperience in the domain of life sciences is a plus\\nMust have experience in leading teams\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"Job Title: DATA SCIENTIST\\nTotal Experience: 5 TO 10 YEARS\\nJob Location: PUNE (KHARADI)\\nNotice Period: IMMEDIATE TO 30 DAYS.\\nSalary Budget: Upto 45 lacs\\nBelow are the job Details: -\\nIdeal Candidate\\nThe ideal candidate will come with hands-on experience as a Data Scientist having a Data-oriented personality with a good scripting and programming skills. He/she should have hands-on expertise on data science toolkits, specifically in using R for statistical modeling and machine learning.\\nHands-on expertise and exposure in R packages, Shiny for interactive Web applications & machine learning algorithms, model building, statistical modelling, predictive modelling environments. This person will have a proven track record of delivering successful technology solutions to business clients preferably in financial services.\\nRequirements\\n5-10 years of experience in R (preference), Python, or SAS for complex data\\nmanipulation, statistical analysis, and machine learning.\\nExperience with Forecasting, Time Series Analysis, statistical modeling, etc.\\nExperience translating high-level project requirements into technical tasks.\\nData manipulation and data engineering experience involving structured and\\nunstructured data.\\nData manipulation expertise involving data extractions, data matching between multiple systems, transformations, cleansing, and loading.\\nProficient in using Shiny to build interactive web apps straight using R.\\nExperience with big data and cloud platforms especially GCP.\\nExperience in developing predictive, prescriptive, optimization, and forecasting models.\\nExperience in interpreting results from statistical and mathematical models.\\nExperience in advance data visualizations and interpretation.\\nExperience with data visualization tools (e.g., Tableau, Bokeh, D3) or elastic stac (Kibana).\\nExperience with modern machine learning libraries, including Keras, TensorFlow, PyTorch, MXNet.\\nNatural Language Processing (NLP) experience a plus.\\nCollaborative and decisive with strong communication and interpersonal abilities.\\nExpertise in working with large and complex datasets to create dashboards and data visualizations\\nStrong analytics background: Hands on experiences in statistical modeling (e.g. regression model, test and control etc.), machine learning, etc.\\nMultitasker: Good project management and communication skills that can work multiple projects at same time using minimum guidance.\\nResponsibilities\\nUnderstand business requirements to translate business problems into analytics\\nProblems and construct analysis road-map based on the business context\\nManage large volumes of structured and unstructured data, extract & clean data to make it amenable for analysis\\nAnalyse big data using statistics, econometrics, mathematics, operations research, and text mining techniques\\nDevelop good visualization to communicate business insights from analysis and make actionable recommendations\\nHelp deploy analytics solutions and enable tracking of business outcomes to measure return on investment\\nKeep up with cutting edge analytics techniques and tools in the continuously evolving area of decision science\\nPresent/Advise/Interpret/Justify on analytics solutions from a project to Client/Internal Stakeholder\\nJob Type: Full-time\\nSalary: Up to ₹500,000.00 per year\\nSchedule:\\nDay shift\\nEvening shift\\nMorning shift\\nNight shift\\nExperience:\\nTableau, Bokeh, D3) or elastic stack (Kibana): 5 years (Required)\\nBFSI domain experience: 5 years (Required)\\nPython or SAS: 5 years (Preferred)\\nKeras, TensorFlow, PyTorch, MXNet: 5 years (Required)\\nDeep Learning Experience: 5 years (Required)\\nExperience in R: 5 years (Required)\\nNeural Learning Experience: 5 years (Required)\\nEducation:\\nBachelor's (Required)\\nSpeak with the employer\\n+91 9850529592\",\n",
       " 'Business:\\nCCO Tech, HOST\\nOpen positions:\\n1\\n\\nRole Title:\\nManager, Technology Risk & Control Review/CCO\\nGlobal Career Band:\\n5\\n\\nLocation: (Country/City) :\\nIndia/Pune\\nShift Timing:\\nDay job\\n\\nWhy join us? (Overview of Dept./Function)\\n\\nWe are TRaCR (Technology risk and control review) team part of CCO tech, HOST. An agile, responsive and high-quality first line review capability able to deliver a rapid tempo of risk insight to technology to drive continuous improvement in our control environment. TRaCR team offers a world of potential. We are embarking into the journey of Automation and Data analytics with strong focus on Innovation and building new capabilities and solutions.\\nWeencourage our people to dive in, roll up their sleeves and take on the many opportunities bound to come their way. We provide freedom to innovate, code and develop innovative product and solutions. We offer ample opportunities as well as training and development programs that empower you to expand your skills and abilities.\\n\\nThe Opportunity: (Brief Overview of the Role)\\n\\nWe are looking for technical lead with strong hands-on experience in python programming and data analytics to create various capabilities and solutions. The candidate will be passionate about automation and machine learning, artificial intelligence and stay up-to-date with the latest developments in the field.\\n\\nWhat you’ll do: (List out Key Responsibilities)\\n\\nIdentify the opportunity for automation and design/build the end to end solutions.\\nExploring and visualizing data to gain an understanding of it, then identifying pattern in data distribution and generate insights\\nHelp in building key hypothesis and provide data analytics support to generate key insights for technology reviews\\nBuilding machine learning based product leveraging development life cycle –Data preparation, model building, model validation, and model deployment\\nCollaborate with stakeholders and end-users to understand and gather requirements to develop the best automation solutions and data products.\\n\\nWhat you will need to succeed in the role: (Minimum Qualification and Skills Required)\\n\\nFive years’+ software development (either C++/Java/C#/Python) and at least two years solid Python development experience;\\nStrong understanding of machine learning libraries, e.g., Pandas, NumPy, Scikit-learn, Matplotlib, SciPy, PyTorch, TensorFlow;\\nStrong understanding of machine learning and deep learning algorithms, e.g., ensemble models, Naïve Bayes, SVM, Decision Tree, DNN, CNN, RNN\\nGood experience of visualization tool - Tableau/Qlik/Matplotlib\\nGood experience of machine learning development life cycle –Data preparation, model building, model validation, and model deployment\\nGood experience with database, including Relational, Key-value and Search engine\\nGood experience with building and implementing Rest API, API Gateway;\\nFamiliarity with Flask/Django and Docker\\n· Knowledge on Hadoop, Spark, Kafka, NoSQL databases is plus\\n\\nWhat additional skills will be good to have? (List out good to have skills and certifications)\\nGood fundamentals in Computer Science / Software Engineering\\nGood working knowledge in Cloud Platform (prefer GCP)\\nGood understanding of fundamental design principles behind a scalable application\\nGood understanding of Agile, DevOps, CI/CD practice and tooling\\nGood working knowledge of physical IT infrastructures (e.g. Servers, SANs, Networking, etc.)\\nGood experience with Linux systems, e.g. use common shell commands and scripts.\\n\\n\\nThe information contained in this job description is a true and accurate reflection of the job as specified.\\n\\nQualifications\\nBusiness:\\nCCO Tech, HOST\\nOpen positions:\\n1\\n\\nRole Title:\\nManager, Technology Risk & Control Review/CCO\\nGlobal Career Band:\\n5\\n\\nLocation: (Country/City) :\\nIndia/Pune\\nShift Timing:\\nDay job\\n\\nWhy join us? (Overview of Dept./Function)\\n\\nWe are TRaCR (Technology risk and control review) team part of CCO tech, HOST. An agile, responsive and high-quality first line review capability able to deliver a rapid tempo of risk insight to technology to drive continuous improvement in our control environment. TRaCR team offers a world of potential. We are embarking into the journey of Automation and Data analytics with strong focus on Innovation and building new capabilities and solutions.\\nWeencourage our people to dive in, roll up their sleeves and take on the many opportunities bound to come their way. We provide freedom to innovate, code and develop innovative product and solutions. We offer ample opportunities as well as training and development programs that empower you to expand your skills and abilities.\\n\\nThe Opportunity: (Brief Overview of the Role)\\n\\nWe are looking for technical lead with strong hands-on experience in python programming and data analytics to create various capabilities and solutions. The candidate will be passionate about automation and machine learning, artificial intelligence and stay up-to-date with the latest developments in the field.\\n\\nWhat you’ll do: (List out Key Responsibilities)\\n\\nIdentify the opportunity for automation and design/build the end to end solutions.\\nExploring and visualizing data to gain an understanding of it, then identifying pattern in data distribution and generate insights\\nHelp in building key hypothesis and provide data analytics support to generate key insights for technology reviews\\nBuilding machine learning based product leveraging development life cycle –Data preparation, model building, model validation, and model deployment\\nCollaborate with stakeholders and end-users to understand and gather requirements to develop the best automation solutions and data products.\\n\\nWhat you will need to succeed in the role: (Minimum Qualification and Skills Required)\\n\\nFive years’+ software development (either C++/Java/C#/Python) and at least two years solid Python development experience;\\nStrong understanding of machine learning libraries, e.g., Pandas, NumPy, Scikit-learn, Matplotlib, SciPy, PyTorch, TensorFlow;\\nStrong understanding of machine learning and deep learning algorithms, e.g., ensemble models, Naïve Bayes, SVM, Decision Tree, DNN, CNN, RNN\\nGood experience of visualization tool - Tableau/Qlik/Matplotlib\\nGood experience of machine learning development life cycle –Data preparation, model building, model validation, and model deployment\\nGood experience with database, including Relational, Key-value and Search engine\\nGood experience with building and implementing Rest API, API Gateway;\\nFamiliarity with Flask/Django and Docker\\n· Knowledge on Hadoop, Spark, Kafka, NoSQL databases is plus\\n\\nWhat additional skills will be good to have? (List out good to have skills and certifications)\\nGood fundamentals in Computer Science / Software Engineering\\nGood working knowledge in Cloud Platform (prefer GCP)\\nGood understanding of fundamental design principles behind a scalable application\\nGood understanding of Agile, DevOps, CI/CD practice and tooling\\nGood working knowledge of physical IT infrastructures (e.g. Servers, SANs, Networking, etc.)\\nGood experience with Linux systems, e.g. use common shell commands and scripts.\\n\\n\\nThe information contained in this job description is a true and accurate reflection of the job as specified.',\n",
       " 'Job Title Data Science\\nTotal Experience 6 - 8 years\\nJob Location Pune\\nNotice Period IMMEDIATELY / 30 DAYS MAX\\nSalary Budget Total exp into 2x to 2.5x\\nCANDIDATES WHO CAN JOIN IMMEDIATELY / 30 DAYS MAX - MAY ONLY APPLY\\nInterview process\\nLevel 1 - Video Technical discussion thru Monjin Panel\\nLevel 2 - HR discussion (Salary check before setting up the Client Interview)\\nLevel 3 - Technical round with End client\\nBelow are Job details\\nExperience: 6 - 8 years\\nOverall 5+ years of Data Science experience\\nStrong hands on Python, Red Shift, Apache Kafka, Spark / Streaming skills\\nData Engineer will have to solve problems such as efficient ETL from MongoDB, MySQL, ProstreSQL ,\\nData leak technology, batch processing, real time processing, warehousing\"\\nWork on the customer requirement\\nProvide Status updates\\nRaise risks on time\\nAdhere to timelines\\nProvide Value add to the customer and ensure customer issues are addressed\\nJob Type: Full-time\\nSalary: Up to ₹500,000.00 per year\\nSchedule:\\nDay shift\\nEvening shift\\nMorning shift\\nExperience:\\ndata science: 6 years (Required)\\nApache Kafka, Spark: 6 years (Required)\\nRed Shift: 6 years (Required)\\npython: 6 years (Required)\\nEducation:\\nSecondary(10th Pass) (Required)\\nSpeak with the employer\\n+91 9850529592',\n",
       " 'Roles and Responsibilities\\nUnderstand clients business objectives and strategy to ensure that analysis work is focused on the areas where most value can be added.\\nCollaborate with stakeholders/ team leaders in order to understand problem statements and design and execute potential solutions.\\nMentor team members and ensure fault-free execution of projects / solutions.\\nIntegration of multiple sources of data working on BigData platforms.\\nPerform Exploratory Data Analysis on large and complex data sets comprising of structured, semi-structured and unstructured data.\\nWork on multiple unstructured problems to deliver insights/ end-to- end solutions and improve our clients- understanding of their customers using analysis / statistics / machine learning algorithms.\\nKeep abreast of the latest developments in the data science space across industries for potential uses.\\nPlease mail your CV to career@torcai.com',\n",
       " '11/23/2020\\nEcoMetric Consulting is a USA based full service energy consulting firm focusing on energy efficiency, and distributed energy resources including demand response and renewables. EcoMetric is setting up an off-shore office in Pune, India and we are looking for two Energy Engineers to join our team. Opportunities to visit and train in the USA will be provided. EcoMetric Consulting is focused on constructive research to influence energy consumption & behaviors. We provide inspired, forward-thinking advisory services to inform demand-side management decision making. Our core services include energy efficiency program planning and evaluation services for various American utilities, state regulatory boards and other program sponsors. EcoMetric offers competitive compensation packages and an opportunity to learn US standards in energy investments.\\nDuties and Responsibilities\\nExperience importing, cleaning and manipulating large datasets (500,000+ records) using one or more statistical packages (R, Python, STATA) and identifying, summarizing and effectively correcting data inconsistencies. Ability to clearly document and communicate data exploration and cleaning decisions while assessing their effect on resulting data structures and possible analyses.\\nEmploy sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling.\\nBuild scalable and high-performance machine learning algorithms.\\nCreate easily understandable data visualizations of findings (e.g. charts, graphs, infographics).\\nDocument findings visually and/or verbally for memos and reports to clients and/or internal project teams.\\nSupport senior staff with development of presentations and papers.\\nQualifications\\nBachelor’s or Master’s Degree in physics, applied mathematics, economics, statistics, environmental policy, or a related field\\nTwo or more years’ work experience in data management, ideally developing and maintaining databases, data ingestion, cleaning, summarizing, aggregation and manipulation\\nProgramming proficiency with SAS, Stata, Python, and/or R\\nExperience with VBA\\nStrong written and oral presentation skills\\nExperience reading and analyzing IoT data by making API calls is preferred\\nStrong statistical analysis and modeling skills preferably using R or Python\\nExperience conducting econometric modeling or statistical regression analysis\\nExperience with model validation techniques\\nExperience with machine learning methods\\nDemonstrated aptitude with data visualization tools and techniques such as Tableu and Power BI\\nPlease send your resume and a brief cover letter to hiring@ecometricconsulting.com. If you are applying through a job portal such as LinkedIn or Indeed, do not send your materials to the hiring email address.',\n",
       " \"Softnautics is looking for Machine Learning Engineer who is technically strong, possesses hands-on experience in Machine Learning Solutions in domain of Audio, Video, IoT. He/she should have some experience working with complex (SoC / Microprocessor) Embedded Systems is mandatory for this role. The role will be part of Embedded department in which there is a very strong culture of teamwork, cooperation and collaboration\\nResponsibilities\\nMentor and build the team of 2 or more junior engineers\\nDocumentation and Process adherence\\nTechnical ownership for module (s) and / or project (s) and / or domain (s)\\nEffort estimation, planning, customer Interaction\\nRequired Skills:\\n2 - 5 years of experience with Machine Learning Solutions in the domain of Audio, Video, IoT\\n1 - 3 years of experience working with Complex (SoC / Microprocessors) Embedded System\\nStrong at programming, debugging and communication\\nSound knowledge of version control and bug tracking systems – GIT, JIRA, Perforce, CVS etc.\\nHands on experience on Machine Learning Algorithms – Conventional and Deep Learning (must have)\\nHands on experience working on Machine Learning Platforms / Frameworks like TensorFlow, TensorFlow Lite, Keras, Caffe/2, MxNet, pyTorch etc.\\nSound knowledge of Cloud Computing tools’ cognitive ML services – Google cloud, AWS, Azure, IBM Cloud etc.\\nExperience working on Large datasets – Learning, tuning, deployment on Embedded Platform\\nFamiliar with Deep Learning Compilers – CPUs, GPUs, FPGAs\\nShould be able to work in aggressive, high pressure environment\\nExcellent written and verbal communication\\nSelf-starter, problem-solving mentality, and creative thinker\\nDesirable Skills:\\nExperience of mentoring 2 or 3 engineers\\nQuality process – CMMi, Agile Scrum\\nGood knowledge of working with Open source software packages is beneficial and preferred\\nPositive attitude\\nReady to switch between domains based on the project needs\\nApplication Deadline: 31/1/2021\\nExpected Start Date: 15/1/2021\\nJob Type: Full-time\\nSalary: ₹500,000.00 - ₹1,200,000.00 per year\\nBenefits:\\nFlexible schedule\\nHealth insurance\\nPaid time off\\nWork from home\\nSchedule:\\nDay shift\\nMonday to Friday\\nExperience:\\nMachine learning: 3 years (Required)\\ntotal work: 3 years (Required)\\nEducation:\\nBachelor's (Required)\\nApplication Question:\\nCurrent CTC:\\nNotice Period:\\nCurrent Location:\\nEmail ID:\\nWork Remotely:\\nNo\\nCOVID-19 Precaution(s):\\nRemote interview process\\nVirtual meetings\",\n",
       " 'Job Description\\nWe are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.\\nResponsibilities\\nSelecting features, building and optimizing classifiers using machine learning techniques.\\nData mining using state-of-the-art methods.\\nExtending company’s data with third party sources of information when needed.\\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\\nProcessing, cleansing, and verifying the integrity of data used for analysis.\\nDoing ad-hoc analysis and presenting results in a clear manner.\\nCreating automated anomaly detection systems and constant tracking of its performance.\\nRequired Skills\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\nExperience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.\\nExperience with data visualization tools, such as D3.js, GGplot, etc.\\nProficiency in using query languages such as SQL, Hive, Pig.\\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase.\\nExperience with Hadoop or similar distributed computing and storage platforms.\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nGood scripting and programming skills.\\nExceptional analytical abilities,creativity and attention to details.\\nGood organizational and problem solving skills.\\nGood team player who is a self-starter and well organized.\\nStrong oral and written communication skills.\\nRequired Education\\nGraduate degree in Math, Statistics, Computer Science, or other quantitative discipline.\\nPlease email your resume to careers@gtpltech.com',\n",
       " \"A)Should have minimum 1+ years of professional experience in Data Science AI domain\\nB) Should have very good communication skills.\\nC) Should have experience in giving training through online Platform i.e Skype, Webinars, GoToMeeting etc.\\nD)Should have depth knowledge of Data Analytics, Machine Learning, Deep Learning, python, R and NLP Text etc.\\nE)Should have good Presentation and team lead skills\\nF) Expertise in chatbot creation & deployment using NLP, IBM Watson, Google AI tools etc. (optional)\\n*\\nKey skills\\n1. Google dialogue flow\\n2. IBM Watson\\n3. Deep learning\\n4. Python\\n5. NLP\\n6. Computer vision\\n7. Aws or azure deployment knowledge\\n8. Ai Chatbot development\\n9. Machine learning\\n10. Statistics\\n*\\nJob Types: Full-time, Regular / Permanent\\nSalary: ₹240,000.00 - ₹360,000.00 per year\\nSchedule:\\nDay shift\\nMorning shift\\nEducation:\\nBachelor's (Preferred)\\nExperience:\\nData Science: 1 year (Preferred)\\nLanguage:\\nEnglish (Preferred)\\nIndustry:\\nEducation & Instruction\\nWork Remotely:\\nNo\",\n",
       " 'Overview: To be part of with Data Science and Analytics (DSA) team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. It includes simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modelling and machine learning techniques primarily using multiple technologies and big data platforms.\\n\\nRoles and Responsibilities:\\n\\nYour primary role will be to identify and work on high-impact business problems and develop viable solutions through data analysis, predictive modelling, and advanced analytics techniques.\\n\\nExtracts data from multiple sources and creates an analytical data mart.\\n\\nPerforms statistical data analysis on large data sets, resulting in impactful insights and outcomes.\\n\\nLogically integrates information from multiple resources and effectively communicates results to department management.\\n\\nShould have in-depth experience in experimental design, sampling, feature selection, building classifiers, model selection and training, and model interpretation.\\n\\nDevelops ad hoc analyses using standard and advanced statistical techniques (e.g., regression, CHAID, factor analysis, ANOVA, clustering analysis) .\\n\\nCollaborates to implement projects, complete tasks, and fulfil plans to ensure timely and efficient analysis, modelling, evaluation and reporting.\\n\\nTemplatize best in class data-mining processes and reporting.\\n\\nPrepares written analysis and presents findings and recommendations to key business leaders. Communicate changes in business trends to c-level executives and provide guidance as to the overall impact.\\n\\nIdentifies actionable insights, suggests recommendations, and influences the direction of the business by effectively communicating results to cross functional groups.\\n\\nTeam Management:\\n\\nManaged team size of 10 associates with skillsets of data science and analytics\\n\\nQualifying Criteria:\\n\\nBE/B.Tech/M.Sc.,degree in related discipline strongly desired (Mathematics, Statistics, Operations Research)\\n\\n5+ years of relevant experience in analytics, data science and building ML models\\n\\nConceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc.\\n\\nStrong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise\\n\\nExposure to R, Python, Hive, or other open source languages preferable\\n\\nGood programming knowledge in Relational Databases (MySQL,PL/SQL) and NoSQL Databases, along with know-how about database performances.\\nPowered by JazzHR\\n0LVoiYxIZN',\n",
       " 'Two positions are currently available in Pune, India and one position is open in Sunnyvale, CA. Title seniority and salary are set to the experience level of the applicant.\\nRole and Responsibilities\\nExecute data mining projects, training and deploying models over a typical duration of 2 -12 months.\\nThe ideal candidate should be able to innovate, analyze the customer requirement, develop a solution in the time box of the project plan, execute and deploy the solution.\\nIntegrate the data mining projects embedded data mining applications in the FogHorn platform (on Docker or Android).\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications:\\nHave analyzed, trained and deployed at least three data mining models in the past. If the candidate did not directly deploy their own models, they will have worked with others who have put their models into production. The models should have been validated as robust over at least an initial time period.\\nThree years of industry work experience, developing data mining models which were deployed and used.\\nProgramming experience in Python is core using data mining related libraries like Scikit-Learn. Other relevant Python mining libraries include NumPy, SciPy and Pandas.\\nData mining algorithm experience in at least 3 algorithms within any of the bullets below:\\ndeep learning (TensorFlow, Convolutional Neural Nets (CNN) or related),\\nprediction (statistical regression, neural nets, deep learning, decision trees, SVM, ensembles),\\nclustering (k-means, DBSCAN or other) or Bayesian networks\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive:\\nSoft Skills\\nSets expectations, develops project plans and meets expectations.\\nExperience adapting technical dialogue to the right level for the audience (i.e. executives) or specific jargon for a given vertical market and job function.\\nTechnical skills\\nCommonly, candidates have a MS or Ph.D. in Computer Science, Math, Statistics or an engineering technical discipline. BS candidates with experience are considered.\\nHave managed past models in production over their full life cycle until model replacement is needed. Have developed automated model refreshing on newer data. Have developed frameworks for model automation as a prototype for product.\\nTraining or experience in Deep Learning, such as TensorFlow, Keras, PyTorch, ONNX, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network architectures. If you don’t have deep learning experience, we will train you on the job.\\nJava, Android development\\nShrinking deep learning models, optimizing to speed up execution time of scoring or inference.\\nOpenCV or other image processing tools or libraries\\nCloud computing: Google Cloud, Amazon AWS or Microsoft Azure.\\nDecision trees like XGBoost or Random Forests is helpful.\\nComplex Event Processing (CEP) or other streaming data as a data source for data mining analysis\\nTime series algorithms from ARIMA to LSTM to Digital Signal Processing (DSP).\\nBayesian Networks (BN), a.k.a. Bayesian Belief Networks (BBN) or Graphical Belief Networks (GBN)\\nExperience with PMML is of interest (see www.DMG.org).\\nVertical experience in Industrial Internet of Things (IoT) applications:\\nEnergy: Oil and Gas, HVAC energy consumption, Wind Turbines\\nManufacturing: Motors, chemical processes, tools, automotive\\nSmart Cities: Elevators, cameras on population or cars, power grid\\nTransportation: Cars, truck fleets, trains\\nHow To Apply\\nTo apply, submit a resume to careers@foghorn.io, with an email subject of either:\\n“Sunnyvale Data Scientist application <name>”, where <name> is the applicant’s name. No “<>” are needed. This assumes you are near enough to commute to Sunnyvale, CA, USA and have a work permit.\\nor “Pune Data Scientist application <name>”, if you are applying for a job in that location in Pune, India.\\nIf you want to be more competitive, address how you meet all the minimum requirements and any bonus qualifications.\\n\\nAbout FogHorn Systems\\nFogHorn is a leading developer of “edge intelligence” software for industrial and commercial IoT application solutions. FogHorn’s Lightning software platform brings the power of advanced analytics and machine learning to the on-premise edge environment enabling a new class of applications for advanced monitoring and diagnostics, machine performance optimization, proactive maintenance and operational intelligence use cases. FogHorn’s technology is ideally suited for OEMs, systems integrators and end customers in manufacturing, power and water, oil and gas, renewable energy, mining, transportation, healthcare, retail, as well as Smart Grid, Smart City, Smart Building and connected vehicle applications.\\nPress: https://www.foghorn.io/press-room/\\nAwards: https://www.foghorn.io/awards-and-recognition/\\n2020 World Economic Forum Technology Pioneer\\n2020 IoT World Awards, Best Edge Computing Solution\\n2020 Golden Bridge Awards, Most Innovative Company of the Year – AI Category\\n2020 IoT Evolution Edge Computing Excellence Award\\n2019 Edge Computing Company of the Year – Compass Intelligence\\n2019 Internet of Things 50: 10 Coolest Industrial IoT Companies – CRN\\n2018 IoT Planforms Leadership Award & Edge Computing Excellence – IoT Evolution World Magazine\\n2018 10 Hot IoT Startups to Watch – Network World. (Gartner estimated 20 billion connected things in use worldwide by 2020)\\n2018 Winner in Artificial Intelligence and Machine Learning – Globe Awards\\n2018 Ten Edge Computing Vendors to Watch – ZDNet & 451 Research\\n2018 The 10 Most Innovative AI Solution Providers – Insights Success\\n2018 The AI 100 – CB Insights\\n2017 Cool Vendor in IoT Edge Computing – Gartner\\n2017 20 Most Promising AI Service Providers – CIO Review\\nOur Series A round was for $15 million. Our Series B round was for $30 million October 2017. Investors include: Saudi Aramco Energy Ventures, Intel Capital, GE, Dell, Bosch, Honeywell and The Hive.\\nAbout the Data Science Solutions team\\nIn 2018, our Data Science Solutions team grew from 4 to 9. We are growing again from 10 t0 13. We work on revenue-generating projects for clients, such as predictive maintenance, time to failure, manufacturing defects. About half of our projects have been related to vision recognition or deep learning. We are not only working on consulting projects but developing vertical solution applications that run on our Lightning platform, with embedded data mining.\\nOur data scientists like our team because:\\nWe care about “best practices”\\nHave a direct impact on the company’s revenue\\nGive or receive mentoring as part of the collaborative process\\nQuestions and challenging the status quo with data is safe\\nIntellectual curiosity balanced with humility\\nPresent papers or projects in our “Thought Leadership” meeting series, to support continuous learning',\n",
       " \"Vacancy for Machine Learning Engineer\\n*\\nAbout Us:\\nWe are a team of talented and inspired professionals, motivated to change the world by making energy greener, and more affordable. Established in 2011 in London, we are now one of the most recognized artificial intelligence companies in the power sector with recent recognitions from the US Department of Energy and from the CleanTech Group. Our services are trusted by the largest and best performing renewable energy and distribution companies in India. In 2020, we started functioning as an independent subsidiary of the largest renewable energy generator in India, ReNew Power.\\n*\\n*\\nLike most successful start-ups, we started with just a dream: To have a global 100% renewables powered grid, at 10% of the price we pay for our energy today, with 100% reliability of supply for all. We believe that machine learning and other software technologies will be key in enabling this vision. Thus, our mission is to construct the data architecture and design algorithms that give an intelligently powered future to the world. Join us in turning this dream into a reality\\n*\\n*\\nWhat it’s really like to work here:\\nWe recognize the value that company culture plays in the recruitment process. Beyond the standard technical and experience fit, we look for individuals who will become a part of our family. When you join our team, you become a part of a strong network of brilliant and an accomplished legacy from top engineering and business schools in the world such as the Indian Institute of Technology, Oxford University, University of Cambridge, University College of London and many more.\\n*\\n*\\nWe want more people who can thrive in a collaborative team-environment. Our multi-layered support system, comprising a global network of advisors, provides unparalleled opportunities for growth and learning in a friendly environment. We don’t believe in old-fashioned hierarchies. We work in teams and give people at all levels the freedom to lead and implement projects. With flexible hours and merit-based reward systems, we offer tremendous potential for advancement.\\n*\\n*\\nYou are the person for this job, if you have these qualities:\\nResults-oriented. You can meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nCollaboration. You have the ability to work closely with other business teams in a collaborative setting.\\nCommunication skills. You are great at conveying your message to team members and other stakeholders.\\nHonesty. You work diligently and honestly. You have strong moral principles.\\nKnowledgeable. You are constantly researching and always up-to-date with all recent advancements in data sciences. You have a flair for using the right metrics to measure model performance, quality, and reliability.\\nProblem-solver. You proactively identify challenges and risks to the project and offer solutions. You demonstrate the ability to transform theoretical knowledge to practical, real-world situations.\\nCritical-thinker. You have the ability to think critically and conceptually about the role of each feature/development unit in the achievement of the product’s goals\\nExperience. You have previously worked with large databases to access, manipulate and process data.\\nWe are looking for people with knowledge of:\\nPython.\\nLibraries like Numpy, Pandas, sk-learn, tensorflow 2.0, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nMySQL, MongoDB, ElasticSearch or other NoSQL database implementations.\\nAPIs and JSON-REST. Able to access and work with various data APIs.\\nA wide set of machine learning approaches and designing the features and data processing to actually make them work.\\n*\\n*\\nWhat you’ll work on:\\n*\\n*\\nAs an ML Engineer, you will be creating a forecasting model in python for the Solar and Wind Plants by using the various Machine Learning algorithms. Ultimately, through your contribution to the renewable energy revolution, you will be doing your bit to mitigate the effects of climate change. These are a few things you can look forward to working on:\\nDeveloping and testing the forecasting algorithms using large data sets such as load whether historical, grid etc.\\nCollaborating with the team to deploy the developed model as per the client need\\nTaking responsibility for the Model development process, testing, and debugging required for deploying the models\\nCollaborating with the operations team and management to establish strategies.\\nEnsuring tracking of appropriate events/metrics, so that monitoring is timely and rigorous.\\nDriving the response to discovery of regressions or failures, by undertaking various\\nexercises (e.g. debugging, RCA, etc.)\\nStaying up-to-date on evolutions in best practice, tooling, and strategies in the ML space.\\n*\\n*\\nQualifications:\\n1-3 years of experience in the field of Data Sciences or Machine Learning\\n*\\n*\\nWhere you will work:\\nPune, Maharashtra\\nDelhi\\n*\\n*\\nRemuneration:\\nThe remuneration for this position is one of the most competitive in the market\\n*\\n*\\nHow we will select you:\\nWe will parse your CVs and if selected our HR department will connect with you and confirm your interest.\\nThere will be a two-part take home assignment.\\nThere will be three interview rounds, out of which two rounds will be technical assessment and one will be a personal interview.\\n*\\n*\\n*\\n*\\n*\\nJob Type: Full-time\\nSalary: ₹700,000.00 - ₹1,200,000.00 per year\\nSchedule:\\nDay shift\\nExperience:\\nTotal work as Machine Learning Engineer: 2 years (Required)\\nEducation:\\nBachelor's (Preferred)\\nWork Remotely:\\nTemporarily due to COVID-19\",\n",
       " 'We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\\n\\nResponsibilities:\\nDesigning and deploying deep learning algorithms and predictive models\\nDevelop custom data models and algorithms to apply to data sets\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\\nDevelop processes and tools to monitor and analyze model performance and data accuracy\\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\\n\\nQualifications:\\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\\nAbility to drive a project and work both independently and in a team',\n",
       " 'Looking for full time & part time Data Science/Machine Learning Trainers to teach in classroom(offline) in our Viman Nagar branch in Pune.\\nWe are a leading software training institute in Pune with our branches in Pimple Saudagar and Viman Nagar. We have been providing exclusive training on Data Science, Machine Learning & Artificial Intelligence since 2014.\\nIf interested, please send your updated resume to the given email id with the subject line \"Data Science Trainer\".\\nhttps://marsiantech.com/\\nMobile: 7028052110\\nJob Types: Full-time, Part-time, Contract\\nSalary: ₹240,000.00 - ₹400,000.00 per year\\nBenefits:\\nFlexible schedule\\nExperience:\\nAnalytics: 1 year (Required)\\nMachine Learning: 1 year (Required)\\nR: 1 year (Required)\\nPython: 1 year (Required)\\nLocation:\\nPune, Maharashtra (Required)\\nIndustry:\\nEducation & Instruction\\nWork Remotely:\\nNo\\nSpeak with the employer\\n+91 7028052110',\n",
       " 'Experience : 5 - 7 Years\\nJOB DESCRIPTION\\nShould have a Master’s degree in Statistics, Mathematics, Computer Science\\nResponsibilities Include:\\nInteracting with the stakeholders, within the company and the customers, to understand the needs\\nExploratory analysis from the existing data\\nFormulating the questions to be answered and hypotheses to be tested\\nIdentifying additional data to be collected and third-party data sources that will help the analysis\\nDeveloping data presentations, models and algorithms required\\nUsing data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback\\nProviding inputs and support to software / firmware developers to build the required software components, data structures and dashboards\\nInteract with other project team members to adhere to overall project schedules\\nEnsure Adherence to internal development policies and participating in continually improving existing processes\\nMandatory Technical Abilities:\\nStrong problem-solving skills with an emphasis on product development\\nExperience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets\\nExperience of working with and creating data architectures\\nExperience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)\\nExperience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)\\nProficiency in using query languages such as SQL, Hive\\nExperience with NoSql databases (MongoDB, Cassandra…)\\nKnowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications\\nGood written and verbal communication skills for coordinating across teams\\nAbility to learn and master new technologies and techniques',\n",
       " 'Job Location – Pune, India\\nRequired experience – 6-10 Years\\nAbout Innoplexus\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nLead and mentor a small team of data scientists in applying existing learning algorithms and develop new ones\\nDevelop scalable customer-facing solutions over real-world, noisy and unstructured data\\nDevelop highly scalable deep learning algorithms to improve our platform\\nDevelop state-of-the-art machine learning and neural network methodologies to improve our intelligence platform\\nCross-functional collaboration between data science and engineering teams to support the integration of finished algorithms and prototypes into product\\nSupport sales and business development teams to fine-tune client requirements, perform feasibility testing and proposing an approach for solutions\\nWe need you to have:\\nBachelors/Masters/PhD Degree in Computer Science, related Machine Learning field or equivalent from Tier-1 or premier institutes like IIT, IISc, BITS, NIT or globally renowned universities\\nKnowledge On:\\nRelevant Hands-on Experience in any of the below groups:\\nInformation Extraction, Text Mining from Unstructured data\\nComputational Genomics, Bioinformatics\\nStrong in Python programming\\nKnowledge commonly used machine learning tools:, pytorch, scikit-learn, gensim, pandas\\nExperience with major NoSQL products\\nExperience in the domain of life sciences is a plus\\nMust have experience in leading teams\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " 'Machine Learning Engineer\\nJob Description\\nA candidate is expected to understand and develop relevant Natural Language Processing and Text Extraction model as per business need.\\nThe ideal candidate must be a keen problem solver and can transform business requirements into working real-life applications\\nA candidate is expected to deliver the working solution in stringent timelines\\nMust have developed and delivered multiple NLP projects to cloud platforms in past, using DevOps\\nPast experience of Hackathon participation will be an added advantage\\nRequirements\\nIn-depth knowledge of Python, NumPy, Pandas, and other Python packages\\nExceptional command on entity extraction from unstructured data using NLTK, SpaCy, BERT, PyTorch, and other packages\\nWell versed with deep learning algorithms and text analytics tools like RNN, LSTM, word2vec, Glove, Keras, TensorFlow, and so on.\\nExposure to Python Django or Python Flask\\nKnowledge of Docker, GitHub, MongoDB, and AWS will be an added advantage\\nConversant with Agile, Scrum methodologies\\nProven, in-depth understanding of ML algorithms and modeling including supervised, and unsupervised learning models\\nPost Date: 25 Sep 2020\\nLocation: Pune, India\\nJob Type: Information Technology\\nContact us at indiahr@brightleaf.com',\n",
       " 'Machine Learning: Classification, Regression, Clustering, Decision Tree, K-Means Clustering, Naïve Bayes.\\nStatistical Methods: Predictive Analysis, Hypothesis Testing and Confidence interval, Principal Component Analysis & Dimensionality Reduction, Market Basket Analysis, Text Analytics, Sampling, Bootstrap, Cross Validation.\\nProgramming Languages: R, Python\\nScripting Language: Linux\\nData Reporting Tool: Tableau\\nTelecom domain exp.\\n\\n10.00-15.00 Years\\nBachelor Of Technology (B.Tech/B.E), Master in Computer Application (M.C.A), Masters in Technology (M.Tech/M.E/M.Sc)',\n",
       " 'Job Background/context:\\n1. Candidate should have around 8-12 years development & systems design experience\\n2. More than 5 years of experience in BigData technologies like spark, python & Java with minimum 2 years experience in Data Science or certified candidate from a prominent institute who can demonstrate good skills in Data Science.\\n3. Proven proactive problems identification & rapid trouble-shooting skills.\\n4. Candidate with Trade Surveillance domain experience will be preferred\\nKey Responsibilities:\\nThe right candidate will be expected to be a significant player in the project evolution & deployment shouldering the following responsibilities:\\nWork as a collaborative member of a team spread over multiple locations (India, UK, US)\\nUnderstand internally published architectural guidelines to design solutions and represent them in architectural reviews.\\nDefine & communicate development standards that follow established architectural designs and perform code reviews to ensure quality standards of systems & team.\\nLead by example in developing exceptional quality code by doing design & code reviews.\\nDesign & develop platform functionality that is scalable & configurable as a global platform.\\nSkills:\\nMandatory Skills:\\nStrong knowledge in Spark ,Java/Python.\\nStrong experience in Hive/SQL, PL/SQL\\nGood Experience in Data Science , Unix Shell Scripting\\nDesirable Skills:\\nTrade Life cycle\\nMarket data systems\\nOther skills & Qualifications:\\nBachelor’s degree in engineering or masters degree in Maths, physics\\nCandidate should be willing to work late in the evening India time on need basis in order to interact with US/UK onshore team and to meet urgent requests by Clients.\\nExhibit sound and comprehensive communication and diplomacy skills to exchange complex information\\nAct as advisor or coach to new or lower level analysts;\\nOrganizational and project management skills required\\nStrong influencing & interpersonal skills.\\nDevelopment Value:\\nOpportunities for career growth within a Surveillance domain that is expanding\\nHands-on design and development experience including experience on a production implementation of Hadoop with massive data volumes and unstructured data sets\\nInvolve and lead projects involving complex feature-based data algorithms and machine learning\\nExposure to communication surveillance functions in a dynamic and challenging industry with regular close collaboration with our surveillance portfolio clients\\nA team with a win-together/lose-together attitude and strong sense of identity and positive culture\\n-\\nJob Family Group:\\nTechnology\\n-\\nJob Family:\\nApplications Development\\n-\\nTime Type:\\nFull time\\n-\\nCiti is an equal opportunity and affirmative action employer.\\nQualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\nCitigroup Inc. and its subsidiaries (\"Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\\nView the \"EEO is the Law\" poster. View the EEO is the Law Supplement.\\nView the EEO Policy Statement.\\nView the Pay Transparency Posting',\n",
       " 'Title:\\nData ScientistUnder general supervision, independently applies advanced engineering techniques, makes decisions on engineering problems and methods, and represents the organization in conferences to resolve important questions or to negotiate with key engineers and officials of other organizations. Provides technical guidance to designers and less experienced engineers and is consulted extensively by associates and others with a high degree of reliance placed on scientific interpretations and advice. Job role is responsible for a measurable asset such as an assigned staff and budget. Skills are typically acquired through an undergraduate degree in Engineering and a minimum of 7 years related experience, with average experience ranging from 10+ years.\\nScheduled Weekly Hours:\\n40',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\n\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Ecolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nEcolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nOur Commitment to Diversity and Inclusion\\nAt Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.\\nIn addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.',\n",
       " \"Company Description\\nDemandMatrix Inc. is a data company that provides Go To Market, Operations and Data Science teams with high quality company level data and intelligence. DemandMatrix uses advanced data science methodologies to process millions of unstructured data points that produce reliable and accurate technology intelligence, organizational intent and B2B spend data.\\n\\nJob Description\\nWe are looking for a Lead Data Scientist to lead a technical team to discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus is to work with the team to drive multiple initiatives for applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products in the domain of technographics and problems like buyer's journey, Technology Adoption Models (TAM)\\nResponsibilities:\\nRun CRISP-DM projects with a team of 3 data scientists in the following -\\nSelecting features, building and optimizing classifiers (logistic regression or RF based propensity models) and recommenders using machine learning techniques\\nData mining using state-of-the-art methods - Automate scoring using machine learning techniques, build recommendation systems, improve and extend the features used by recommendation and propensity modeling algos,\\nExtending company’s data with third party sources of information when needed\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis and perform deep EDA (we create our own training data for our models)\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating recommended and propensity models and tracking of its performance especially to compensate for concept drift\\n\\nQualifications\\nHands on machine learning techniques and algorithms, such as k-NN, Naive Bayes, Ensemble methods XGBoost, Decision Forests and working towards deep learning methods using TensorFlow especially for NLP like word embeddings and topic discovery\\nHands with common data science toolkits, such as Python, scikit learn, numpy, pandas, plotly, TensorFlow, ElasticSearch, Auto-ML platforms like AWS Sagemaker\\nSolid proficiency in using query languages such as SQL, Experience with NoSQL databases, such as Elasticsearch and Graph DBs as Neo4j\\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression and strong EDA skills\\nData-oriented personality with strong sense of appreciating the business domain of your work e.g.\\nInterest in working in tech domain e.g. data center analytics, understanding of macro factors in market for computing, software and cloud adoptions\\nExperience of 5+ years\\n\\nAdditional Information\\nFlexible Working hours\\nEntire Work From Home\\nBirthday Leave\\nRemote Work\",\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'About Us\\nBlueshift is a venture-funded startup headquartered in San Francisco, USA. Our AI-Powered marketing platform empowers cutting edge B2C brands to drive 1:1 marketing on every channel. With Blueshift, marketers are in full control of automating various forms of personalized messaging across every engagement channel.\\nBlueshift is trusted by leading digital brands like Udacity, Discovery, Live Nation, LendingTree, BBC, and Paypal to automate their customer engagement marketing and recognized by Gartner as a \"Cool Vendor for AI in Marketing\".\\nBlueshift is founded by repeat entrepreneurs who previously built Mertado.com (acquired by Groupon to become Groupon Goods), and were part of the early team behind Kosmix (acquired by Walmart to become @WalmartLabs). We are backed by top-tier VCs including Nexus Venture Partners, Storm Ventures, Luma Partners, and SoftBank Venture Asia.\\nBlueshift is staffing its development center in Pune, India. As part of Blueshift, you will get to work on cutting-edge technologies including machine learning, artificial intelligence, big data, and large-scale distributed data systems. This is an exciting opportunity for motivated individuals to build a great career.\\nResponsibilities\\nAs an AI Solutions Engineer in the Data Science team, you will be responsible to understand and communicate with customers personalization and predictive scoring use cases and implement them within Blueshift platform. You will help the clients realize full power of machine learning and AI modules. You will be the interface between the customer and the data scientists and data engineers.\\nWork with customer representatives - mainly marketers in mid to large enterprises - to design, develop and deploy creative marketing campaigns using AI.\\nImplement and define AI configurations and code and translate client campaign ideas in to workable solutions.\\nWork with data scientists to design experiments and benchmark AI results.\\nRequirements\\nAt least 4 years of industry experience in software development with at least 2 years of experience working with customers directly\\nExcellent spoken and written communication skills and ability to interact with customers\\nStrong proficiency with SQL and database systems - demonstrated ability to handle complex data analysis\\nProven programming skills with scripting languages like python or ruby\\nPreferred\\nKnowledge of modern machine learning algorithms\\nPrior experience working on large scale data sets\\nPerks and Benefits\\nOpportunity to be part of the early team in India\\nCompetitive salary along with stock option grants\\nExcellent hospitalisation, personal accident, and term insurance coverage\\nLocated in a top-notch facility in Baner - one of the best neighbourhoods for tech startups\\nDaily catered breakfast, lunch, and snacks along with well-stocked pantry',\n",
       " 'Pune\\n\\nHands-on experience with Computer Vision/Deep Learning/Neural\\nnetworks is must.\\nMinimum 3-7 years experience\\nDeep knowledge of Algorithm & data structure design is required\\nGood understanding of Linear Algebra, Calculus and Fundamentals\\nof Mathematics is required\\nExpertise in Python (Tensorflow, Keras, Torch or MxNet) is\\nrequired\\nExperience with Mysql, MongoDB, Elasticsearch, Docker would be\\nan advantage\\nIf you have published research papers, Please share the details\\nIf you have GitHub repo, Please share the details\\nExperience\\n3 - 7 Years\\n\\nSalary\\n5 Lac To 10 Lac P.A.\\n\\nIndustry\\nIT Software - Application Programming / Maintenance\\n\\nQualification\\nPh.D/Doctorate\\n\\nKey Skills\\nASP.NET SQL Server Software Development C++ Java Developer HTML5 Developer Dot Net Developer Python Developer\\n\\n\\nAbout Company\\nContact Person\\nMr. D.M.Patil\\n\\nAddress\\n600, Krushna Business Centre,1st Floor, Behind Sai Service Petrol Pump\\n\\nMobile\\n9579239323\\n\\nEmail ID\\nvijayamgmt@gmail.com',\n",
       " 'As a Data Scientist, you will be responsible for analyzing the large complex data, with the use of advanced statistical analysis, data mining, and data visualization techniques, to give key insights to the product team to enhance business performance. They will also prepare reports and presentations for the management which will give insights for business wide decision making.\\nResponsibilities\\nCollaborate with a multi-disciplinary, data-driven team to leverage key performance metrics to improve game performance;\\nDevelop and publish analysis reports for internal use, including segmentation of audience & user behavior;\\nSet-up and monitor dashboards and assess the performance of the game, including monetization and engagement;\\nCommunicate to stakeholders the performance of the game via reports and ad-hoc analysis;\\nGather business needs and document tracking requirements;\\nParticipate in the design and development of a successful product;\\nSupport the optimization of the game performance with the Product Team.\\nQualifications\\nBachelor’s degree (preferably in a quantitative field);\\nMinimum 2 years of experience in the video game industry;\\nMinimum 5 years of experience in a related field, such as digital marketing, e-commerce, business intelligence, sports analysis etc;\\nExcellent communication skills and ability to synthesize key information to stakeholders and senior management;\\nExperience working on multi-disciplinary teams in a dynamic environment;\\nExperience working with big data, including manipulation and analysis;\\nExperience with database systems is preferred but not required;\\nExpertise in Excel;\\nExperience with reporting tools (e.g. Tableau, R) and analytics platforms such as Google Analytics, Firebase, Flurry, deltaDNA, etc;\\nKnowledge of the video game industry, including freemium games concepts;\\nDemonstrate strong learning abilities as well as humility;\\nPassion for mobile games!!',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " 'Machine Learning Engineer\\nJob Description\\nA candidate is expected to understand and develop relevant Natural Language Processing and Text Extraction model as per business need.\\nThe ideal candidate must be a keen problem solver and can transform business requirements into working real-life applications\\nA candidate is expected to deliver the working solution in stringent timelines\\nMust have developed and delivered multiple NLP projects to cloud platforms in past, using DevOps\\nPast experience of Hackathon participation will be an added advantage\\nRequirements\\nIn-depth knowledge of Python, NumPy, Pandas, and other Python packages\\nExceptional command on entity extraction from unstructured data using NLTK, SpaCy, BERT, PyTorch, and other packages\\nWell versed with deep learning algorithms and text analytics tools like RNN, LSTM, word2vec, Glove, Keras, TensorFlow, and so on.\\nExposure to Python Django or Python Flask\\nKnowledge of Docker, GitHub, MongoDB, and AWS will be an added advantage\\nConversant with Agile, Scrum methodologies\\nProven, in-depth understanding of ML algorithms and modeling including supervised, and unsupervised learning models\\nPost Date: 25 Sep 2020\\nLocation: Pune, India\\nJob Type: Information Technology\\nContact us at indiahr@brightleaf.com',\n",
       " 'Machine Learning: Classification, Regression, Clustering, Decision Tree, K-Means Clustering, Naïve Bayes.\\nStatistical Methods: Predictive Analysis, Hypothesis Testing and Confidence interval, Principal Component Analysis & Dimensionality Reduction, Market Basket Analysis, Text Analytics, Sampling, Bootstrap, Cross Validation.\\nProgramming Languages: R, Python\\nScripting Language: Linux\\nData Reporting Tool: Tableau\\nTelecom domain exp.\\n\\n10.00-15.00 Years\\nBachelor Of Technology (B.Tech/B.E), Master in Computer Application (M.C.A), Masters in Technology (M.Tech/M.E/M.Sc)',\n",
       " 'Job Background/context:\\n1. Candidate should have around 8-12 years development & systems design experience\\n2. More than 5 years of experience in BigData technologies like spark, python & Java with minimum 2 years experience in Data Science or certified candidate from a prominent institute who can demonstrate good skills in Data Science.\\n3. Proven proactive problems identification & rapid trouble-shooting skills.\\n4. Candidate with Trade Surveillance domain experience will be preferred\\nKey Responsibilities:\\nThe right candidate will be expected to be a significant player in the project evolution & deployment shouldering the following responsibilities:\\nWork as a collaborative member of a team spread over multiple locations (India, UK, US)\\nUnderstand internally published architectural guidelines to design solutions and represent them in architectural reviews.\\nDefine & communicate development standards that follow established architectural designs and perform code reviews to ensure quality standards of systems & team.\\nLead by example in developing exceptional quality code by doing design & code reviews.\\nDesign & develop platform functionality that is scalable & configurable as a global platform.\\nSkills:\\nMandatory Skills:\\nStrong knowledge in Spark ,Java/Python.\\nStrong experience in Hive/SQL, PL/SQL\\nGood Experience in Data Science , Unix Shell Scripting\\nDesirable Skills:\\nTrade Life cycle\\nMarket data systems\\nOther skills & Qualifications:\\nBachelor’s degree in engineering or masters degree in Maths, physics\\nCandidate should be willing to work late in the evening India time on need basis in order to interact with US/UK onshore team and to meet urgent requests by Clients.\\nExhibit sound and comprehensive communication and diplomacy skills to exchange complex information\\nAct as advisor or coach to new or lower level analysts;\\nOrganizational and project management skills required\\nStrong influencing & interpersonal skills.\\nDevelopment Value:\\nOpportunities for career growth within a Surveillance domain that is expanding\\nHands-on design and development experience including experience on a production implementation of Hadoop with massive data volumes and unstructured data sets\\nInvolve and lead projects involving complex feature-based data algorithms and machine learning\\nExposure to communication surveillance functions in a dynamic and challenging industry with regular close collaboration with our surveillance portfolio clients\\nA team with a win-together/lose-together attitude and strong sense of identity and positive culture\\n-\\nJob Family Group:\\nTechnology\\n-\\nJob Family:\\nApplications Development\\n-\\nTime Type:\\nFull time\\n-\\nCiti is an equal opportunity and affirmative action employer.\\nQualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\nCitigroup Inc. and its subsidiaries (\"Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\\nView the \"EEO is the Law\" poster. View the EEO is the Law Supplement.\\nView the EEO Policy Statement.\\nView the Pay Transparency Posting',\n",
       " 'Title:\\nData ScientistUnder general supervision, independently applies advanced engineering techniques, makes decisions on engineering problems and methods, and represents the organization in conferences to resolve important questions or to negotiate with key engineers and officials of other organizations. Provides technical guidance to designers and less experienced engineers and is consulted extensively by associates and others with a high degree of reliance placed on scientific interpretations and advice. Job role is responsible for a measurable asset such as an assigned staff and budget. Skills are typically acquired through an undergraduate degree in Engineering and a minimum of 7 years related experience, with average experience ranging from 10+ years.\\nScheduled Weekly Hours:\\n40',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\n\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Ecolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nEcolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nOur Commitment to Diversity and Inclusion\\nAt Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.\\nIn addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.',\n",
       " \"Company Description\\nDemandMatrix Inc. is a data company that provides Go To Market, Operations and Data Science teams with high quality company level data and intelligence. DemandMatrix uses advanced data science methodologies to process millions of unstructured data points that produce reliable and accurate technology intelligence, organizational intent and B2B spend data.\\n\\nJob Description\\nWe are looking for a Lead Data Scientist to lead a technical team to discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus is to work with the team to drive multiple initiatives for applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products in the domain of technographics and problems like buyer's journey, Technology Adoption Models (TAM)\\nResponsibilities:\\nRun CRISP-DM projects with a team of 3 data scientists in the following -\\nSelecting features, building and optimizing classifiers (logistic regression or RF based propensity models) and recommenders using machine learning techniques\\nData mining using state-of-the-art methods - Automate scoring using machine learning techniques, build recommendation systems, improve and extend the features used by recommendation and propensity modeling algos,\\nExtending company’s data with third party sources of information when needed\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis and perform deep EDA (we create our own training data for our models)\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating recommended and propensity models and tracking of its performance especially to compensate for concept drift\\n\\nQualifications\\nHands on machine learning techniques and algorithms, such as k-NN, Naive Bayes, Ensemble methods XGBoost, Decision Forests and working towards deep learning methods using TensorFlow especially for NLP like word embeddings and topic discovery\\nHands with common data science toolkits, such as Python, scikit learn, numpy, pandas, plotly, TensorFlow, ElasticSearch, Auto-ML platforms like AWS Sagemaker\\nSolid proficiency in using query languages such as SQL, Experience with NoSQL databases, such as Elasticsearch and Graph DBs as Neo4j\\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression and strong EDA skills\\nData-oriented personality with strong sense of appreciating the business domain of your work e.g.\\nInterest in working in tech domain e.g. data center analytics, understanding of macro factors in market for computing, software and cloud adoptions\\nExperience of 5+ years\\n\\nAdditional Information\\nFlexible Working hours\\nEntire Work From Home\\nBirthday Leave\\nRemote Work\",\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'About Us\\nBlueshift is a venture-funded startup headquartered in San Francisco, USA. Our AI-Powered marketing platform empowers cutting edge B2C brands to drive 1:1 marketing on every channel. With Blueshift, marketers are in full control of automating various forms of personalized messaging across every engagement channel.\\nBlueshift is trusted by leading digital brands like Udacity, Discovery, Live Nation, LendingTree, BBC, and Paypal to automate their customer engagement marketing and recognized by Gartner as a \"Cool Vendor for AI in Marketing\".\\nBlueshift is founded by repeat entrepreneurs who previously built Mertado.com (acquired by Groupon to become Groupon Goods), and were part of the early team behind Kosmix (acquired by Walmart to become @WalmartLabs). We are backed by top-tier VCs including Nexus Venture Partners, Storm Ventures, Luma Partners, and SoftBank Venture Asia.\\nBlueshift is staffing its development center in Pune, India. As part of Blueshift, you will get to work on cutting-edge technologies including machine learning, artificial intelligence, big data, and large-scale distributed data systems. This is an exciting opportunity for motivated individuals to build a great career.\\nResponsibilities\\nAs an AI Solutions Engineer in the Data Science team, you will be responsible to understand and communicate with customers personalization and predictive scoring use cases and implement them within Blueshift platform. You will help the clients realize full power of machine learning and AI modules. You will be the interface between the customer and the data scientists and data engineers.\\nWork with customer representatives - mainly marketers in mid to large enterprises - to design, develop and deploy creative marketing campaigns using AI.\\nImplement and define AI configurations and code and translate client campaign ideas in to workable solutions.\\nWork with data scientists to design experiments and benchmark AI results.\\nRequirements\\nAt least 4 years of industry experience in software development with at least 2 years of experience working with customers directly\\nExcellent spoken and written communication skills and ability to interact with customers\\nStrong proficiency with SQL and database systems - demonstrated ability to handle complex data analysis\\nProven programming skills with scripting languages like python or ruby\\nPreferred\\nKnowledge of modern machine learning algorithms\\nPrior experience working on large scale data sets\\nPerks and Benefits\\nOpportunity to be part of the early team in India\\nCompetitive salary along with stock option grants\\nExcellent hospitalisation, personal accident, and term insurance coverage\\nLocated in a top-notch facility in Baner - one of the best neighbourhoods for tech startups\\nDaily catered breakfast, lunch, and snacks along with well-stocked pantry',\n",
       " 'Pune\\n\\nHands-on experience with Computer Vision/Deep Learning/Neural\\nnetworks is must.\\nMinimum 3-7 years experience\\nDeep knowledge of Algorithm & data structure design is required\\nGood understanding of Linear Algebra, Calculus and Fundamentals\\nof Mathematics is required\\nExpertise in Python (Tensorflow, Keras, Torch or MxNet) is\\nrequired\\nExperience with Mysql, MongoDB, Elasticsearch, Docker would be\\nan advantage\\nIf you have published research papers, Please share the details\\nIf you have GitHub repo, Please share the details\\nExperience\\n3 - 7 Years\\n\\nSalary\\n5 Lac To 10 Lac P.A.\\n\\nIndustry\\nIT Software - Application Programming / Maintenance\\n\\nQualification\\nPh.D/Doctorate\\n\\nKey Skills\\nASP.NET SQL Server Software Development C++ Java Developer HTML5 Developer Dot Net Developer Python Developer\\n\\n\\nAbout Company\\nContact Person\\nMr. D.M.Patil\\n\\nAddress\\n600, Krushna Business Centre,1st Floor, Behind Sai Service Petrol Pump\\n\\nMobile\\n9579239323\\n\\nEmail ID\\nvijayamgmt@gmail.com',\n",
       " 'As a Data Scientist, you will be responsible for analyzing the large complex data, with the use of advanced statistical analysis, data mining, and data visualization techniques, to give key insights to the product team to enhance business performance. They will also prepare reports and presentations for the management which will give insights for business wide decision making.\\nResponsibilities\\nCollaborate with a multi-disciplinary, data-driven team to leverage key performance metrics to improve game performance;\\nDevelop and publish analysis reports for internal use, including segmentation of audience & user behavior;\\nSet-up and monitor dashboards and assess the performance of the game, including monetization and engagement;\\nCommunicate to stakeholders the performance of the game via reports and ad-hoc analysis;\\nGather business needs and document tracking requirements;\\nParticipate in the design and development of a successful product;\\nSupport the optimization of the game performance with the Product Team.\\nQualifications\\nBachelor’s degree (preferably in a quantitative field);\\nMinimum 2 years of experience in the video game industry;\\nMinimum 5 years of experience in a related field, such as digital marketing, e-commerce, business intelligence, sports analysis etc;\\nExcellent communication skills and ability to synthesize key information to stakeholders and senior management;\\nExperience working on multi-disciplinary teams in a dynamic environment;\\nExperience working with big data, including manipulation and analysis;\\nExperience with database systems is preferred but not required;\\nExpertise in Excel;\\nExperience with reporting tools (e.g. Tableau, R) and analytics platforms such as Google Analytics, Firebase, Flurry, deltaDNA, etc;\\nKnowledge of the video game industry, including freemium games concepts;\\nDemonstrate strong learning abilities as well as humility;\\nPassion for mobile games!!',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " 'Machine Learning Engineer\\nJob Description\\nA candidate is expected to understand and develop relevant Natural Language Processing and Text Extraction model as per business need.\\nThe ideal candidate must be a keen problem solver and can transform business requirements into working real-life applications\\nA candidate is expected to deliver the working solution in stringent timelines\\nMust have developed and delivered multiple NLP projects to cloud platforms in past, using DevOps\\nPast experience of Hackathon participation will be an added advantage\\nRequirements\\nIn-depth knowledge of Python, NumPy, Pandas, and other Python packages\\nExceptional command on entity extraction from unstructured data using NLTK, SpaCy, BERT, PyTorch, and other packages\\nWell versed with deep learning algorithms and text analytics tools like RNN, LSTM, word2vec, Glove, Keras, TensorFlow, and so on.\\nExposure to Python Django or Python Flask\\nKnowledge of Docker, GitHub, MongoDB, and AWS will be an added advantage\\nConversant with Agile, Scrum methodologies\\nProven, in-depth understanding of ML algorithms and modeling including supervised, and unsupervised learning models\\nPost Date: 25 Sep 2020\\nLocation: Pune, India\\nJob Type: Information Technology\\nContact us at indiahr@brightleaf.com',\n",
       " 'Machine Learning: Classification, Regression, Clustering, Decision Tree, K-Means Clustering, Naïve Bayes.\\nStatistical Methods: Predictive Analysis, Hypothesis Testing and Confidence interval, Principal Component Analysis & Dimensionality Reduction, Market Basket Analysis, Text Analytics, Sampling, Bootstrap, Cross Validation.\\nProgramming Languages: R, Python\\nScripting Language: Linux\\nData Reporting Tool: Tableau\\nTelecom domain exp.\\n\\n10.00-15.00 Years\\nBachelor Of Technology (B.Tech/B.E), Master in Computer Application (M.C.A), Masters in Technology (M.Tech/M.E/M.Sc)',\n",
       " 'Job Background/context:\\n1. Candidate should have around 8-12 years development & systems design experience\\n2. More than 5 years of experience in BigData technologies like spark, python & Java with minimum 2 years experience in Data Science or certified candidate from a prominent institute who can demonstrate good skills in Data Science.\\n3. Proven proactive problems identification & rapid trouble-shooting skills.\\n4. Candidate with Trade Surveillance domain experience will be preferred\\nKey Responsibilities:\\nThe right candidate will be expected to be a significant player in the project evolution & deployment shouldering the following responsibilities:\\nWork as a collaborative member of a team spread over multiple locations (India, UK, US)\\nUnderstand internally published architectural guidelines to design solutions and represent them in architectural reviews.\\nDefine & communicate development standards that follow established architectural designs and perform code reviews to ensure quality standards of systems & team.\\nLead by example in developing exceptional quality code by doing design & code reviews.\\nDesign & develop platform functionality that is scalable & configurable as a global platform.\\nSkills:\\nMandatory Skills:\\nStrong knowledge in Spark ,Java/Python.\\nStrong experience in Hive/SQL, PL/SQL\\nGood Experience in Data Science , Unix Shell Scripting\\nDesirable Skills:\\nTrade Life cycle\\nMarket data systems\\nOther skills & Qualifications:\\nBachelor’s degree in engineering or masters degree in Maths, physics\\nCandidate should be willing to work late in the evening India time on need basis in order to interact with US/UK onshore team and to meet urgent requests by Clients.\\nExhibit sound and comprehensive communication and diplomacy skills to exchange complex information\\nAct as advisor or coach to new or lower level analysts;\\nOrganizational and project management skills required\\nStrong influencing & interpersonal skills.\\nDevelopment Value:\\nOpportunities for career growth within a Surveillance domain that is expanding\\nHands-on design and development experience including experience on a production implementation of Hadoop with massive data volumes and unstructured data sets\\nInvolve and lead projects involving complex feature-based data algorithms and machine learning\\nExposure to communication surveillance functions in a dynamic and challenging industry with regular close collaboration with our surveillance portfolio clients\\nA team with a win-together/lose-together attitude and strong sense of identity and positive culture\\n-\\nJob Family Group:\\nTechnology\\n-\\nJob Family:\\nApplications Development\\n-\\nTime Type:\\nFull time\\n-\\nCiti is an equal opportunity and affirmative action employer.\\nQualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\nCitigroup Inc. and its subsidiaries (\"Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\\nView the \"EEO is the Law\" poster. View the EEO is the Law Supplement.\\nView the EEO Policy Statement.\\nView the Pay Transparency Posting',\n",
       " 'Title:\\nData ScientistUnder general supervision, independently applies advanced engineering techniques, makes decisions on engineering problems and methods, and represents the organization in conferences to resolve important questions or to negotiate with key engineers and officials of other organizations. Provides technical guidance to designers and less experienced engineers and is consulted extensively by associates and others with a high degree of reliance placed on scientific interpretations and advice. Job role is responsible for a measurable asset such as an assigned staff and budget. Skills are typically acquired through an undergraduate degree in Engineering and a minimum of 7 years related experience, with average experience ranging from 10+ years.\\nScheduled Weekly Hours:\\n40',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\n\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Ecolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nEcolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nOur Commitment to Diversity and Inclusion\\nAt Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.\\nIn addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.',\n",
       " \"Company Description\\nDemandMatrix Inc. is a data company that provides Go To Market, Operations and Data Science teams with high quality company level data and intelligence. DemandMatrix uses advanced data science methodologies to process millions of unstructured data points that produce reliable and accurate technology intelligence, organizational intent and B2B spend data.\\n\\nJob Description\\nWe are looking for a Lead Data Scientist to lead a technical team to discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus is to work with the team to drive multiple initiatives for applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products in the domain of technographics and problems like buyer's journey, Technology Adoption Models (TAM)\\nResponsibilities:\\nRun CRISP-DM projects with a team of 3 data scientists in the following -\\nSelecting features, building and optimizing classifiers (logistic regression or RF based propensity models) and recommenders using machine learning techniques\\nData mining using state-of-the-art methods - Automate scoring using machine learning techniques, build recommendation systems, improve and extend the features used by recommendation and propensity modeling algos,\\nExtending company’s data with third party sources of information when needed\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis and perform deep EDA (we create our own training data for our models)\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating recommended and propensity models and tracking of its performance especially to compensate for concept drift\\n\\nQualifications\\nHands on machine learning techniques and algorithms, such as k-NN, Naive Bayes, Ensemble methods XGBoost, Decision Forests and working towards deep learning methods using TensorFlow especially for NLP like word embeddings and topic discovery\\nHands with common data science toolkits, such as Python, scikit learn, numpy, pandas, plotly, TensorFlow, ElasticSearch, Auto-ML platforms like AWS Sagemaker\\nSolid proficiency in using query languages such as SQL, Experience with NoSQL databases, such as Elasticsearch and Graph DBs as Neo4j\\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression and strong EDA skills\\nData-oriented personality with strong sense of appreciating the business domain of your work e.g.\\nInterest in working in tech domain e.g. data center analytics, understanding of macro factors in market for computing, software and cloud adoptions\\nExperience of 5+ years\\n\\nAdditional Information\\nFlexible Working hours\\nEntire Work From Home\\nBirthday Leave\\nRemote Work\",\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'About Us\\nBlueshift is a venture-funded startup headquartered in San Francisco, USA. Our AI-Powered marketing platform empowers cutting edge B2C brands to drive 1:1 marketing on every channel. With Blueshift, marketers are in full control of automating various forms of personalized messaging across every engagement channel.\\nBlueshift is trusted by leading digital brands like Udacity, Discovery, Live Nation, LendingTree, BBC, and Paypal to automate their customer engagement marketing and recognized by Gartner as a \"Cool Vendor for AI in Marketing\".\\nBlueshift is founded by repeat entrepreneurs who previously built Mertado.com (acquired by Groupon to become Groupon Goods), and were part of the early team behind Kosmix (acquired by Walmart to become @WalmartLabs). We are backed by top-tier VCs including Nexus Venture Partners, Storm Ventures, Luma Partners, and SoftBank Venture Asia.\\nBlueshift is staffing its development center in Pune, India. As part of Blueshift, you will get to work on cutting-edge technologies including machine learning, artificial intelligence, big data, and large-scale distributed data systems. This is an exciting opportunity for motivated individuals to build a great career.\\nResponsibilities\\nAs an AI Solutions Engineer in the Data Science team, you will be responsible to understand and communicate with customers personalization and predictive scoring use cases and implement them within Blueshift platform. You will help the clients realize full power of machine learning and AI modules. You will be the interface between the customer and the data scientists and data engineers.\\nWork with customer representatives - mainly marketers in mid to large enterprises - to design, develop and deploy creative marketing campaigns using AI.\\nImplement and define AI configurations and code and translate client campaign ideas in to workable solutions.\\nWork with data scientists to design experiments and benchmark AI results.\\nRequirements\\nAt least 4 years of industry experience in software development with at least 2 years of experience working with customers directly\\nExcellent spoken and written communication skills and ability to interact with customers\\nStrong proficiency with SQL and database systems - demonstrated ability to handle complex data analysis\\nProven programming skills with scripting languages like python or ruby\\nPreferred\\nKnowledge of modern machine learning algorithms\\nPrior experience working on large scale data sets\\nPerks and Benefits\\nOpportunity to be part of the early team in India\\nCompetitive salary along with stock option grants\\nExcellent hospitalisation, personal accident, and term insurance coverage\\nLocated in a top-notch facility in Baner - one of the best neighbourhoods for tech startups\\nDaily catered breakfast, lunch, and snacks along with well-stocked pantry',\n",
       " 'Pune\\n\\nHands-on experience with Computer Vision/Deep Learning/Neural\\nnetworks is must.\\nMinimum 3-7 years experience\\nDeep knowledge of Algorithm & data structure design is required\\nGood understanding of Linear Algebra, Calculus and Fundamentals\\nof Mathematics is required\\nExpertise in Python (Tensorflow, Keras, Torch or MxNet) is\\nrequired\\nExperience with Mysql, MongoDB, Elasticsearch, Docker would be\\nan advantage\\nIf you have published research papers, Please share the details\\nIf you have GitHub repo, Please share the details\\nExperience\\n3 - 7 Years\\n\\nSalary\\n5 Lac To 10 Lac P.A.\\n\\nIndustry\\nIT Software - Application Programming / Maintenance\\n\\nQualification\\nPh.D/Doctorate\\n\\nKey Skills\\nASP.NET SQL Server Software Development C++ Java Developer HTML5 Developer Dot Net Developer Python Developer\\n\\n\\nAbout Company\\nContact Person\\nMr. D.M.Patil\\n\\nAddress\\n600, Krushna Business Centre,1st Floor, Behind Sai Service Petrol Pump\\n\\nMobile\\n9579239323\\n\\nEmail ID\\nvijayamgmt@gmail.com',\n",
       " 'As a Data Scientist, you will be responsible for analyzing the large complex data, with the use of advanced statistical analysis, data mining, and data visualization techniques, to give key insights to the product team to enhance business performance. They will also prepare reports and presentations for the management which will give insights for business wide decision making.\\nResponsibilities\\nCollaborate with a multi-disciplinary, data-driven team to leverage key performance metrics to improve game performance;\\nDevelop and publish analysis reports for internal use, including segmentation of audience & user behavior;\\nSet-up and monitor dashboards and assess the performance of the game, including monetization and engagement;\\nCommunicate to stakeholders the performance of the game via reports and ad-hoc analysis;\\nGather business needs and document tracking requirements;\\nParticipate in the design and development of a successful product;\\nSupport the optimization of the game performance with the Product Team.\\nQualifications\\nBachelor’s degree (preferably in a quantitative field);\\nMinimum 2 years of experience in the video game industry;\\nMinimum 5 years of experience in a related field, such as digital marketing, e-commerce, business intelligence, sports analysis etc;\\nExcellent communication skills and ability to synthesize key information to stakeholders and senior management;\\nExperience working on multi-disciplinary teams in a dynamic environment;\\nExperience working with big data, including manipulation and analysis;\\nExperience with database systems is preferred but not required;\\nExpertise in Excel;\\nExperience with reporting tools (e.g. Tableau, R) and analytics platforms such as Google Analytics, Firebase, Flurry, deltaDNA, etc;\\nKnowledge of the video game industry, including freemium games concepts;\\nDemonstrate strong learning abilities as well as humility;\\nPassion for mobile games!!',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " 'Machine Learning Engineer\\nJob Description\\nA candidate is expected to understand and develop relevant Natural Language Processing and Text Extraction model as per business need.\\nThe ideal candidate must be a keen problem solver and can transform business requirements into working real-life applications\\nA candidate is expected to deliver the working solution in stringent timelines\\nMust have developed and delivered multiple NLP projects to cloud platforms in past, using DevOps\\nPast experience of Hackathon participation will be an added advantage\\nRequirements\\nIn-depth knowledge of Python, NumPy, Pandas, and other Python packages\\nExceptional command on entity extraction from unstructured data using NLTK, SpaCy, BERT, PyTorch, and other packages\\nWell versed with deep learning algorithms and text analytics tools like RNN, LSTM, word2vec, Glove, Keras, TensorFlow, and so on.\\nExposure to Python Django or Python Flask\\nKnowledge of Docker, GitHub, MongoDB, and AWS will be an added advantage\\nConversant with Agile, Scrum methodologies\\nProven, in-depth understanding of ML algorithms and modeling including supervised, and unsupervised learning models\\nPost Date: 25 Sep 2020\\nLocation: Pune, India\\nJob Type: Information Technology\\nContact us at indiahr@brightleaf.com',\n",
       " 'Machine Learning: Classification, Regression, Clustering, Decision Tree, K-Means Clustering, Naïve Bayes.\\nStatistical Methods: Predictive Analysis, Hypothesis Testing and Confidence interval, Principal Component Analysis & Dimensionality Reduction, Market Basket Analysis, Text Analytics, Sampling, Bootstrap, Cross Validation.\\nProgramming Languages: R, Python\\nScripting Language: Linux\\nData Reporting Tool: Tableau\\nTelecom domain exp.\\n\\n10.00-15.00 Years\\nBachelor Of Technology (B.Tech/B.E), Master in Computer Application (M.C.A), Masters in Technology (M.Tech/M.E/M.Sc)',\n",
       " 'Job Background/context:\\n1. Candidate should have around 8-12 years development & systems design experience\\n2. More than 5 years of experience in BigData technologies like spark, python & Java with minimum 2 years experience in Data Science or certified candidate from a prominent institute who can demonstrate good skills in Data Science.\\n3. Proven proactive problems identification & rapid trouble-shooting skills.\\n4. Candidate with Trade Surveillance domain experience will be preferred\\nKey Responsibilities:\\nThe right candidate will be expected to be a significant player in the project evolution & deployment shouldering the following responsibilities:\\nWork as a collaborative member of a team spread over multiple locations (India, UK, US)\\nUnderstand internally published architectural guidelines to design solutions and represent them in architectural reviews.\\nDefine & communicate development standards that follow established architectural designs and perform code reviews to ensure quality standards of systems & team.\\nLead by example in developing exceptional quality code by doing design & code reviews.\\nDesign & develop platform functionality that is scalable & configurable as a global platform.\\nSkills:\\nMandatory Skills:\\nStrong knowledge in Spark ,Java/Python.\\nStrong experience in Hive/SQL, PL/SQL\\nGood Experience in Data Science , Unix Shell Scripting\\nDesirable Skills:\\nTrade Life cycle\\nMarket data systems\\nOther skills & Qualifications:\\nBachelor’s degree in engineering or masters degree in Maths, physics\\nCandidate should be willing to work late in the evening India time on need basis in order to interact with US/UK onshore team and to meet urgent requests by Clients.\\nExhibit sound and comprehensive communication and diplomacy skills to exchange complex information\\nAct as advisor or coach to new or lower level analysts;\\nOrganizational and project management skills required\\nStrong influencing & interpersonal skills.\\nDevelopment Value:\\nOpportunities for career growth within a Surveillance domain that is expanding\\nHands-on design and development experience including experience on a production implementation of Hadoop with massive data volumes and unstructured data sets\\nInvolve and lead projects involving complex feature-based data algorithms and machine learning\\nExposure to communication surveillance functions in a dynamic and challenging industry with regular close collaboration with our surveillance portfolio clients\\nA team with a win-together/lose-together attitude and strong sense of identity and positive culture\\n-\\nJob Family Group:\\nTechnology\\n-\\nJob Family:\\nApplications Development\\n-\\nTime Type:\\nFull time\\n-\\nCiti is an equal opportunity and affirmative action employer.\\nQualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\nCitigroup Inc. and its subsidiaries (\"Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\\nView the \"EEO is the Law\" poster. View the EEO is the Law Supplement.\\nView the EEO Policy Statement.\\nView the Pay Transparency Posting',\n",
       " 'Title:\\nData ScientistUnder general supervision, independently applies advanced engineering techniques, makes decisions on engineering problems and methods, and represents the organization in conferences to resolve important questions or to negotiate with key engineers and officials of other organizations. Provides technical guidance to designers and less experienced engineers and is consulted extensively by associates and others with a high degree of reliance placed on scientific interpretations and advice. Job role is responsible for a measurable asset such as an assigned staff and budget. Skills are typically acquired through an undergraduate degree in Engineering and a minimum of 7 years related experience, with average experience ranging from 10+ years.\\nScheduled Weekly Hours:\\n40',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\n\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Ecolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nEcolab is looking for a talented Senior Data Scientist in Pune R&DE center to work in-house innovation hub chartered with creating big data analytics and data science innovation to derive valuable insights driving business and commercial successes. Ecolab ranks 93rd in Forbes top 100 most innovative companies in the world. Our technologies help our customers across a broad spectrum of segments spanning from institutional to industrial and oil/gas industries succeed by getting visibility into their processes and generate actionable insights to help us fulfill our mission of Safe Food, Clean Water Healthy Environments, and Abundant Energy.\\n\\nResponsibilities\\nWork in nimble, fast-paced thriving entrepreneurial environment to create data analytics solutions and connect to business needs and commercial strategies.\\nWork closely with a team of energized Data Scientists and technologists based in both India and U.S. with diverse backgrounds, to tinker with new ideas in an agile, collaborative, and “fast to fail” fashion.\\nStay on the cutting edge of technology evolution in the data science and engineering area, and closely connect with external technology partners and innovations.\\nProactively collaborate with business partners and domain experts from various functions (R&D, marketing, sales, IT, supply chain, etc.) to identify and formulate problems and innovation opportunities that can be enabled by the predictive and deep data analytics.\\nArchitect, rapid prototype and test data analytics solutions in a POC (proof of concept) scale to operationalize the outcomes of the predictive modeling and validate the results.\\nQualifications\\n5+ years of hand-on experience in developing predictive and deep data analytics solutions for real-world business operation and commercial uses (e.g., customer analytics, supply chain and logistics, predictive maintenance, etc.).\\nMaster’s or PhD degree in Data Science/Data Analytics, Computer Science, Operations Research, Applied Mathematics, Statistics or related science and technical field.\\nBackground in Chemical or other Engineering disciplines or Chemistry.\\nProficiency with modern statistical modeling (regression, boosting trees, random forests, etc.), machine learning (text mining, neural network, NLP, etc.), optimization (linear optimization, nonlinear optimization, stochastic optimization, etc.) methodologies.\\nBackground in solving problems in the B2B world including supply chain optimization, predictive service etc.\\nProficiency with open-source data analytics toolsets such as R, Python, etc.\\nExperience with advanced data analytics platform tools such as SAS, Azure ML, Rapidminer, MATLAB, KNIME, etc.\\nFamiliar with modern data analytics architecture and data engineering technologies (Hadoop, SQL and No-SQL databases, ETL techniques, etc.)\\nA strong business focus, ownership and inner self-drive to bring connected offerings to real-world customers with tangible impact.\\nComfortable working in an agile and fast-paced environment and creating order from ambiguity.\\nAbility to work with multidisciplinary and passionate team members to do whatever it takes to get the job done.\\nA life-long learner who constantly updates skills (certifications earned and a portfolio of self-driven analytics problem solving examples in repositories like GitHub).\\nOur Commitment to Diversity and Inclusion\\nAt Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.\\nIn addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.',\n",
       " \"Company Description\\nDemandMatrix Inc. is a data company that provides Go To Market, Operations and Data Science teams with high quality company level data and intelligence. DemandMatrix uses advanced data science methodologies to process millions of unstructured data points that produce reliable and accurate technology intelligence, organizational intent and B2B spend data.\\n\\nJob Description\\nWe are looking for a Lead Data Scientist to lead a technical team to discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus is to work with the team to drive multiple initiatives for applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products in the domain of technographics and problems like buyer's journey, Technology Adoption Models (TAM)\\nResponsibilities:\\nRun CRISP-DM projects with a team of 3 data scientists in the following -\\nSelecting features, building and optimizing classifiers (logistic regression or RF based propensity models) and recommenders using machine learning techniques\\nData mining using state-of-the-art methods - Automate scoring using machine learning techniques, build recommendation systems, improve and extend the features used by recommendation and propensity modeling algos,\\nExtending company’s data with third party sources of information when needed\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis and perform deep EDA (we create our own training data for our models)\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating recommended and propensity models and tracking of its performance especially to compensate for concept drift\\n\\nQualifications\\nHands on machine learning techniques and algorithms, such as k-NN, Naive Bayes, Ensemble methods XGBoost, Decision Forests and working towards deep learning methods using TensorFlow especially for NLP like word embeddings and topic discovery\\nHands with common data science toolkits, such as Python, scikit learn, numpy, pandas, plotly, TensorFlow, ElasticSearch, Auto-ML platforms like AWS Sagemaker\\nSolid proficiency in using query languages such as SQL, Experience with NoSQL databases, such as Elasticsearch and Graph DBs as Neo4j\\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression and strong EDA skills\\nData-oriented personality with strong sense of appreciating the business domain of your work e.g.\\nInterest in working in tech domain e.g. data center analytics, understanding of macro factors in market for computing, software and cloud adoptions\\nExperience of 5+ years\\n\\nAdditional Information\\nFlexible Working hours\\nEntire Work From Home\\nBirthday Leave\\nRemote Work\",\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'About Us\\nBlueshift is a venture-funded startup headquartered in San Francisco, USA. Our AI-Powered marketing platform empowers cutting edge B2C brands to drive 1:1 marketing on every channel. With Blueshift, marketers are in full control of automating various forms of personalized messaging across every engagement channel.\\nBlueshift is trusted by leading digital brands like Udacity, Discovery, Live Nation, LendingTree, BBC, and Paypal to automate their customer engagement marketing and recognized by Gartner as a \"Cool Vendor for AI in Marketing\".\\nBlueshift is founded by repeat entrepreneurs who previously built Mertado.com (acquired by Groupon to become Groupon Goods), and were part of the early team behind Kosmix (acquired by Walmart to become @WalmartLabs). We are backed by top-tier VCs including Nexus Venture Partners, Storm Ventures, Luma Partners, and SoftBank Venture Asia.\\nBlueshift is staffing its development center in Pune, India. As part of Blueshift, you will get to work on cutting-edge technologies including machine learning, artificial intelligence, big data, and large-scale distributed data systems. This is an exciting opportunity for motivated individuals to build a great career.\\nResponsibilities\\nAs an AI Solutions Engineer in the Data Science team, you will be responsible to understand and communicate with customers personalization and predictive scoring use cases and implement them within Blueshift platform. You will help the clients realize full power of machine learning and AI modules. You will be the interface between the customer and the data scientists and data engineers.\\nWork with customer representatives - mainly marketers in mid to large enterprises - to design, develop and deploy creative marketing campaigns using AI.\\nImplement and define AI configurations and code and translate client campaign ideas in to workable solutions.\\nWork with data scientists to design experiments and benchmark AI results.\\nRequirements\\nAt least 4 years of industry experience in software development with at least 2 years of experience working with customers directly\\nExcellent spoken and written communication skills and ability to interact with customers\\nStrong proficiency with SQL and database systems - demonstrated ability to handle complex data analysis\\nProven programming skills with scripting languages like python or ruby\\nPreferred\\nKnowledge of modern machine learning algorithms\\nPrior experience working on large scale data sets\\nPerks and Benefits\\nOpportunity to be part of the early team in India\\nCompetitive salary along with stock option grants\\nExcellent hospitalisation, personal accident, and term insurance coverage\\nLocated in a top-notch facility in Baner - one of the best neighbourhoods for tech startups\\nDaily catered breakfast, lunch, and snacks along with well-stocked pantry',\n",
       " 'Pune\\n\\nHands-on experience with Computer Vision/Deep Learning/Neural\\nnetworks is must.\\nMinimum 3-7 years experience\\nDeep knowledge of Algorithm & data structure design is required\\nGood understanding of Linear Algebra, Calculus and Fundamentals\\nof Mathematics is required\\nExpertise in Python (Tensorflow, Keras, Torch or MxNet) is\\nrequired\\nExperience with Mysql, MongoDB, Elasticsearch, Docker would be\\nan advantage\\nIf you have published research papers, Please share the details\\nIf you have GitHub repo, Please share the details\\nExperience\\n3 - 7 Years\\n\\nSalary\\n5 Lac To 10 Lac P.A.\\n\\nIndustry\\nIT Software - Application Programming / Maintenance\\n\\nQualification\\nPh.D/Doctorate\\n\\nKey Skills\\nASP.NET SQL Server Software Development C++ Java Developer HTML5 Developer Dot Net Developer Python Developer\\n\\n\\nAbout Company\\nContact Person\\nMr. D.M.Patil\\n\\nAddress\\n600, Krushna Business Centre,1st Floor, Behind Sai Service Petrol Pump\\n\\nMobile\\n9579239323\\n\\nEmail ID\\nvijayamgmt@gmail.com',\n",
       " 'As a Data Scientist, you will be responsible for analyzing the large complex data, with the use of advanced statistical analysis, data mining, and data visualization techniques, to give key insights to the product team to enhance business performance. They will also prepare reports and presentations for the management which will give insights for business wide decision making.\\nResponsibilities\\nCollaborate with a multi-disciplinary, data-driven team to leverage key performance metrics to improve game performance;\\nDevelop and publish analysis reports for internal use, including segmentation of audience & user behavior;\\nSet-up and monitor dashboards and assess the performance of the game, including monetization and engagement;\\nCommunicate to stakeholders the performance of the game via reports and ad-hoc analysis;\\nGather business needs and document tracking requirements;\\nParticipate in the design and development of a successful product;\\nSupport the optimization of the game performance with the Product Team.\\nQualifications\\nBachelor’s degree (preferably in a quantitative field);\\nMinimum 2 years of experience in the video game industry;\\nMinimum 5 years of experience in a related field, such as digital marketing, e-commerce, business intelligence, sports analysis etc;\\nExcellent communication skills and ability to synthesize key information to stakeholders and senior management;\\nExperience working on multi-disciplinary teams in a dynamic environment;\\nExperience working with big data, including manipulation and analysis;\\nExperience with database systems is preferred but not required;\\nExpertise in Excel;\\nExperience with reporting tools (e.g. Tableau, R) and analytics platforms such as Google Analytics, Firebase, Flurry, deltaDNA, etc;\\nKnowledge of the video game industry, including freemium games concepts;\\nDemonstrate strong learning abilities as well as humility;\\nPassion for mobile games!!']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Titles']=titles\n",
    "df['Companies']=companies\n",
    "df['Locations']=locations\n",
    "df['Links']=links\n",
    "df['Reviews']=reviews\n",
    "df['Salaries']=salaries\n",
    "df['Descriptions']=descriptions\n",
    "df['Urgent Hiring']=Hir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Links</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Salaries</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Urgent Hiring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Aretove</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=9f74dedcc3e617...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>We are looking for Data Scientists to join our...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>Michelin</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=607eba399767a6...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Manager - Data Scientist\\n- - - - - - - - - - ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist_TS</td>\n",
       "      <td>AppZen</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=84ed41fbb2765b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AppZen is the leader in AI software for financ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Diverse Lynx India</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=7b7263651549e2...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>None</td>\n",
       "      <td>Job description\\nResponsibilities for Data Sci...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SE/SSE - Python+AI+ML+NLP</td>\n",
       "      <td>TDG</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=a797acc634406d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Position - SE/SSE - Python+AI+ML+NLP\\nExperien...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Bioinformatic (Data Scientist) -Variant analyst</td>\n",
       "      <td>Innoplexus</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=a41007039b5edb...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Location – Pune – India\\nRequired experien...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Principal Data Scientist - Remote</td>\n",
       "      <td>Icertis</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=9ac255234c0c86...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>None</td>\n",
       "      <td>With unmatched technology and category-definin...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>AI Solutions Engineer</td>\n",
       "      <td>Blueshift</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=b08921a9bfc432...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>None</td>\n",
       "      <td>About Us\\nBlueshift is a venture-funded startu...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Deep Learning Engineer/ Software Engineer-3 Post</td>\n",
       "      <td>Vijaya Management Services</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=1b86a0727a8a66...</td>\n",
       "      <td>None</td>\n",
       "      <td>₹5,00,000 - ₹10,00,000 a year</td>\n",
       "      <td>Pune\\n\\nHands-on experience with Computer Visi...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Cympl</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=5c81218d15c549...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>As a Data Scientist, you will be responsible f...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titles  \\\n",
       "0                                      Data Scientist   \n",
       "1                            Manager - Data Scientist   \n",
       "2                                   Data Scientist_TS   \n",
       "3                                      Data Scientist   \n",
       "4                           SE/SSE - Python+AI+ML+NLP   \n",
       "..                                                ...   \n",
       "100   Bioinformatic (Data Scientist) -Variant analyst   \n",
       "101                 Principal Data Scientist - Remote   \n",
       "102                             AI Solutions Engineer   \n",
       "103  Deep Learning Engineer/ Software Engineer-3 Post   \n",
       "104                               Senior Data Analyst   \n",
       "\n",
       "                      Companies          Locations  \\\n",
       "0                       Aretove  Pune, Maharashtra   \n",
       "1                      Michelin  Pune, Maharashtra   \n",
       "2                        AppZen  Pune, Maharashtra   \n",
       "3            Diverse Lynx India  Pune, Maharashtra   \n",
       "4                           TDG  Pune, Maharashtra   \n",
       "..                          ...                ...   \n",
       "100                  Innoplexus  Pune, Maharashtra   \n",
       "101                     Icertis  Pune, Maharashtra   \n",
       "102                   Blueshift  Pune, Maharashtra   \n",
       "103  Vijaya Management Services  Pune, Maharashtra   \n",
       "104                       Cympl  Pune, Maharashtra   \n",
       "\n",
       "                                                 Links Reviews  \\\n",
       "0    https://in.indeed.com/rc/clk?jk=9f74dedcc3e617...    None   \n",
       "1    https://in.indeed.com/rc/clk?jk=607eba399767a6...     4.0   \n",
       "2    https://in.indeed.com/rc/clk?jk=84ed41fbb2765b...    None   \n",
       "3    https://in.indeed.com/rc/clk?jk=7b7263651549e2...     4.8   \n",
       "4    https://in.indeed.com/rc/clk?jk=a797acc634406d...    None   \n",
       "..                                                 ...     ...   \n",
       "100  https://in.indeed.com/rc/clk?jk=a41007039b5edb...     4.5   \n",
       "101  https://in.indeed.com/rc/clk?jk=9ac255234c0c86...     3.8   \n",
       "102  https://in.indeed.com/rc/clk?jk=b08921a9bfc432...     4.1   \n",
       "103  https://in.indeed.com/rc/clk?jk=1b86a0727a8a66...    None   \n",
       "104  https://in.indeed.com/rc/clk?jk=5c81218d15c549...    None   \n",
       "\n",
       "                          Salaries  \\\n",
       "0                             None   \n",
       "1                             None   \n",
       "2                             None   \n",
       "3                             None   \n",
       "4                             None   \n",
       "..                             ...   \n",
       "100                           None   \n",
       "101                           None   \n",
       "102                           None   \n",
       "103  ₹5,00,000 - ₹10,00,000 a year   \n",
       "104                           None   \n",
       "\n",
       "                                          Descriptions Urgent Hiring  \n",
       "0    We are looking for Data Scientists to join our...          none  \n",
       "1    Manager - Data Scientist\\n- - - - - - - - - - ...          none  \n",
       "2    AppZen is the leader in AI software for financ...          none  \n",
       "3    Job description\\nResponsibilities for Data Sci...          none  \n",
       "4    Position - SE/SSE - Python+AI+ML+NLP\\nExperien...          none  \n",
       "..                                                 ...           ...  \n",
       "100  Job Location – Pune – India\\nRequired experien...          none  \n",
       "101  With unmatched technology and category-definin...          none  \n",
       "102  About Us\\nBlueshift is a venture-funded startu...          none  \n",
       "103  Pune\\n\\nHands-on experience with Computer Visi...          none  \n",
       "104  As a Data Scientist, you will be responsible f...          none  \n",
       "\n",
       "[105 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('indeed data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
