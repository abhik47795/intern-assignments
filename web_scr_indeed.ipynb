{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"E:\\DATA SCIENCE\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://in.indeed.com/jobs?q=Data+Scientist&l=Pune%2C+Maharashtra&radius=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=[]\n",
    "time=[]\n",
    "titles=[]\n",
    "companies=[]\n",
    "locations=[]\n",
    "Hir=[]\n",
    "links =[]\n",
    "ratings=[]\n",
    "salaries = []\n",
    "descriptions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,7):\n",
    "    \n",
    "    jobs = driver.find_elements_by_xpath('//div[contains(@class,\"clickcard\")]')\n",
    "    \n",
    "    for job in jobs:\n",
    "       \n",
    "        now=datetime.now()\n",
    "        time.append(now.strftime(\"%H:%M:%S\"))\n",
    "        today=datetime.today()\n",
    "        dt.append(today.strftime(\"%y:%m:%d\"))\n",
    "        try:\n",
    "            rating = job.find_element_by_xpath('.//span[@class=\"ratingsContent\"]').text\n",
    "        except:\n",
    "            rating = \"None\"\n",
    "        ratings.append(rating)\n",
    " \n",
    "        try:\n",
    "            salary = job.find_element_by_xpath('.//span[@class=\"salaryText\"]').text\n",
    "        except:\n",
    "            salary = \"None\"\n",
    "      \n",
    "        salaries.append(salary)\n",
    "        \n",
    "        try:\n",
    "            hir=job.find_element_by_xpath('.//td[@class=\"jobCardShelfItem urgentlyHiring\"]').text\n",
    "        except:\n",
    "            hir=\"none\"\n",
    "            \n",
    "        Hir.append(hir)\n",
    "        \n",
    "        try:\n",
    "            location = job.find_element_by_xpath('.//span[contains(@class,\"location\")]').text\n",
    "        except:\n",
    "            location = \"None\"\n",
    "        \n",
    "        locations.append(location)\n",
    "        \n",
    "        try:\n",
    "            title  = job.find_element_by_xpath('.//h2[@class=\"title\"]//a').text\n",
    "        except:\n",
    "            title = job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"title\")\n",
    "        titles.append(title)\n",
    "        links.append(job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"href\"))\n",
    "        companies.append(job.find_element_by_xpath('.//span[@class=\"company\"]').text)\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('//a[@aria-label={}]//span[@class=\"pn\"]'.format(i+2))\n",
    "        next_page.click()\n",
    "\n",
    "    except:\n",
    "        next_page = driver.find_element_by_xpath('//a[@aria-label=\"Next\"]//span[@class=\"np\"]')\n",
    "        next_page.click()\n",
    "        \n",
    "    \n",
    "    print(\"Page: {}\".format(str(i+2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " '₹10,000 - ₹20,000 a month',\n",
       " '₹6,00,000 - ₹9,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹20,000 - ₹50,000 a month',\n",
       " '₹5,00,000 - ₹8,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹6,00,000 - ₹22,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹5,00,000 - ₹12,00,000 a year',\n",
       " 'None',\n",
       " '₹5,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '₹2,40,000 - ₹4,00,000 a year',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions=[]\n",
    "for link in links:\n",
    "    \n",
    "    driver.get(link)\n",
    "    jd = driver.find_element_by_xpath('//div[@id=\"jobDescriptionText\"]').text\n",
    "    descriptions.append(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job Title:Data Scientist\\nLocation: Pune\\nProject and Program management within Data Integration CoE.\\nTechno-Managerial role that involves coordination with various teams like Infra, Platform, Unix, Storage, Cloud Architects and Data Analysts/Stewards.\\nAbility to plan, architect and design the migrations of ETL projects to Cloud platform.\\nAbility to interpret user stories/ requirements into applications.\\nAbility to develop tools in the most efficient manner with fastest cycle time.\\nAbility to work in Agile Teams and support Agile Testing\\nWhat will you be doing?\\nLeading Others\\nResponsible for co-ordinating, participating in, and is responsible for, the work of a team of managed services/ contractors on a need basis.\\nMaking effective use of resources during the various stages of the work, ensuring that business objectives are met and deliverables achieved to agreed time, and quality\\nProviding advice, guidance and assistance to less experienced colleagues (as required).\\nPutting in place mechanisms and procedures for the structured review of work produced and ensuring that these are adhered to.\\nEstablishing and maintaining agreed standards applicable to the work undertaken and ensuring that these, and other mandatory standards and architectures, are adhered to.\\nCapability Growth\\nBuilding and maintaining an expert understanding of the various stages of software development, enhancements, and support (where required).\\nProviding guidance and assistance to colleagues in any aspect of programme design, creation, testing and documentation.\\nInterfacing with other teams, sharing technical knowledge and expertise and resolving issues as necessary. Acting as a point of reference for both internal and external technical queries.\\nOrganizational Improvement\\nAssisting with the implementation of operational objectives for relevant team/programme.\\nSupporting the implementation of strategy and policy issues by involvement in development/change and/or advice to other technical areas and making recommendations to improve procedures and working practices.\\nTaking part in evaluations and reviews of programming methods, tools and standards.\\nWhat we’re looking for:\\nSkills in open source technologies and other areas including python, Java, AWS Services (or other Cloud platforms)\\nProject and program management, estimation, costing and forecasting, project planning.\\nAbility to engage with Stakeholders, elicit requirements/ user stories and translate requirements into technical components\\nGood communication skills.\\nAbility to understand the infrastructure, team involved and be able to provide solutions either individually or working with teams.\\nGood knowledge of ETL and Datawarehousing.\\nShould have worked on at least two major Cloud implementations\\nWhere will you be working?\\nPune\\nBe More at Barclays\\nAt Barclays, each day is about being more – as a professional, and as a person. ‘Be More @ Barclays’ represents our core promise to all current and future employees. It’s the characteristic that we want to be associated with as an employer, and at the heart of every employee experience. We empower our colleagues to Be More Globally Connected, working on international projects that improve the way millions of customers handle their finances. Be More Inspired by working alongside the most talented people in the industry, and delivering imaginative new solutions that are redefining the future of finance. Be More Impactful by having the opportunity to work on cutting-edge projects, and Be More Valued for who you are.\\nInterested and want to know more about Barclays? Visit home.barclays/who-we-are/ for more details.\\nOur Values\\nEverything we do is shaped by the five values of Respect, Integrity, Service, Excellence and Stewardship. Our values inform the foundations of our relationships with customers and clients, but they also shape how we measure and reward the performance of our colleagues. Simply put, success is not just about what you achieve, but about how you achieve it.\\nOur Diversity\\nWe aim to foster a culture where individuals of all backgrounds feel confident in bringing their whole selves to work, feel included and their talents are nurtured, empowering them to contribute fully to our vision and goals.\\nOur Benefits\\nOur customers are unique. The same goes for our colleagues. That's why at Barclays we offer a range of benefits, allowing every colleague to choose the best options for their personal circumstances. These include a competitive salary and pension, health care and all the tools, technology and support to help you become the very best you can be. We are proud of our dynamic working options for colleagues. If you have a need for flexibility, then please discuss this with us.\",\n",
       " \"About the company:\\nWe are a research and product development company in the field of electric vehicles and mobility as a service (MaaS) platform. Currently, we are working on intelligent electric scooters and related fleet services. We lead with a holistic approach, followed by thorough research and special emphasis on user needs, giving them easy and fluid experiences without any compromises.\\nAbout the internship/job:\\nSelected intern's day-to-day responsibilities may include some of the following tasks:- 1. Using tools/languages such as Excel, Tableau, and Python for data analysis and data visualization. Using AWS related services. 2. Working on data analytics for docked and dock-less electric scooter sharing system and on the back-end for giving meaningful insights to the business team 3. Gathering demographic data such as population density, residential and commercial zones, public parking spaces, restaurants, malls and other places of interest 4. Deciding strategic locations for placing the docks of e-scooters for maximum usage of vehicles and revenue generation 5. Vehicle profiling and assigning parameters for data analytics purposes 6. Working on the analysis of data generated by IoT device on the vehicle. Sensors include Accelerometer, Gyroscope, Magnetometer, GPS, Voltage sensor.\\nWho can apply:\\nOnly those students or freshers can apply who:\\nare available for the part time job/internship (it may be part time in-office or part time at home/work from home online)\\nhave relevant skills and interests\\ncan start the part time job/internship between 23rd Dec'20 and 27th Jan'21\\nare available for duration of 3 months\\nhave already graduated or are currently in any year of study\\nFemales willing to start/restart their career may also apply\\nNumber of internships/jobs available: 4\\nCategories: Data Science\",\n",
       " 'Responsibilities and Duties\\nKnowledge of Deep learning, image processing, Yolo, object detection,\\noptical character recognition\\nExperience in driving systemic operational improvements\\nExperience working with cross-functional teams including communicating with other technical teams, product management, and senior management\\nDemonstrated ability to mentor junior software engineers in all aspects of the software engineering craft\\nTrack record of developing web services or other large-scale distributed systems\\nExperience : 2 To 4 Years\\nCTC ;6 To 9 L.P.A\\nContact: 9637195895\\nNotice period : Max 1 Month\\nRequired Experience, Skills and Qualifications\\nProficiency with Unix Shell scripting,Python, SQL, and PL/SQL\\nExperience with ML frameworks including scikit-learn, TensorFlow, OpenCV.\\nProfessional experience developing highly scalable distributed systems using Python\\nExpert Python programming language and Object-Oriented design with hands on experience on above\\nHands on knowledge of Restful API development\\nExperience in developing large scale, micro service oriented, distributed applications and API.\\nExperience influencing software engineering best practices within your team, including design reviews, coding standards, code reviews, source control management, build processes, testing, and operations\\nLinux system programming with Python and C or C++.\\nExperience with computer hardware, not just virtual or cloud services.\\nMust be a self-starter in identifying ways to improve design and development processes\\nStrong attention to detail, An eagerness to dig in and find the root causes of obscure problems.\\nJob Type: Full-time\\nSalary: ₹600,000.00 - ₹900,000.00 per year\\nSchedule:\\nDay shift\\nExperience:\\nwork: 1 year (Preferred)\\ntotal work: 1 year (Preferred)\\nEducation:\\nSecondary(10th Pass) (Preferred)',\n",
       " 'No of Positions – 2\\n\\nExperience – Fresher\\n\\nJob Requirement / Description\\nData collect and generate from social media and other things\\nWell versed with tools like python, hive ,sas,hadoop.\\nGood Communication skill\\nFlexible & Adjustable',\n",
       " 'Manager - Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nData Analysis and Modelization\\n· The need is understood and formalized in a descriptive datasheet or Cahier des Charges\\n· The methods are clearly selected by their theoretical bases, advantages and drawbacks\\n· The data, its relevance and its source are described and prioritized\\n· The data are prepared (cleansed, enriched, mapped,agregated, …) and the approach is documented.\\n· The analysis is implemented and documented\\n· The results of the analysis or the model are presented to the customers in the form of presentation (PPT or other) indicating the performances and the limits. The source code is delivered and explained if necessary.\\nMarket Watch\\n· Benchmarks other companies and stays aware of the latest trends\\nEnsures the sharing of good practices (internally and externally)',\n",
       " 'We are looking for Data Scientists to join our Data Services Team in India. If you are a data scientist and looking for driving business strategy through predictive and prescriptive analytics, then lets talk! Send your resume to careers@aretove.com\\n\\nResponsibilities\\nWork with stakeholders from products, merchandising, operations, customer retention to identify opportunities for leveraging in-house and third party data to drive decisions.\\nProcessing, cleansing, and verifying the integrity of various data sets to drive insights on customer, marketing, operations, products and other business strategies.\\nBuild predictive models to enhance customer experiences & retention, spend optimization, campaigns, supply chain and other business outcomes.\\nDevelop visualization/ presentations to clearly articulate and present data insights to various stakeholders\\nDevelop processes and tools to monitor, analyze and report model performance and data accuracy.\\nSkills/Experience\\nBachelors/Masters Degree in computer science, math, engineering, analytics, or related field and five (5) years or more experience\\n2 -5 years of experience using statistical computer languages (R, Python, SQL) to draw insights and foresights using large and heterogeneous data sets\\nExperience with machine learning techniques (clustering, supervised learning and tree based, etc.) under real-word problem statements.\\nExperience on statistical techniques and concepts (regression, properties of distributions, statistical tests, etc.).\\nExperience using business intelligence/visualization tools (Tableau/ Looker/ Power BI/Others)\\nExposure to cloud-based machine learning platforms such as Spark MLlib or Azure ML etc would be an added advantage.\\nAbility to work independently, deal well with ambiguous and undefined problems.\\nAbility to work in a fast-paced and agile environment.',\n",
       " 'AppZen is the leader in AI software for finance teams. Over 1,800 global enterprises use AppZen to automate manual finance processes, reduce expenditures, and gain real-time insights into their business spend trends. Our patented software technology delivers AI deep learning, semantic analysis, and Star Match™, the only automated spend validation that processes intelligence from thousands of data sources, documents, and images to understand financial transactions and make decisions based on finance policies. AppZen is the platform of choice for today’s digital CFO and their teams, including four of the top five banks, four of the top ten media companies, four of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and six of the top ten software providers.\\n\\nWe’ve taken off this year! Since releasing our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor, and have been recognized as one of the fastest-growing technology companies in the market. In 2019 we received $50 million in Series C funding from Lightspeed, Redpoint and other leading venture capital firms.\\n\\nWe are looking for a Data Scientist to come and work on our growing AI stack. You will be working\\nwith a team of highly skilled and motivated data scientists and machine learning engineers. If you\\nare excited about natural language understanding and machine translation, AppZen is the right place\\nfor you to apply and grow your skills.\\nMust-Have:\\nSolid understanding of machine learning fundamentals, and familiarity with standard\\nalgorithms and techniques\\nAbility to analyse a wide variety of data: structured and unstructured, observational and\\nexperimental, to drive system designs and product implementations\\nExpert knowledge of a statistical computing language such as Python. Knowledge of\\nprobability and statistics, including experimental design, predictive modelling, optimization,\\nand causal inference Experience in design and deployment of real-world, large-scale, user-\\nfacing systems\\nEnsure data quality throughout all stages of acquisition and processing, including such areas\\nas data sourcing/collection, ground truth generation, normalization, transformation, cross-\\nlingual alignment/mapping, etc.\\nManage your own process: identify and execute on high impact projects, triage external\\nrequests, and make sure you bring projects to conclusion in time for the results to be useful\\nExcellent written and verbal technical communication skills; communicate proposals and\\nresults in a clear manner backed by data and coupled with actionable conclusions to drive\\nbusiness decisions\\nExperience in developing and productionizing AI/ML models in client facing roles\\nB.E./B.Tech/M.E./M.Tech in Computer Science, Engineering, Statistics, or another relevant\\ntechnical field\\nMust have 1-3 years of industry experience\\nYou are a team player\\nCome as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.',\n",
       " \"We are An IT company Based in Pune.\\nwe are looking for Fresher candidate for data science Internship. Internship is available in Data Science ,Ml And AI technology.\\nskills: Interns\\nSelected intern's day-to-day responsibilities include: 1. Working on data science algorithms and AI concepts 2. Using Python or R for web scraping 3. Building AI models using Python, machine learning, and deep learning algorithms 4. Processing of unstructured/structured data\\nBenefit : Assured Job placement after Internship.\\nEducation : Any graduation Or Master Pursuing student can join.\\nJob Types: Part-time, Internship\\nSchedule:\\nDay shift\\nEducation:\\nBachelor's (Preferred)\\nLocation:\\nPune, Maharashtra (Preferred)\\nWork Remotely:\\nNo\",\n",
       " \"Hi,\\nGreetings from Vedita Ventures!\\nUrgent Hiring - ML Engineer\\nBoth Male/Female candidates can Apply\\nJob Location: Pune\\nMachine Learning Engineer responsibilities include creating machine learning models and retraining systems.\\nResponsibilities:\\nAbility to create and analyze software architecture/designs\\nStrong python developer with hands-on experience on machine learning, statistical models and frameworks\\nResearch and implement appropriate ML algorithms and tools\\nTrain models and tune their hyperparameters\\nAnalyze the errors of the model and design strategies to overcome them * Deploy models to production\\nSkills:\\nExperience in:\\no Database: SQL, Mongo DB, NoSQL\\no Programming Language: Python and libraries like Pandas, Numpy, Matplotlib, NLTK o Ability to handle various data types and structured as well as unstructured data. o Rest API development and integration\\no Knowledge of TensorFlow framework\\no Knowledge of Threading, thread synchronization , socket programming, IPC, Locking Primitives, Timers, File I/O, shared memory, low latency high throughput, Data Structures\\nEducation:\\nBE in Computer Science / IT or MCA\\nLocation: Pune\\nJob Type: Full-time\\nSalary: ₹20,000.00 - ₹50,000.00 per month\\nBenefits:\\nWork from home\\nSchedule:\\nDay shift\\nExperience:\\nwork: 1 year (Preferred)\\ntotal work: 1 year (Preferred)\\nmechanical engineering: 2 years (Preferred)\\nEducation:\\nBachelor's (Preferred)\",\n",
       " 'Job Description\\nRole: - Data Scientist\\nLocation: Pune\\nWork Experience of 2-7 years\\n\\nØ Experience in Python & Scrapping using Selenium, Beautiful Soup, and pandas.\\nØ Experience in NLP and NLG using TFIDF, Word2Vec, ELMO, Spacy and BERT & T5.\\nØ Experience in Flask web service and Docker image development.\\nØ Strong problem-solving skills with an emphasis on data transformation.\\nØ Knowledge or experience in RNN, LSTM & CNN.\\nØ Knowledge and experience in statistical and data mining techniques: Regression, Random Forest, Boosting, Trees, ARIMA etc.\\nØ Knowledge in Cloud Services like AWS, Azure.\\nØ Excellent written and verbal communication skills for coordinating across teams.\\nØ Coordinate with different functional teams to implement models and monitor outcomes.\\n\\n2.00-7.00 Years',\n",
       " 'Requirements\\nBS/MS degree in Computer science, Maths\\nYou are experienced with data stores such as Mysql, MongoDB, Cassandra, HBase, Hive\\nExperienced with data visualisation tools, such as Tableau, D3.js, GGplot, etc\\nPast experience with Deep Learning/NLP would be an advantage (although not necessary)\\nGood Communication Skills\\nTeam Player\\nWhat We Expect.?\\nYou take pride in your knowledge of design patterns, algorithms and data structures\\nYou are comfortable processing, cleansing, and verifying the integrity of data used for analysis\\nYou understand machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CART, CHAID etc\\nYou understand feature selection, model performance metrics, building and optimizing machine learning models\\nYou are good at doing ad-hoc analysis and presenting results in a clear manner\\nYou are good at creating automated anomaly detection systems and constant performance tracking\\nYou can code comfortably in R & Python (NumPy, sklearn, xgboost)',\n",
       " '11/23/2020\\nEcoMetric Consulting is a USA based full-service energy consulting firm focusing on energy efficiency, and distributed energy resources including demand response and renewables. EcoMetric has setup an offshore office in Pune, India and we are looking a self-reliant and dedicated Django stack developer with data science experience to join our team. Opportunities to visit and train in the USA will be provided.\\nEcoMetric Consulting is focused on constructive research to influence energy consumption & behaviors. We provide inspired, forward-thinking advisory services to inform demand-side management decision making. Our core services include energy efficiency program planning and evaluation services for various American utilities, state regulatory boards and other program sponsors. EcoMetric offers competitive compensation packages and an opportunity to learn US standards in energy investments.\\nDuties and Responsibilities\\nExperience importing, cleaning and manipulating large datasets (500,000+ records) using one or more statistical packages (R, Python, STATA) and identifying, summarizing and effectively correcting data inconsistencies. Ability to clearly document and communicate data exploration and cleaning decisions while assessing their effect on resulting data structures and possible analyses.\\nEmploy sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling.\\nBuild scalable and high-performance machine learning algorithms.\\nCreate easily understandable data visualizations of findings (e.g. charts, graphs, infographics).\\nDocument findings visually and/or verbally for memos and reports to clients and/or internal project teams.\\nSupport senior staff with development of presentations and papers.\\nQualifications\\nBachelor’s or Master’s Degree Computer Science, Computer Engineering or Information Technology with data science training\\nFive or more years’ work experience with cloud-based software development and data analytics applications\\nProgramming proficiency with React/Angular, D3, MySQL and Python/R.\\nDetailed understanding of backend and UI/UX development using modern cloud based platforms.\\nExperience with Exploratory Data Analysis including wrangling, grooming, transformation, and analysis\\nExperience using IDE tools such as Jupyter to develop and demonstrate results\\nExperience with Azure stack and Kubernetes is a plus\\nExperience and success operating on an Agile Scrum team\\nExperience working with MySQL and relational databases.\\nExperience working with NoSQL databases such as MongoDB or CosmosDB.\\nExperience with integrating and using Data Science libraries such as scikit-learn, MlLib, Pandas, python (Jupyter, scikit-learn, pandas, etc.), R, Java\\nExperience with supervised and unsupervised machine learning techniques\\nExperience with Agile development and Agile tools (i.e. Jira, Confluence)\\nStrong understanding of creating APIs to leverage a variety of storage and analytical engine nodes.',\n",
       " 'Experience with C++ and Python\\nExperience with machine learning architectures and computer vision applications.Ability to self-start and deliver on time and on budgetWillingness to take ownership of tasks and products and drive these to completionPractical application skills & temperament relevant to solution prototyping in office, workshop & occasional site work environmentsExcellent communication skills with the ability to influence internal and external stakeholdersProficiency in using query languages\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.Good scripting and programming skills\\nOrganization: Advanta\\nCompany: Siemens Technology and Services Private Limited\\nExperience Level: Early Professional\\nJob Type: Full-time',\n",
       " 'Senior Manager - Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nThe need is understood and formalized in a descriptive datasheet or Cahier des Charges\\nthe methods are clearly selected by their theoretical bases, advantages and disadvantages\\nthe data, its relevance and its source are described and prioritized\\nthe data are aggregated and the approach is documented. (Key or parameter allowing to link the different sources )\\nthe analysis is implemented and documented\\nthe results of the analysis or the model are presented to the customers in the form of presentation (Pt or other) indicating the performances and the limits. The source code is delivered and explained if necessary.\\nthe team has a technical expert who is accessible and available to guide and help others in case of difficulty with an adapted communication. A technical seminar is organized each year\\nthe person in charge of the network Business regularly receives information on the health of the business as well as more or less formalized proposals for improvements',\n",
       " 'Business:\\nCCO Tech, HOST\\nOpen positions:\\n1\\n\\nRole Title:\\nManager, Technology Risk & Control Review/CCO\\nGlobal Career Band:\\n5\\n\\nLocation: (Country/City) :\\nIndia/Pune\\nShift Timing:\\nDay job\\n\\nWhy join us? (Overview of Dept./Function)\\n\\nWe are TRaCR (Technology risk and control review) team part of CCO tech, HOST. An agile, responsive and high-quality first line review capability able to deliver a rapid tempo of risk insight to technology to drive continuous improvement in our control environment. TRaCR team offers a world of potential. We are embarking into the journey of Automation and Data analytics with strong focus on Innovation and building new capabilities and solutions.\\nWeencourage our people to dive in, roll up their sleeves and take on the many opportunities bound to come their way. We provide freedom to innovate, code and develop innovative product and solutions. We offer ample opportunities as well as training and development programs that empower you to expand your skills and abilities.\\n\\nThe Opportunity: (Brief Overview of the Role)\\n\\nWe are looking for technical lead with strong hands-on experience in python programming and data analytics to create various capabilities and solutions. The candidate will be passionate about automation and machine learning, artificial intelligence and stay up-to-date with the latest developments in the field.\\n\\nWhat you’ll do: (List out Key Responsibilities)\\n\\nIdentify the opportunity for automation and design/build the end to end solutions.\\nExploring and visualizing data to gain an understanding of it, then identifying pattern in data distribution and generate insights\\nHelp in building key hypothesis and provide data analytics support to generate key insights for technology reviews\\nBuilding machine learning based product leveraging development life cycle –Data preparation, model building, model validation, and model deployment\\nCollaborate with stakeholders and end-users to understand and gather requirements to develop the best automation solutions and data products.\\n\\nWhat you will need to succeed in the role: (Minimum Qualification and Skills Required)\\n\\nFive years’+ software development (either C++/Java/C#/Python) and at least two years solid Python development experience;\\nStrong understanding of machine learning libraries, e.g., Pandas, NumPy, Scikit-learn, Matplotlib, SciPy, PyTorch, TensorFlow;\\nStrong understanding of machine learning and deep learning algorithms, e.g., ensemble models, Naïve Bayes, SVM, Decision Tree, DNN, CNN, RNN\\nGood experience of visualization tool - Tableau/Qlik/Matplotlib\\nGood experience of machine learning development life cycle –Data preparation, model building, model validation, and model deployment\\nGood experience with database, including Relational, Key-value and Search engine\\nGood experience with building and implementing Rest API, API Gateway;\\nFamiliarity with Flask/Django and Docker\\n· Knowledge on Hadoop, Spark, Kafka, NoSQL databases is plus\\n\\nWhat additional skills will be good to have? (List out good to have skills and certifications)\\nGood fundamentals in Computer Science / Software Engineering\\nGood working knowledge in Cloud Platform (prefer GCP)\\nGood understanding of fundamental design principles behind a scalable application\\nGood understanding of Agile, DevOps, CI/CD practice and tooling\\nGood working knowledge of physical IT infrastructures (e.g. Servers, SANs, Networking, etc.)\\nGood experience with Linux systems, e.g. use common shell commands and scripts.\\n\\n\\nThe information contained in this job description is a true and accurate reflection of the job as specified.\\n\\nQualifications\\nBusiness:\\nCCO Tech, HOST\\nOpen positions:\\n1\\n\\nRole Title:\\nManager, Technology Risk & Control Review/CCO\\nGlobal Career Band:\\n5\\n\\nLocation: (Country/City) :\\nIndia/Pune\\nShift Timing:\\nDay job\\n\\nWhy join us? (Overview of Dept./Function)\\n\\nWe are TRaCR (Technology risk and control review) team part of CCO tech, HOST. An agile, responsive and high-quality first line review capability able to deliver a rapid tempo of risk insight to technology to drive continuous improvement in our control environment. TRaCR team offers a world of potential. We are embarking into the journey of Automation and Data analytics with strong focus on Innovation and building new capabilities and solutions.\\nWeencourage our people to dive in, roll up their sleeves and take on the many opportunities bound to come their way. We provide freedom to innovate, code and develop innovative product and solutions. We offer ample opportunities as well as training and development programs that empower you to expand your skills and abilities.\\n\\nThe Opportunity: (Brief Overview of the Role)\\n\\nWe are looking for technical lead with strong hands-on experience in python programming and data analytics to create various capabilities and solutions. The candidate will be passionate about automation and machine learning, artificial intelligence and stay up-to-date with the latest developments in the field.\\n\\nWhat you’ll do: (List out Key Responsibilities)\\n\\nIdentify the opportunity for automation and design/build the end to end solutions.\\nExploring and visualizing data to gain an understanding of it, then identifying pattern in data distribution and generate insights\\nHelp in building key hypothesis and provide data analytics support to generate key insights for technology reviews\\nBuilding machine learning based product leveraging development life cycle –Data preparation, model building, model validation, and model deployment\\nCollaborate with stakeholders and end-users to understand and gather requirements to develop the best automation solutions and data products.\\n\\nWhat you will need to succeed in the role: (Minimum Qualification and Skills Required)\\n\\nFive years’+ software development (either C++/Java/C#/Python) and at least two years solid Python development experience;\\nStrong understanding of machine learning libraries, e.g., Pandas, NumPy, Scikit-learn, Matplotlib, SciPy, PyTorch, TensorFlow;\\nStrong understanding of machine learning and deep learning algorithms, e.g., ensemble models, Naïve Bayes, SVM, Decision Tree, DNN, CNN, RNN\\nGood experience of visualization tool - Tableau/Qlik/Matplotlib\\nGood experience of machine learning development life cycle –Data preparation, model building, model validation, and model deployment\\nGood experience with database, including Relational, Key-value and Search engine\\nGood experience with building and implementing Rest API, API Gateway;\\nFamiliarity with Flask/Django and Docker\\n· Knowledge on Hadoop, Spark, Kafka, NoSQL databases is plus\\n\\nWhat additional skills will be good to have? (List out good to have skills and certifications)\\nGood fundamentals in Computer Science / Software Engineering\\nGood working knowledge in Cloud Platform (prefer GCP)\\nGood understanding of fundamental design principles behind a scalable application\\nGood understanding of Agile, DevOps, CI/CD practice and tooling\\nGood working knowledge of physical IT infrastructures (e.g. Servers, SANs, Networking, etc.)\\nGood experience with Linux systems, e.g. use common shell commands and scripts.\\n\\n\\nThe information contained in this job description is a true and accurate reflection of the job as specified.',\n",
       " 'The Company\\n\\nHitachi Vantara, a wholly-owned subsidiary of Hitachi, Ltd., guides our customers from what’s now to what’s next by solving their digital challenges. Working alongside each customer, we apply our unmatched industrial and digital capabilities to their data and applications to benefit both business and society. More than 80% of the Fortune 100 trust Hitachi Vantara to help them develop new revenue streams, unlock competitive advantages, lower costs, enhance customer experiences, and deliver social and environmental value.\\n\\nThe Role\\n\\nWe are seeking Data Scientist\\n\\nResponsibilities\\nRole Overview:\\nExplore large datasets to surface useful trends, signals, and segments.The role drives business and industry solutions focused on Big Data and Advanced Analytics. Domain expertise in Manufacturing/Healthcare/Telecom/Financial Services is a key aspect. The role uses analytics to provide predictive, prescriptive, and decisive insight.\\nJob Description:\\nInteract with customers to understand business objectives and create analytical strategies to help achieve them.\\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\\nProcessing, cleansing, and verifying the integrity of data used for analysis.\\nAnalyze and model structured data using advanced statistical methods.\\nPerform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.\\nAnalyze data using open source packages and commercial/enterprise applications\\nPerform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.\\nSelecting features, building and optimizing classifiers using machine learning techniques.\\nImplement algorithms and software needed to perform analyses.\\nDrive client engagements focused on Big Data and Advanced Business Analytics.\\nDoing ad-hoc analysis and presenting results in a clear manner.\\nCommunicate results and educate others through reports and presentations. Skills Required â€¢ Expertise in Data Mining, Data wrangling, and data munging using one or more of the most commonly used data science tools: R, Python, SAS, SPSS, Weka â€¢ Experience in end-to-end data science and engineering activities.\\nExpertise in client engagement, data science consulting type activities.\\nMust have led a team of data engineers and data scientists in leading data science engagements.\\nExperience with analytics in IT and IoT space is a plus.\\nKnowledge and experience in Hadoop (Map Reduce paradigm) etc.\\nMust be hands-on and must have worked on implementing machine learning and data mining algorithms.\\nPassion for finding meaning in large data sets and identifying actionable results.\\nExcellent communication skills (both written and verbal) and interpersonal skills.\\nExperience working with and transforming large data sets.\\nUnderstanding of business value and how this relates to actionable results.\\nAbility to identify or interpret many inputs and requirements then transforming them into actionable plans.\\nAbility to take vaguely defined data sets and requirements then proactively identify and partner with needed SMEs to provide interpretations tailored to individual client needs.\\nAbility to visualize data results into meaningful workflows including charts and graphs\\nExperience in scripting languages with experience in scripting to integrate software solutions is a plus.\\nAdditional Skills (optional) Scala, Spark, H2O,Mahout, Hive\\nProduct Knowledge: At least 3 of the following: o R, Python (Scikit-learn, numpy, etc), Weka, SAS, SPSS, MATLAB/Octave, Hadoop (Map Reduce programming).\\nAbility to work in a Linux environment, and process large amounts of data in a cloud environment.\\nKnowledge in Search Engine: such as Elastic, Apache Lucene/Solr\\nQualifications\\nBE / B Tech / ME / M Tech\\n\\n\\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.',\n",
       " 'Job description\\nResponsibilities for Data Scientist\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\\nDevelop custom data models and algorithms to apply to data sets.\\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\\nDevelop company A/B testing framework and test model quality.\\nCoordinate with different functional teams to implement models and monitor outcomes.\\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\\nQualifications for Data Scientist\\nStrong problem solving skills with an emphasis on product development.\\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nExcellent written and verbal communication skills for coordinating across teams.\\nA drive to learn and master new technologies and techniques.',\n",
       " 'Company Description\\nMerkle | Sokrati, a leader in Digital Marketing and Analytics, managing Digital Marketing campaigns for several large brand clients in India. We are currently a 750+ people team; and growing extremely fast to gain more market share and roll out even cooler technology solutions in Digital Advertising space.\\nIn pursuit of this, we seek to hire an Manager – Data Science in our team.\\n\\nJob Description\\nWhat you’ll do at Merkle|Sokrati?\\nUse statistical methods to analyze data and generate useful business reports\\nAnalyze client data using EDA and provide actionable insights to improve processes and present them successfully to management using a reporting tool.\\nUse data to create AI&ML models to solve complex business problems\\nProvide support for ad hoc requests from the Business Users\\nProvide support for Analytics Processes monitoring and troubleshooting.\\nIdentify, evaluate and implement external services and tools to support data validation and cleansing\\nLiaise with internal and external clients to fully understand data content\\nGather, understand and document detailed business requirements using appropriate tools and techniques\\nSupport in creating PowerPoints, reports, dashboards and models\\nIndependently determine the appropriate approach for new assignments\\nComplete a variety of atypical assignments\\nSolve a range of straight forward problems\\nBuilds knowledge of the organization, processes and customers\\n\\nQualifications\\nWhat we are looking for?\\nSomeone who is inquisitive and has great problem-solving skills.\\n3+ years core data science/analytics experience\\nHands-on experience of building statistical models like regression, decision tree, random forests and other AI/ML models is a must\\nExperience using R, Python, SAS is mandatory.\\nAbility to write SQL queries, doing cohort analysis, comparative analysis etc.\\nAbility to lead own projects and work independently once given a direction.\\nExperience working directly with business users to build reports, dashboards and solving business questions with data.\\nExperience of working on visualization tools (Tableau/Power BI etc.)\\nUnderstanding about GA360/Adobe/Datorama/CDP/DMP etc.\\n\\nAdditional Information\\nWhat’s on Offer:\\nAn opportunity to work with one of India’s most promising companies in a genuine growth hacking role\\nUnparalleled learning opportunities in the company of ridiculously smart folks with very high levels of expertise in their respective functions\\nFantastically transparent, vibrant and positive work culture\\nFeel like a good fit? We would love to have a chat with you!',\n",
       " \"Job Description\\nRole purpose:\\nThe primary purpose of this role is to deliver analytical / decision services to Vodafone’s businesses across the globe. The role works with OpCo and is a part of the VOIS (Vodafone Shared Services) organisation in India.\\nThe incumbent works on the assigned projects & it's stakeholder to understand the business challenges faced by them. Using expertise in analytics, the incumbent provide structured and data-backed analytics solutions to create bottom-line impact for the business. The role leverages / re-engineers existing solutions to delivery efficiently. The role also demands an innovation-led approach to delivery by using evolving analytical techniques / technologies.\\nThe candidate works with the assigned business stakeholder(s) to agree scope, deliverables, process and expected outcomes from the products and services developed.\\nKey accountabilities and decision ownership:\\nThis is a senior data scientist role. The incumbent has to lead a team of data scientist on a work stream. Has to assign projects & manage stakeholders. Understand the business challenges faced and propose solution. Has to deliver projects in parallel as independent consultant.\\nSupport build & deployment of analytical solutions (models, hypothesis, analyses & scenarios) across the spectrum of analytical maturity - descriptive, inferential, predictive & prescriptive\\nLeverage previously created data models, insights and analyses from across the Vodafone business to drive positive business outcomes\\nDrive efficiencies in how analytical services are delivered, through automation and standardisation of analytical delivery\\nProvide a delightful and “easy to work” experience to the business stakeholders while setting clear expectations\\nCore competencies, knowledge and experience :\\nPhD / Masters in Analytics, Operations Research, Statistics or similar / MBA from a premier B-school\\nMinimum experience of 6 years of experience in building Analytics Solutions\\nExcellent communication & presentation skills with track record of engaging with business project leads\\nFlexibility and Problem solving Ability\\nPrevious experience in Telecom would be a distinct advantage\\nMust have technical / professional qualifications:\\n6+ years of hands on experience in Python with thorough knowledge of various analytics & statistical techniques (Atleast 2 years in Python is mandatory; rest can be in R/SAS/or other analytics tools)\\nConceptual expertise on Machine Learning, Clustering & Segmentation, Binary & Multi-Class Classification, ML Forecasting & Regression Models\\nWorked on minimum of 15 predictive modelling/Advanced Analytics projects across domain with business & value impact\\nExceptional data manipulation and analysis techniques; comfortable using very large (>10’s millions rows) datasets, containing both structured and unstructured data\\nGood to have experience of working & implementing analytics solution in Cloud – GCP/AWS or Big Data technologies (e.g. Hadoop, Hive, Pig, etc.)\",\n",
       " 'Roles and Responsibilities\\nUnderstand clients business objectives and strategy to ensure that analysis work is focused on the areas where most value can be added.\\nCollaborate with stakeholders/ team leaders in order to understand problem statements and design and execute potential solutions.\\nMentor team members and ensure fault-free execution of projects / solutions.\\nIntegration of multiple sources of data working on BigData platforms.\\nPerform Exploratory Data Analysis on large and complex data sets comprising of structured, semi-structured and unstructured data.\\nWork on multiple unstructured problems to deliver insights/ end-to- end solutions and improve our clients- understanding of their customers using analysis / statistics / machine learning algorithms.\\nKeep abreast of the latest developments in the data science space across industries for potential uses.\\nPlease mail your CV to career@torcai.com',\n",
       " 'Job title\\nSr Data Scientist\\nDepartment\\n53 RAF/STARS\\nReport To\\nDeepthi Devarakonda/Simhan Ramakrishnan\\nNo of yrs. of exp\\n5+\\nWork Location\\nPune\\nNo of Positions\\n1\\nIt’s Time For A Change…\\nYour Future Evolves Here\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.\\nAre we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.\\nPosition summary\\nAs an experienced Data Scientist you’ll join a team of data scientists, analysts, and software engineers working to push the boundaries of data science in health care. We like to experiment, iterate, and innovate with technology, from developing new algorithms specific to health care’s challenges, to bringing the latest machine learning practices and applications developed in other industries into the health care world. We know that algorithms are only valuable when powered by the right data, so we focus on fully understanding the problems we need to solve, and truly understanding the data behind them before launching into solutions – ensuring that the solutions we do land on are impactful and powerful\\nEssential functions\\nResearch, conceptualize, and implement analytical approaches and predictive modeling to evaluate scenarios, predict utilization and clinical outcomes, and recommend actions to impact results.\\nManage and execute on the entire model development process, including scope definition, hypothesis formation, data cleaning and preparation, feature selection, model implementation in production, validation and iteration, using multiple data sources.\\nProvide guidance on necessary data and software infrastructure capabilities to deliver a scalable solution across partners and support the implementation of the team’s algorithms and models into Evolent’s product & platform offerings.\\nContribute to the development and publication in major journals, conferences showcasing Evolent’s leadership in healthcare data science.\\nWork closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals\\nProvide guidance to other Data Scientist and Machine Learning Engineers',\n",
       " 'Company Description\\nAutonomIQ is a cloud platform that enables product and IT teams to autonomously test, release and deploy software, thereby increasing velocity of software releases without compromising quality. With pre-built integrations to common web applications and SaaS providers, customers can instantly create test cases, generate test scripts and test data, and execute tests. Using deep-learning and AI algorithms, AutonomIQ detects changes, enables self-healing for test assets and provides advanced diagnostics. In real world situations, AutonomIQ has been shown to provide over ~50% improvement in speed and quality compared to existing tools and techniques.\\n\\nJob Description\\nResponsibilities:\\nDevelop Algorithms in NLP Systems for Intent, Entity detections and contextual understanding\\nWork on solving real world scenarios for user commands and requests, and build scalable systems that solve their problems\\nThink creatively to identify new opportunities and contribute to high quality publications or patents.\\nWork in a highly collaborative environment with teams to deliver systems from prototyping to production level.\\nMust have;\\nHands-on experience on modern NLP Neural Networks e.g. Transformer Models like BERT, RoBERTa, etc to build Intent classification, Named Entity Recognition (NER) and Q&A systems, for both training and inference.\\nExposure to either PyTorch or TensorFlow Deep learning tools and exporting models for inference is preferred.\\nKnowledge of building a robust validation framework for small-sized datasets is a hard requirement.\\n\\nQualifications\\nBE / BTech Only\\n\\nAdditional Information\\nFlexible Working Hours\\nProduct Start Up Culture\\nRemote Work',\n",
       " 'Two positions are currently available in Pune, India and one position is open in Sunnyvale, CA. Title seniority and salary are set to the experience level of the applicant.\\nRole and Responsibilities\\nExecute data mining projects, training and deploying models over a typical duration of 2 -12 months.\\nThe ideal candidate should be able to innovate, analyze the customer requirement, develop a solution in the time box of the project plan, execute and deploy the solution.\\nIntegrate the data mining projects embedded data mining applications in the FogHorn platform (on Docker or Android).\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications:\\nHave analyzed, trained and deployed at least three data mining models in the past. If the candidate did not directly deploy their own models, they will have worked with others who have put their models into production. The models should have been validated as robust over at least an initial time period.\\nThree years of industry work experience, developing data mining models which were deployed and used.\\nProgramming experience in Python is core using data mining related libraries like Scikit-Learn. Other relevant Python mining libraries include NumPy, SciPy and Pandas.\\nData mining algorithm experience in at least 3 algorithms within any of the bullets below:\\ndeep learning (TensorFlow, Convolutional Neural Nets (CNN) or related),\\nprediction (statistical regression, neural nets, deep learning, decision trees, SVM, ensembles),\\nclustering (k-means, DBSCAN or other) or Bayesian networks\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive:\\nSoft Skills\\nSets expectations, develops project plans and meets expectations.\\nExperience adapting technical dialogue to the right level for the audience (i.e. executives) or specific jargon for a given vertical market and job function.\\nTechnical skills\\nCommonly, candidates have a MS or Ph.D. in Computer Science, Math, Statistics or an engineering technical discipline. BS candidates with experience are considered.\\nHave managed past models in production over their full life cycle until model replacement is needed. Have developed automated model refreshing on newer data. Have developed frameworks for model automation as a prototype for product.\\nTraining or experience in Deep Learning, such as TensorFlow, Keras, PyTorch, ONNX, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network architectures. If you don’t have deep learning experience, we will train you on the job.\\nJava, Android development\\nShrinking deep learning models, optimizing to speed up execution time of scoring or inference.\\nOpenCV or other image processing tools or libraries\\nCloud computing: Google Cloud, Amazon AWS or Microsoft Azure.\\nDecision trees like XGBoost or Random Forests is helpful.\\nComplex Event Processing (CEP) or other streaming data as a data source for data mining analysis\\nTime series algorithms from ARIMA to LSTM to Digital Signal Processing (DSP).\\nBayesian Networks (BN), a.k.a. Bayesian Belief Networks (BBN) or Graphical Belief Networks (GBN)\\nExperience with PMML is of interest (see www.DMG.org).\\nVertical experience in Industrial Internet of Things (IoT) applications:\\nEnergy: Oil and Gas, HVAC energy consumption, Wind Turbines\\nManufacturing: Motors, chemical processes, tools, automotive\\nSmart Cities: Elevators, cameras on population or cars, power grid\\nTransportation: Cars, truck fleets, trains\\nHow To Apply\\nTo apply, submit a resume to careers@foghorn.io, with an email subject of either:\\n“Sunnyvale Data Scientist application <name>”, where <name> is the applicant’s name. No “<>” are needed. This assumes you are near enough to commute to Sunnyvale, CA, USA and have a work permit.\\nor “Pune Data Scientist application <name>”, if you are applying for a job in that location in Pune, India.\\nIf you want to be more competitive, address how you meet all the minimum requirements and any bonus qualifications.\\n\\nAbout FogHorn Systems\\nFogHorn is a leading developer of “edge intelligence” software for industrial and commercial IoT application solutions. FogHorn’s Lightning software platform brings the power of advanced analytics and machine learning to the on-premise edge environment enabling a new class of applications for advanced monitoring and diagnostics, machine performance optimization, proactive maintenance and operational intelligence use cases. FogHorn’s technology is ideally suited for OEMs, systems integrators and end customers in manufacturing, power and water, oil and gas, renewable energy, mining, transportation, healthcare, retail, as well as Smart Grid, Smart City, Smart Building and connected vehicle applications.\\nPress: https://www.foghorn.io/press-room/\\nAwards: https://www.foghorn.io/awards-and-recognition/\\n2020 World Economic Forum Technology Pioneer\\n2020 IoT World Awards, Best Edge Computing Solution\\n2020 Golden Bridge Awards, Most Innovative Company of the Year – AI Category\\n2020 IoT Evolution Edge Computing Excellence Award\\n2019 Edge Computing Company of the Year – Compass Intelligence\\n2019 Internet of Things 50: 10 Coolest Industrial IoT Companies – CRN\\n2018 IoT Planforms Leadership Award & Edge Computing Excellence – IoT Evolution World Magazine\\n2018 10 Hot IoT Startups to Watch – Network World. (Gartner estimated 20 billion connected things in use worldwide by 2020)\\n2018 Winner in Artificial Intelligence and Machine Learning – Globe Awards\\n2018 Ten Edge Computing Vendors to Watch – ZDNet & 451 Research\\n2018 The 10 Most Innovative AI Solution Providers – Insights Success\\n2018 The AI 100 – CB Insights\\n2017 Cool Vendor in IoT Edge Computing – Gartner\\n2017 20 Most Promising AI Service Providers – CIO Review\\nOur Series A round was for $15 million. Our Series B round was for $30 million October 2017. Investors include: Saudi Aramco Energy Ventures, Intel Capital, GE, Dell, Bosch, Honeywell and The Hive.\\nAbout the Data Science Solutions team\\nIn 2018, our Data Science Solutions team grew from 4 to 9. We are growing again from 10 t0 13. We work on revenue-generating projects for clients, such as predictive maintenance, time to failure, manufacturing defects. About half of our projects have been related to vision recognition or deep learning. We are not only working on consulting projects but developing vertical solution applications that run on our Lightning platform, with embedded data mining.\\nOur data scientists like our team because:\\nWe care about “best practices”\\nHave a direct impact on the company’s revenue\\nGive or receive mentoring as part of the collaborative process\\nQuestions and challenging the status quo with data is safe\\nIntellectual curiosity balanced with humility\\nPresent papers or projects in our “Thought Leadership” meeting series, to support continuous learning',\n",
       " 'Job Title Data Science\\nTotal Experience 6 - 8 years\\nJob Location Pune\\nNotice Period IMMEDIATELY / 30 DAYS MAX\\nSalary Budget Total exp into 2x to 2.5x\\nCANDIDATES WHO CAN JOIN IMMEDIATELY / 30 DAYS MAX - MAY ONLY APPLY\\nInterview process\\nLevel 1 - Video Technical discussion thru Monjin Panel\\nLevel 2 - HR discussion (Salary check before setting up the Client Interview)\\nLevel 3 - Technical round with End client\\nBelow are Job details\\nExperience: 6 - 8 years\\nOverall 5+ years of Data Science experience\\nStrong hands on Python, Red Shift, Apache Kafka, Spark / Streaming skills\\nData Engineer will have to solve problems such as efficient ETL from MongoDB, MySQL, ProstreSQL ,\\nData leak technology, batch processing, real time processing, warehousing\"\\nWork on the customer requirement\\nProvide Status updates\\nRaise risks on time\\nAdhere to timelines\\nProvide Value add to the customer and ensure customer issues are addressed\\nJob Type: Full-time\\nSalary: Up to ₹500,000.00 per year\\nSchedule:\\nDay shift\\nEvening shift\\nMorning shift\\nExperience:\\ndata science: 6 years (Required)\\nApache Kafka, Spark: 6 years (Required)\\nRed Shift: 6 years (Required)\\npython: 6 years (Required)\\nEducation:\\nSecondary(10th Pass) (Required)\\nSpeak with the employer\\n+91 9850529592',\n",
       " 'Experience : 5 - 7 Years\\nJOB DESCRIPTION\\nShould have a Master’s degree in Statistics, Mathematics, Computer Science\\nResponsibilities Include:\\nInteracting with the stakeholders, within the company and the customers, to understand the needs\\nExploratory analysis from the existing data\\nFormulating the questions to be answered and hypotheses to be tested\\nIdentifying additional data to be collected and third-party data sources that will help the analysis\\nDeveloping data presentations, models and algorithms required\\nUsing data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback\\nProviding inputs and support to software / firmware developers to build the required software components, data structures and dashboards\\nInteract with other project team members to adhere to overall project schedules\\nEnsure Adherence to internal development policies and participating in continually improving existing processes\\nMandatory Technical Abilities:\\nStrong problem-solving skills with an emphasis on product development\\nExperience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets\\nExperience of working with and creating data architectures\\nExperience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)\\nExperience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)\\nProficiency in using query languages such as SQL, Hive\\nExperience with NoSql databases (MongoDB, Cassandra…)\\nKnowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications\\nGood written and verbal communication skills for coordinating across teams\\nAbility to learn and master new technologies and techniques',\n",
       " 'Overview: To be part of with Data Science and Analytics (DSA) team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. It includes simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modelling and machine learning techniques primarily using multiple technologies and big data platforms.\\n\\nRoles and Responsibilities:\\n\\nYour primary role will be to identify and work on high-impact business problems and develop viable solutions through data analysis, predictive modelling, and advanced analytics techniques.\\n\\nExtracts data from multiple sources and creates an analytical data mart.\\n\\nPerforms statistical data analysis on large data sets, resulting in impactful insights and outcomes.\\n\\nLogically integrates information from multiple resources and effectively communicates results to department management.\\n\\nShould have in-depth experience in experimental design, sampling, feature selection, building classifiers, model selection and training, and model interpretation.\\n\\nDevelops ad hoc analyses using standard and advanced statistical techniques (e.g., regression, CHAID, factor analysis, ANOVA, clustering analysis) .\\n\\nCollaborates to implement projects, complete tasks, and fulfil plans to ensure timely and efficient analysis, modelling, evaluation and reporting.\\n\\nTemplatize best in class data-mining processes and reporting.\\n\\nPrepares written analysis and presents findings and recommendations to key business leaders. Communicate changes in business trends to c-level executives and provide guidance as to the overall impact.\\n\\nIdentifies actionable insights, suggests recommendations, and influences the direction of the business by effectively communicating results to cross functional groups.\\n\\nTeam Management:\\n\\nManaged team size of 10 associates with skillsets of data science and analytics\\n\\nQualifying Criteria:\\n\\nBE/B.Tech/M.Sc.,degree in related discipline strongly desired (Mathematics, Statistics, Operations Research)\\n\\n5+ years of relevant experience in analytics, data science and building ML models\\n\\nConceptual understanding of analytical techniques like Linear Regression, Logistic Regression, Time-series models, Classification Techniques, etc.\\n\\nStrong written and verbal communication skills to explain complex analytical methodologies to clients regardless of the clients technical expertise\\n\\nExposure to R, Python, Hive, or other open source languages preferable\\n\\nGood programming knowledge in Relational Databases (MySQL,PL/SQL) and NoSQL Databases, along with know-how about database performances.\\nPowered by JazzHR\\n0LVoiYxIZN',\n",
       " 'Position - SE/SSE - Python+AI+ML+NLP\\nExperience - 5-15 years\\nWork Timings - 12:30 PM - 09:30 PM\\n\\nPython, Artificial Intelligence, Machine Learning, NLP, NLU, Deep Learning, TensorFlow, Keras, SpaCy, NLTK, Image processing, OpenCV, Tesseract',\n",
       " 'Job Location – Pune, India\\nRequired experience – 6-10 Years\\nAbout Innoplexus\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nLead and mentor a small team of data scientists in applying existing learning algorithms and develop new ones\\nDevelop scalable customer-facing solutions over real-world, noisy and unstructured data\\nDevelop highly scalable deep learning algorithms to improve our platform\\nDevelop state-of-the-art machine learning and neural network methodologies to improve our intelligence platform\\nCross-functional collaboration between data science and engineering teams to support the integration of finished algorithms and prototypes into product\\nSupport sales and business development teams to fine-tune client requirements, perform feasibility testing and proposing an approach for solutions\\nWe need you to have:\\nBachelors/Masters/PhD Degree in Computer Science, related Machine Learning field or equivalent from Tier-1 or premier institutes like IIT, IISc, BITS, NIT or globally renowned universities\\nKnowledge On:\\nRelevant Hands-on Experience in any of the below groups:\\nInformation Extraction, Text Mining from Unstructured data\\nComputational Genomics, Bioinformatics\\nStrong in Python programming\\nKnowledge commonly used machine learning tools:, pytorch, scikit-learn, gensim, pandas\\nExperience with major NoSQL products\\nExperience in the domain of life sciences is a plus\\nMust have experience in leading teams\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " 'Roles and Responsibilities - Use data science method and practices to design the solution - Build data pipelines for deep learning model - Design and build machine learning algorithms using tools and technologies like Tensorflow, Python, R and similar technologies - Develop optimized Nural Networks Models - Build and optimize Deep Learning Models - Create reports and dashboards using data visualisation tools and methods\\n\\nQualification - Experience in Machine learning - Experience with Tensorflow/Theano/Torch/Caffe/Keras/Lasagne or similar deep learning framework - Programming experience with R/Python/ - Basic software design and development skills in one or more high level languages (C/C++/Java etc) - Hands-on experience in Deep Learning(CNN, Autoencoders, GAN - General Adversal Network, RNN-Recurrent Neural Networks, LSTMs-Long sort term memory, GRU-Gated Recurrent Units, Restricted Boltzmann Machines etc.)\\n\\nGood to have - Experience in image processing and computer vision, statistics and machine learning - Research experience in Computer vision, image processing, pattern recognition, signal processing - Experience in in the object detection, image analysis, image segmentation\\n\\n5.00-8.00 Years',\n",
       " '5th fastest-growing private company in the Silicon Valley - Series-B funded - EdTech - Computer Networking & AI\\nSecurly, Inc (www.securly.com) was Award by INC 5000 as the 5th fastest-growing private company in the Silicon Valley. Our R&D Engineering team is in Pune, India. Securly is a world-renowned innovator in student safety solutions. We started by building the first cloud-based web filter for schools in 2012 and have continued innovating comprehensive solutions, with AI and machine learning, for student safety - both in school and at home. By pioneering these developments, Securly continues to be a leader in an industry that is continually evolving.\\nIn a few short years, our innovative products and talented people have;\\nEstablished Securly in over 20% of the US market\\nGrown to 11+ products with a presence in EMEA, LATAM, APAC\\nImplemented Securly into 15,000+ schools\\nMonitored more than 5 billion online activities\\nRevolutionized school safety for more than 10 million children\\nSaved the lives of more than 1000+ children\\n\\nSummary\\nAs a Data Scientist/BI Engineer working out of our Pune office and reporting to the Senior Vice President, you will constantly be pushing the boundaries of your role and in the process-you will be redefining what it means to be a \"Business Analyst\".\\nWe will be migrating to a state of the art analytics stack that will being new silos of customer data (product/UI analytics, Ad performance, support analytics, email performance, customer engagement) under your purview. Tools like the ones we are choosing will be the \"norm\" in the Business Intelligence world in the next 3-5 years (many early adopters in Silicon Valley are already moving towards them) and this role will allow you to explore career adjacencies and position yourself for the \"change that is coming\".\\nWhat\\'s in it for you? You will have the opportunity to collaborate with and learn from talented colleagues in our US and India teams. You will have the advantage to work in a very diverse environment that has broader perspectives and deeper ideas.\\nResponsibilities:\\nUse effective text representations to transform natural language into useful features.\\nTrain the developed model and run evaluation experiments.\\nPerform statistical analysis of results and refine models.\\nRemain up-to-date on machine learning research and trends, challenge current best thinking, test theories, evaluate feature concepts and iterate rapidly\\nOwn the full flow of very challenging data problems starting with data discovery/collection/cleaning through the production implementation of resilient models that can perform using noisy real-world data, owning the deliverables and managing the priorities/timelines\\nPosition Requirements\\n4+years experience in a similar role\\nA proven track record of successfully implementing deep learning and machine learning models on real-world structured and unstructured data.\\nSolid fundamentals, knowledge of machine learning / deep learning algorithms, classification, clustering, regression, SVM,CNN, RNN, Bayesian modeling, probability theory , linear algebra, Bayesian statistics, and information retrieval.\\nHands-on experience in NLP tasks such as Sentiment Analysis, Name Entity Recognition, Text Summarization, Intent Detection, Topic Modeling.\\nKnowledge of text representation (e.g. n-grams, bag of words, embeddings etc.),statistics and classification algorithms.\\nFamiliarity with rule-based NLP, including CFG, constituency and dependency parsing, as well as their statistical variants. Experiences using NLTK, spaCy, or Stanford NLP.\\nUnderstanding of Transformers, ELMo, BERT ,OCR is preferred but not required.\\nHands-on experience with Scikit-learn, Tensorflow, Keras, or PyTorch Framework.\\nBachelors Degree, Masters or PhD in Computer Science, Statistics, Applied Math, Engineering with an emphasis on Machine Learning is preferred\\n\\nPreferred Qualifications:\\nSuccess in competitive Machine Learning competitions such as Kaggle Competitions\\nStrong combination of theoretical knowledge and hands-on experience in feature selection, dimensionality reduction, statistical techniques, classification models, machine learning / deep learning algorithms and data visualization.\\nExperience/proficiency in at least one compiled/object oriented programming language e.g. Python\\nExperience in managing and coordinating complex cross-functional software teams and projects\\nHighly motivated team player with an entrepreneurial spirit and strong communication and collaboration skills, self-starter with willingness to learn, master new technologies and clearly communicate results to technical and nontechnical audiences\\nWe are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\n\\nAbout Securly\\n2-minute product demo - https://vimeo.com/245108303\\nSecurly\\'s 6 years of student safety disruption - http://bit.ly/Securly_6yr_roadmap\\nSecurly technology & Milestones - http://bit.ly/Securly-Tech-and-Milestones\\nSecurly is the only company offering a unified solution that deploys a unique mix of AI and machine learning in conjunction with expert human analysts on call 24/7 to report bullying and self-harm incidents.\\nHolding many patents and growing rapidly at 969%, Securly serves more than 20% of the primary and secondary student populations across the United States and many global markets. With offices in California, North Carolina, India, UK, and Mexico, Securly offers career opportunities worldwide.\\nOur Mission\\nOur mission is to cultivate a safer digital world for children. We see the internet as a space for learning and exploration and social media as an opportunity to develop emotional intelligence and social competence. The internet brings many benefits to children\\'s development and education but also presents many concerns.\\nOur goal is not to censor the internet but to mitigate the adverse effects on kids. We develop solutions to keep children safe online wherever they are - at school, at home, or out in the world. From tools to help adults create a safer internet to an AI that recognizes signs of bullying and even intuits risks of self-harm, Securly continues to build technology and innovate solutions to support children\\'s online safety and healthy digital lives for children.\\nPre-IPO stock options\\nCompany-sponsored health benefits (Family and Parents are covered)\\n21 days PTO + 10 Holidays\\nFun Company-sponsored events/outings on a Quarterly/Annual basis\\nFree Breakfast every day\\nGame room equipped with X-box, Foosball table, carrom board, Jenga, etc.\\nNewly remodeled Office with beautiful open floor plan\\nOur culture and people value empowerment, continual learning and growth, partnership, and execution\\nRecognized as a Top Places to work',\n",
       " 'Who We Are?\\nRanked as one of the fastest growing technology companies on the Deloitte Fast 50 India 2014 survey, at Talentica our vision is to be the # 1 company doing core product development work for start-ups ! So far we’ve built over 130+ innovative products and have worked with some of the hottest start-ups across the globe. We hire technology addicts and encourage them “to create” by understanding the product vision, business context and practical usage.\\nWhat we do?\\nBuild products - Be it building a payment gateway from scratch or Setting up world’s # 1 ad Serving platform or Innovating premium video-mailing software for corporates, we transform our customer’s ideas into successful products.\\nLearn Continuously - Innovation is our DNA. We explore and add value to our customer’s business by being on top of technology.\\nOur Culture\\nColleagues, who inspire, challenge and match up – We’ve flocked some of the finest engineering potential in the country, we hire ONLY from a select few premium engineering institutes\\nOpen work culture - Openness and Transparency is the way we are, we express, hear and enable your ease and growth\\nYour Role\\nBuild Talentica as a thought leader in ML / AI technologies\\nAdd value to our customers through technical innovation and building technical competence across Talentica in ML / AI.\\nTop Accountabilities\\nSolving customer problems through innovation and technical expertise\\nIdentify new tools and technology areas that would benefit our customers and ensure that some of them get adapted by the customers\\nShowcase our AI / ML expertise by presenting in conferences and by contributing to open source projects\\nBuilding a team of Data Scientists / ML experts.\\nBuilding a culture of innovation and technology expertise\\nAuthorities\\nOwn the budget for the team\\nOwn all staffing decisions for the team\\nTeam participation in conferences - as per the allocated budget\\nDesired Skills and Experience\\nStrong expertise and / or demonstrated ability to learn, architect and implement solutions to AI / ML problems\\nBeing hands on with an ability to build quick prototypes to demonstrate new technology / algorithm benefits to our customers and internal stakeholders.\\nPositive “Can do” attitude a must. Results oriented with discipline to deliver on commitments.\\nLeadership to motivate the team and to set a high bar for technical excellence.\\nStrong orientation towards customer satisfaction and high quality of deliverables\\nExperience of speaking at conferences\\nTechnical background\\nIndustry experience in solving problems in Machine Learning, Deep Learning, Natural Language processing, Statistical modelling and Visualization techniques\\nShould have published papers in or been a speaker at A / B level conferences\\nExperience in Python, R etc.\\nPhD in Computer science, Mathematics or related disciplines from a premium institute',\n",
       " 'AppZen is the leader in AI software for finance teams. Over 1,800 global enterprises use AppZen to automate manual finance processes, reduce expenditures, and gain real-time insights into their business spend trends. Our patented software technology delivers AI deep learning, semantic analysis, and Star Match™, the only automated spend validation that processes intelligence from thousands of data sources, documents, and images to understand financial transactions and make decisions based on finance policies. AppZen is the platform of choice for today’s digital CFO and their teams, including four of the top five banks, four of the top ten media companies, four of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and six of the top ten software providers.\\n\\nWe’ve taken off this year! Since releasing our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor, and have been recognized as one of the fastest-growing technology companies in the market. In 2019 we received $50 million in Series C funding from Lightspeed, Redpoint and other leading venture capital firms.\\n\\nWe are looking for a Data Scientist to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about natural language understanding and machine translation, AppZen is the right place for you to apply and grow your skills.\\nMust-Have:\\nSolid understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.\\nAbility to analyze a wide variety of data: structured and unstructured, observational and experimental, to drive system designs and product implementations.\\nExpert knowledge of a statistical computing language such as Python or R Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.\\nEnsure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.\\nManage your own process: identify and execute on high impact projects, triage external requests, and make sure you bring projects to conclusion in time for the results to be useful.\\nExcellent written and verbal technical communication skills; communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions.\\nM.Sc. or M.E. or M.Tech in Computer Science, Engineering, Statistics, or other relevant technical fieldMust have 4-6 years of industry experience.\\nAble to work onsite in Pune, IN\\nYou are a team player\\nCome as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.',\n",
       " \"Job brief\\nClimate Connect Technologies is developing a marketing automation platform through which an electricity retailer may apply a suite of proprietary ML algorithms to optimize outcomes across a range of channels and touch points. We require the services of a data science professional who can design and implement various AI/ML models that optimize the performance, quality, and reliability of the product\\nThis is a data science and ML focused position. You are expected to offer substantial expertise in the field of data preprocessing, feature engineering, and ML modeling, as well as an aptitude for bigpicture, multi-disciplinary thinking. You are analytical, process-driven, detail-oriented, and a good communicator. This position offers a potential pathway to leading an entire ML expert team.\\nResponsibilities\\nTranslate high-level problems and key objectives into granular modelrequirements.\\nDefine acceptance criteria that are well structured, detailed, andcomprehensive.\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nEnsure tracking of appropriate events/metrics, so that monitoring is timely and rigorous\\nDrive the response to the discovery of regressions or failures, by undertaking various exercises (e.g. debugging, RCA, etc.) as needed\\nStay up-to-date on evolutions in best practice, tooling, and strategies in the ML space.\\nRequirements\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow 2.0, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders.\\nFlair for using the right metrics to measure model performance, quality, and reliability.\\nAbility to think critically and conceptually about the role of each feature/development unit in the achievement of the product’s goals.\\nAptitude for and interest in taking ownership of the roadmap (and achievements) of a product.\\nWillingness to embrace the start-up mindset: Ambition, adaptability, and a get-it-done approach.\\nExperience with consumer marketing, or utilities markets is a plus.\\nExperience with semi-remote or fully distributed teams is aplus.\\nGood to have knowledge of backend technologies Message Queues,IPC.\\nGood to have knowledge of working with cloud providers like AWS and Digital Ocean.\\nLocation:\\nPune / Delhi\\nExperience:\\n3 - 6 years in Data Science or Machine Learning\\nContact:\\nInterested candidates can share their CV on mentioned email id: hr@climate-connect.com\\nStructure of take-home assignment:\\nPart I - Data Science problem on model building. Code submission via email.\\nPart II - Report on approach taken, final model description and performance metrics.\",\n",
       " \"We are looking for talented Data Scientist with a minimum 5 years of experience in Machine Learning & Data Science to join fast paced software development team.\\nDesired Skills:\\nMinimum 5 years of experience as Data Scientist\\nBachelors/ Masters Degree\\nKey skills:\\nML\\nNLP\\nDeep Learning\\nKeras\\nPython / Java\\nWell versed with Machine Learning algorithms, Deep Learning - RNN, LSTM, CNN, Attention, Language models (Transfer Learning)\\nExpected Start Date: 4/1/2021\\nJob Type: Full-time\\nSalary: ₹600,000.00 - ₹2,200,000.00 per year\\nBenefits:\\nFlexible schedule\\nHealth insurance\\nWork from home\\nSchedule:\\nDay shift\\nFlexible shift\\nExperience:\\nwork: 4 years (Required)\\ntotal work: 5 years (Required)\\nEducation:\\nBachelor's (Required)\",\n",
       " \"Job Description\\nRole purpose:\\nThe primary purpose of this role is to deliver analytical / decision services to Vodafone’s businesses across the globe. The role works with OpCo and is a part of the VOIS (Vodafone Shared Services) organisation in India.\\nThe incumbent works on the assigned projects & it's stakeholder to understand the business challenges faced by them. Using expertise in analytics, the incumbent provide structured and data-backed analytics solutions to create bottom-line impact for the business. The role leverages / re-engineers existing solutions to delivery efficiently. The role also demands an innovation led approach to delivery through the use of evolving analytical techniques / technologies.\\nThe candidate works with the assigned business stakeholder(s) to agree scope, deliverables, process and expected outcomes from the products and services developed.\\nKey accountabilities and decision ownership:\\nSupport build & deployment of analytical solutions (models, hypothesis, analyses & scenarios) across the spectrum of analytical maturity - descriptive, inferential, predictive & prescriptive\\nLeverage previously created data models, insights and analyses from across the Vodafone business to drive positive business outcomes\\nDrive efficiencies in how analytical services are delivered, through automation and standardisation of analytical delivery\\nProvide a delightful and “easy to work” experience to the business stakeholders while setting clear expectations\\nCore competencies, knowledge and experience :\\nMasters in Analytics, Operations Research, Statistics or similar / MBA from a premier B-school\\nMinimum experience of 4 years in Analytics from a top B-school or T-School of India\\nExcellent communication & presentation skills with track record of engaging with business project leads\\nKnowledge of financial planning, accounting practices and Forecasting\\nFlexibility and problem solving\\nPrevious experience in Telecom & Financial analytics would be a distinct advantage\\nMust have technical / professional qualifications:\\nHands on experience in Analytical tools like Python with through knowledge of various machine learning, analytical & statistical techniques\\nExperience in using SQL to extract large amount of data\\nExceptional data manipulation and analysis techniques; comfortable using very large (>10’s millions rows) datasets, containing both structured and unstructured data\\nAdequate exposure to Data visualisation tools like Tableau, Qlikview, SAS Visual Analytics, etc.\\nExperience in use of Cloud – GCP/AWS or Big Data technologies (e.g. Hadoop, Hive, Pig, etc.) is desirable\\nKey performance indicators:\\nAnalytics solutions models (Proof of concepts, Proofs of value, Automated models)\\nCreation of reusable, defined analytical products (including documentation and, where appropriate, training)\\nVisualisation of results / Presentation of output\",\n",
       " 'Job Description\\nWe are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.\\nResponsibilities\\nSelecting features, building and optimizing classifiers using machine learning techniques.\\nData mining using state-of-the-art methods.\\nExtending company’s data with third party sources of information when needed.\\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\\nProcessing, cleansing, and verifying the integrity of data used for analysis.\\nDoing ad-hoc analysis and presenting results in a clear manner.\\nCreating automated anomaly detection systems and constant tracking of its performance.\\nRequired Skills\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\nExperience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.\\nExperience with data visualization tools, such as D3.js, GGplot, etc.\\nProficiency in using query languages such as SQL, Hive, Pig.\\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase.\\nExperience with Hadoop or similar distributed computing and storage platforms.\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nGood scripting and programming skills.\\nExceptional analytical abilities,creativity and attention to details.\\nGood organizational and problem solving skills.\\nGood team player who is a self-starter and well organized.\\nStrong oral and written communication skills.\\nRequired Education\\nGraduate degree in Math, Statistics, Computer Science, or other quantitative discipline.\\nPlease email your resume to careers@gtpltech.com',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\n\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " \"Softnautics is looking for Machine Learning Engineer who is technically strong, possesses hands-on experience in Machine Learning Solutions in domain of Audio, Video, IoT. He/she should have some experience working with complex (SoC / Microprocessor) Embedded Systems is mandatory for this role. The role will be part of Embedded department in which there is a very strong culture of teamwork, cooperation and collaboration\\nResponsibilities\\nMentor and build the team of 2 or more junior engineers\\nDocumentation and Process adherence\\nTechnical ownership for module (s) and / or project (s) and / or domain (s)\\nEffort estimation, planning, customer Interaction\\nRequired Skills:\\n2 - 5 years of experience with Machine Learning Solutions in the domain of Audio, Video, IoT\\n1 - 3 years of experience working with Complex (SoC / Microprocessors) Embedded System\\nStrong at programming, debugging and communication\\nSound knowledge of version control and bug tracking systems – GIT, JIRA, Perforce, CVS etc.\\nHands on experience on Machine Learning Algorithms – Conventional and Deep Learning (must have)\\nHands on experience working on Machine Learning Platforms / Frameworks like TensorFlow, TensorFlow Lite, Keras, Caffe/2, MxNet, pyTorch etc.\\nSound knowledge of Cloud Computing tools’ cognitive ML services – Google cloud, AWS, Azure, IBM Cloud etc.\\nExperience working on Large datasets – Learning, tuning, deployment on Embedded Platform\\nFamiliar with Deep Learning Compilers – CPUs, GPUs, FPGAs\\nShould be able to work in aggressive, high pressure environment\\nExcellent written and verbal communication\\nSelf-starter, problem-solving mentality, and creative thinker\\nDesirable Skills:\\nExperience of mentoring 2 or 3 engineers\\nQuality process – CMMi, Agile Scrum\\nGood knowledge of working with Open source software packages is beneficial and preferred\\nPositive attitude\\nReady to switch between domains based on the project needs\\nApplication Deadline: 31/1/2021\\nExpected Start Date: 15/1/2021\\nJob Type: Full-time\\nSalary: ₹500,000.00 - ₹1,200,000.00 per year\\nBenefits:\\nFlexible schedule\\nHealth insurance\\nPaid time off\\nWork from home\\nSchedule:\\nDay shift\\nMonday to Friday\\nExperience:\\nMachine learning: 3 years (Required)\\ntotal work: 3 years (Required)\\nEducation:\\nBachelor's (Required)\\nApplication Question:\\nCurrent CTC:\\nNotice Period:\\nCurrent Location:\\nEmail ID:\\nWork Remotely:\\nNo\\nCOVID-19 Precaution(s):\\nRemote interview process\\nVirtual meetings\",\n",
       " 'As a data scientist, you will be responsible to:\\ndevelop and/or enhance the data science capabilities in KBR’s digitalization solutions\\ndevelop new data science solutions for KBR’s clients\\nfollow the applicable standards\\ncollaborate with KBR’s artificial intelligence (AI) and machine learning (ML) partners during solution development and project implementation\\nEducation\\nBachelor’s degree in applied mathematics, data science and statistics\\nBachelor’s degree in chemical, petrochemical or mechanical engineering or equivalent, with specialization in data science\\nJob Location\\nPune, India\\nExperience\\n6-10 years of hands on experience in designing and/or developing analytics, data science, data mining, and machine learning solutions\\nExperience in implementing AI/ML solutions for the process industries, especially oil & gas\\nPrimary Skills\\nExcellent knowledge of data mining algorithms, including supervised and unsupervised machine learning techniques\\nExcellent knowledge of statistical modeling techniques, such as gradient boosting, decision trees, multivariate regressions, logistic regressions, neural network, random forest, support vector machine, Naive Bayes, time series, and optimization methods\\nExpertise in one or more programming languages such as R, Python, or Scala\\nExperience in creating analytics pipelines to pre-process, create and visualize machine learning models\\nHands on experience in configuring at least one data science platform, such as SAS analytics, Tibco, RapidMiner or other equivalent\\nHands on experience with any of the key deep learning frameworks, such as TensorFlow, Caffe, Pytorch, or Keras\\nExperience with technologies required to undertake analysis of large data sources and/or big data (SQL, parallelization, Hadoop, Spark, etc.)\\nSecondary Skills\\nImplementation experience in two or more of the following software products:\\nData historians, such as OSIsoft PI, Honeywell PHD, Yokogawa Exaquantum, or other equivalent\\nSQL Server or Oracle databases\\nAsset Performance Management software packages, such as Bentley, Maximo, Meridium or other equivalent\\nJob Description Outline\\nDesign and develop AI/ML solutions for the process industries, including but not limited to:\\nPerform exploratory data analysis to gain a deeper understanding of the issue\\nUnderstand business data content and how they can be used in data analysis\\nBuild statistical, machine learning, and/or optimization models\\nDevelop and apply required advanced statistical, machine learning, models and algorithms to classify structured and/or unstructured data\\nCollaborate with internal stakeholders to design and develop analytical solutions\\nTest the performance of machine learning models\\nOther qualifications\\nExcellent written and verbal communications skills\\nProven ability to communicate technical issues to non-technical individuals\\nAbility to travel to other KBR offices and/or client sites and work on site for short and longer periods, in accordance with project requirements\\nBuild and maintain effective client relationships\\nProven experience in working in large, multicultural teams\\nExcellent team skills',\n",
       " \"Job Title: DATA SCIENTIST\\nTotal Experience: 5 TO 10 YEARS\\nJob Location: PUNE (KHARADI)\\nNotice Period: IMMEDIATE TO 30 DAYS.\\nSalary Budget: Upto 45 lacs\\nBelow are the job Details: -\\nIdeal Candidate\\nThe ideal candidate will come with hands-on experience as a Data Scientist having a Data-oriented personality with a good scripting and programming skills. He/she should have hands-on expertise on data science toolkits, specifically in using R for statistical modeling and machine learning.\\nHands-on expertise and exposure in R packages, Shiny for interactive Web applications & machine learning algorithms, model building, statistical modelling, predictive modelling environments. This person will have a proven track record of delivering successful technology solutions to business clients preferably in financial services.\\nRequirements\\n5-10 years of experience in R (preference), Python, or SAS for complex data\\nmanipulation, statistical analysis, and machine learning.\\nExperience with Forecasting, Time Series Analysis, statistical modeling, etc.\\nExperience translating high-level project requirements into technical tasks.\\nData manipulation and data engineering experience involving structured and\\nunstructured data.\\nData manipulation expertise involving data extractions, data matching between multiple systems, transformations, cleansing, and loading.\\nProficient in using Shiny to build interactive web apps straight using R.\\nExperience with big data and cloud platforms especially GCP.\\nExperience in developing predictive, prescriptive, optimization, and forecasting models.\\nExperience in interpreting results from statistical and mathematical models.\\nExperience in advance data visualizations and interpretation.\\nExperience with data visualization tools (e.g., Tableau, Bokeh, D3) or elastic stac (Kibana).\\nExperience with modern machine learning libraries, including Keras, TensorFlow, PyTorch, MXNet.\\nNatural Language Processing (NLP) experience a plus.\\nCollaborative and decisive with strong communication and interpersonal abilities.\\nExpertise in working with large and complex datasets to create dashboards and data visualizations\\nStrong analytics background: Hands on experiences in statistical modeling (e.g. regression model, test and control etc.), machine learning, etc.\\nMultitasker: Good project management and communication skills that can work multiple projects at same time using minimum guidance.\\nResponsibilities\\nUnderstand business requirements to translate business problems into analytics\\nProblems and construct analysis road-map based on the business context\\nManage large volumes of structured and unstructured data, extract & clean data to make it amenable for analysis\\nAnalyse big data using statistics, econometrics, mathematics, operations research, and text mining techniques\\nDevelop good visualization to communicate business insights from analysis and make actionable recommendations\\nHelp deploy analytics solutions and enable tracking of business outcomes to measure return on investment\\nKeep up with cutting edge analytics techniques and tools in the continuously evolving area of decision science\\nPresent/Advise/Interpret/Justify on analytics solutions from a project to Client/Internal Stakeholder\\nJob Type: Full-time\\nSalary: Up to ₹500,000.00 per year\\nSchedule:\\nDay shift\\nEvening shift\\nMorning shift\\nNight shift\\nExperience:\\nTableau, Bokeh, D3) or elastic stack (Kibana): 5 years (Required)\\nBFSI domain experience: 5 years (Required)\\nPython or SAS: 5 years (Preferred)\\nKeras, TensorFlow, PyTorch, MXNet: 5 years (Required)\\nDeep Learning Experience: 5 years (Required)\\nExperience in R: 5 years (Required)\\nNeural Learning Experience: 5 years (Required)\\nEducation:\\nBachelor's (Required)\\nSpeak with the employer\\n+91 9850529592\",\n",
       " \"PhonePe's mission is to make it easy and secure for our customers to use and manage their\\nmoney via a purely digital, mobile experience. The data science team at PhonePe\\ncontributes to this mission by using the power of big data and advances in machine learning\\nto help various stakeholders in the business. Most important of these are our users, to whom\\nwe seek to provide the best possible experience by showing them information and insights\\nthat are most relevant and interesting to them. Additionally, we ensure that our own business\\npartners also benefit from how they can best serve customers via the PhonePe platform.\\nFinally, we help our own teams understand and utilize data to improve their own processes\\nand planning efforts. The volume of data, and the variety of problems mean that data\\nscientists can have a visible and a real, positive impact on millions of our users.\\nResponsibilities\\nWe plan to expand our data science team, and we are looking for senior data scientists who\\nwill work on applications related to financial services. They will work in a dynamic\\nenvironment, and with cross-functional teams to assist those teams in every possible\\nmanner to ensure that our products help our users derive most value. They will be expected\\nto work with product, business, and engineering teams to\\nhelp them understand what data science can do for them and set the right\\nexpectations,\\nanalyze large volumes of data, and implement and deploy solutions as necessary,\\nbe able to clearly communicate results and recommendations to various stakeholders,\\nevaluate the effectiveness of the solutions and improve upon them in a continuous\\nmanner. We expect them to have a mix of a strong technical background, the ability\\nto understand the business implications of their work, and the ability to empathize\\nwith our users and work towards helping PhonePe give them the best experience,\\nand\\nhelp and mentor junior members to become better data scientists.\\nQualifications\\nA Bachelor's or higher degree in a quantitative discipline (computer science, statistics,\\nengineering, applied mathematics)\\n6-7 years relevant work experience with a Bachelor’s degree, or 3-4 years relevant\\nexperience with a Master's degree\\nSpecific technical skills include\\no Expertise in Java, Python, R, shell scripting languages.\\no Expertise in querying relational, non-relational, graph databases.\\no Ability to clearly communicate and work with people of different backgrounds.\\no Experience in big data technologies (Spark, MapReduce, Pig, Hive)\\no Experience using machine learning (structured, text, video data) libraries\\n(preferably in Python), deep learning (Tensorflow, PyTorch)\\no Experience using visualization libraries\\nGood to have: Hands-on experience with source control and deployment tools (Git,\\nJenkins, etc.).\",\n",
       " 'At Ajira AI, we focus on developing smart products that leverage artificial intelligence algorithms. We build complex cloud based and mobile business applications. However make no mistake, we solve very significant systems problems along the way. Our products work across our customers ecosystems to help people.\\nWe’re very pleased to be expanding our development team. We’re a close knit group of innovators that have previously launched very successful start-ups. Our track record building successful technology businesses and reputation is helping us grow and we’re now looking to add experienced Data Science Developers to our team in Pune.\\nYou have hands-on experience using AI frameworks such as Tensor Flow and Keras in a work setting. You have at least a couple of years of work experience using Python/R. You’ve used multiple classification models and Pandas, Numpy, Matlab etc. You are proficient at using algorithms such as Logistic Regression, Multiple Linear Regression, Random Tree, Support Vector Machine, Naive Bayes etc. You have a track record of demonstrated success in business problem solving. Data visualization experience is a plus.\\nYou are the kind of developer that other developers seek out to solve their technical difficulties. You keep up to date with what’s happening in the data science world and know the differences between classification, regression, clustering and time series. You know the limitations of each algorithm. You are motivated to learn new technologies.\\nThat’s a high level summary of what we’re looking for but before we dive into the detail, you’ll probably want to know who you are going to be working for and what your work environment will be like:\\nWho we are:\\nWe are an Insurtech company with a core mission of leveraging artificial intelligence algorithms and techniques to solve complex business problems. We like to think that solving these business issues for our customers helps make them better at serving their customers. Some of our applications help people who may be injured or have been in an accident. In our opinion that’s a worthwhile pursuit. While our current business vertical is insurance, we see our technology expanding to other business verticals with time. Our founders have a solid track record of starting technology companies and making them successful.\\nWe love what we do and not the least of which is that we have the opportunity to try out and ‘play’ with the latest advances in tools and technology.\\nWho you’ll be working with:\\nWe are a collaborative, tight knit group of contributors. While we’re headquartered in the Chicago area in Lisle, our software lab is located in Pune, India. We have decades of experience working with remote teams. We’re looking to expand our Developer positions in Pune, India.\\nYou’ll find our CTO a joy to work with; someone with excellent technical skills, always willing to mentor, roll up his sleeves and get deep into the technical issues. He possesses rare technical insight and no matter the day or time he’s always willing to contribute to move things forward. Our CEO is a rare combination of technical and business skills with remarkable vision and the ability to easily cut through the most complex issues to find the simplest answer. You’ll be working side by side with them and the rest of our technical team in what will be an amazing opportunity for you.\\nYour work environment:\\nWe are a group of talented and dedicated individuals and through we are a start-up, we have a ‘no insane hours’ rule.\\nWe are not clock watchers. If you need to take off for a couple of hours to visit the doctor or dentist go ahead. We look at what you’re accomplishing not how many hours you spend in the office. We conduct meetings on a daily basis with our Chicago office so some overlapping hours are necessary.\\nOur Pune office space is modest. We prefer to pay you more than prevailing market wages rather than spend money on fancy office space.\\nOur work is performed using the latest technology and tools. We’re constantly innovating and improving our delivery capability by building our own components and tools as well as licensing new tech that we’ve tried and works in our environment.\\nWe are an open, collaborative work environment and suggestions are not just welcome, they are appreciated. You’ll find our product roadmap is exciting and full of opportunity.\\nYour skills:\\nYou keep up with technology changes and trends\\nYou are a top notch Developer whose code not only solves complex issues but is written in such a way that the rest of your team is able to understand. This means that you’re not shy about documenting your code and you understand the need for coding standards and why everyone should use them\\nYou are motivated. You have amazing debugging skills and are quick at identifying and fixing bugs\\nYou are skilled at development with Python/R and using Ai frameworks such as Tensor Flow and Keras\\nProficient in the use of Pandas, Numpy, Matlib, MatPlotlib and commonly used libraries\\nYou understand ML algorithms such as Support Vector Machine, Naïve Bayes, Logistic Regression, Multiple Linear Regression, Random Tree, XgBoost etc thoroughly\\nYou are quick to understand business problems and understand how to classify problems that exist in large datasets\\nAny data visualization experience is a plus as is any background in statistics\\nYou have developed, implemented and supported a ML application successfully at work\\nHow to apply:\\nSend a pdf of your resume to careers@ajiraai.com\\nThis post can also be found at http://www.ajiraai.com/careers\\nWe look forward to hearing from you\\nIf you’re not available or interested in this position but know someone who might be a good fit, please pass this along\\nAjira AI is an equal opportunity employer and we do not discriminate on basis of caste, creed, gender, religion, state of origin, color, race or personal orientation. You are an Indian citizen or authorized to work legally in India.',\n",
       " 'Location : Pune\\nAlgoAnalytics is looking for a Senior Data Scientist who has the passion for hardcore ML and AI work. Minimum 3 years of experience in AI/MI including Deep Learning is required. Deep understanding & proficiency in developing Deep Learning models will be an added advantage. The candidate is expected to manage multiple data science projects from technical as well delivery perspective.\\nRole and Responsibility :\\nTransform business problems into data problems and identify relevant and meaningful solutions\\nPrepare proposals for client projects: detailed description about technical aspects of the proposals such as approaches/algorithms to be tried out as a solution, describing input/output interfaces, tools and technologies to be used/explored, efforts estimation, etc.\\nAttending client calls in the initial phase of the projects: to understand the problem and discuss approaches, data availability, issues/questions from our side, etc.\\nCreating PPTs (e.g. to include technical contents)\\nDesigning a solution (for internal or client projects) from technology and algorithm perspective\\nResearch and build machine-learning models\\nUnderstanding and implementing recent research work/papers in deep learning\\nContribute to the development of research that is based on key insights and findings from the studies\\nProject management (both client-facing as well as team-facing)\\nTroubleshooting for any project (related to machine learning / programming / technology) whenever required\\nIdentifying resources for various tasks like mentoring, hiring, initiatives, tech support, project management, skill management, etc.\\nProvide guidance and training to team members and less experienced data scientists\\nParticipate in management level efforts if and when required\\nQualifications :\\n3+ years of experience in Machine Learning\\nBachelors/Masters in Computer Engineering/Science.\\nBachelors/Masters in Engineering/Mathematics/Statistics with sound knowledge of programming and computer concepts.\\nSkills :\\nStrong Python/ programming skills\\nGood conceptual understanding of Machine Learning/Deep Learning/Natural Language Processing\\nStrong verbal and written communication skills.\\nShould be able to manage team, meet project deadlines and interface with clients.\\nShould be able to work across different domains and quickly ramp up the business processes & flows & translate business problems into the data solutions\\nIf you have the above skills, desire to keep learning, and would like to grow in a dynamic environment, drop your cv to hr@algoanalytics.com',\n",
       " 'Greeting to All :\\nWe are an IT Company Based in Pune Looking for Fresher Interns.\\nare available for Machine Learning ,AI and data Science offline or online internship\\nhave relevant skills and interests\\ncan start the internship Before FEB 2021\\nare available for duration of 3 to 6 Month months\\nhave already graduated or are currently in any year of study.\\nEducation ... Any Pursuing or passout student can Join.\\nExperience .. No Experience Required\\nSkills .html,or Basic Knowledge\\nJob Type: Internship\\nBenefits:\\nFlexible schedule\\nSchedule:\\nDay shift',\n",
       " 'Looking for full time & part time Data Science/Machine Learning Trainers to teach in classroom(offline) in our Viman Nagar branch in Pune.\\nWe are a leading software training institute in Pune with our branches in Pimple Saudagar and Viman Nagar. We have been providing exclusive training on Data Science, Machine Learning & Artificial Intelligence since 2014.\\nIf interested, please send your updated resume to the given email id with the subject line \"Data Science Trainer\".\\nhttps://marsiantech.com/\\nMobile: 7028052110\\nJob Types: Full-time, Part-time, Contract\\nSalary: ₹240,000.00 - ₹400,000.00 per year\\nBenefits:\\nFlexible schedule\\nExperience:\\nAnalytics: 1 year (Required)\\nMachine Learning: 1 year (Required)\\nR: 1 year (Required)\\nPython: 1 year (Required)\\nLocation:\\nPune, Maharashtra (Required)\\nIndustry:\\nEducation & Instruction\\nWork Remotely:\\nNo\\nSpeak with the employer\\n+91 7028052110',\n",
       " 'Employment type: Undefined term\\nFull-time/part-time position: Full time\\nJob Code USA/CA:\\nConsultant- Data analytics\\n\\n[[Pune]]\\n\\n\\nAt Konecranes, we believe that great customer experience is built on the people behind the Konecranes name – people committed to providing our customers with lifting equipment and services that lift their businesses. Everything we do, we do with passion and drive.\\nWe believe diversity drives business success and is the foundation for our growth. We welcome different backgrounds and skills that enrich our community and we promote a place where we can ALL be ourselves. This is what makes Konecranes a unique place to work.\\n\\nDesignation: Consultant – Data Analytics\\n\\nExperience: 1-3 years\\n\\nBase\\n\\nCompany Name: Konecranes and Demag Private Limited\\n\\nWebsite: http://www.konecranes.com\\n\\nJob description -\\nWhat we expect from you:\\nExcellent written and verbal communication in English.\\n1.5-3 Years of Production support and development experience in Business Intelligence and Analytics area (ETL / ELT).\\nStrong understanding of Databases (Microsoft SQL Server).\\nKnowledge on Data marts, Data vault, data loads (batch, incremental) and effective monitoring,\\nExperience on at least one end-to-end implementation, from data source system towards Business Intelligence and Analytics or Portals.\\nExperience with various optimizing techniques in improving the performance of the data loads and database.\\nKnowledge of Azure cloud-based data platforms and solutions.\\nGood to have Knowledge of DENODO data science tool.\\nKnowledge and understanding of ITIL processes and support activities.\\nMin 1-year experience on at least one support project.\\nExperience in handling and resolving Incidents based on priority and severity.\\nAzure certifications would be an added advantage\\nHands on knowledge Agile methodology & Devops way or working would be an added advantage\\n\\nYour responsibilities are:\\nHandling Service Requests and Incidents\\nResolving data load issues and be able to resolve them within limited time window.\\nAny adhoc request coming from other applications for monitoring / support in any environments.\\nProviding monthly report on Interfaces/system availability.\\nParticipate into Critical Incident resolution and communication process.\\nDevelop healthy professional customer relationship\\nAnalyze the repetitive Incidents and addressing the root causes in order to either reduce/ eliminate repetitive Incidents or enhance efficiency in handling those.\\nEnsure to fulfil the KPIs like SLA, TAT, Ageing, Quality Audits, etc. based on management’s expectations and guidance\\nAlign and realign actions based on customers’ feedbacks, inputs from management.\\nAssist peers, superiors, other IT staff members in day to day activities whenever appropriate.\\nDeliver any other tasks as per superior’s instructions and guidance\\nAwareness about ISO 14001, 45001 requirements’\\n\\nGeneral skills / requirements\\nCustomer service attitude\\nExcellent inter-personnel skills with a proven ability to work independently and in team environment as per situation\\nGood communication (verbal, written) and presentation skills, preferably exposed to interaction with global stakeholder\\nAnalytical and problem-solving mindset\\nKnowledge about ITIL and ITSM tool(s)\\nKonecranes, Inc. and its affiliates will not accept resumes from external recruiters or agencies without a Service Agreement and Agency Portal submission. Any resumes sent without a Service Agreement and Agency Portal submission with Konecranes, Inc. are void of any fees and free for internal use. Applicable Konecranes data protection obligations are the responsibility of the agency.\\nKonecranes is a world-leading group of Lifting Businesses™, serving a broad range of customers. We are truly a global company with 18,000 employees at 600 locations in 50 countries. For over 80 years, we have been dedicated to improving the efficiency and performance of businesses in all types of industries. We believe that sustainable growth is a result of a strong responsible performance. Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Other Protected Category.',\n",
       " 'Job Description\\nLooking for an experienced Data Scientist with hands-on experience in a variety of data analysis methods, ML, DL algorithms using Python.\\nExperience: 10+ years\\nLocation\\nPune/Bangalore(IND)\\nSan Jose/Aguora Hills(CA, USA)\\n\\nSend us your resume at careers@nutanxt.com',\n",
       " 'Location: Hyderabad\\n\\nJob Description:\\nTake responsibility for managing our master data set, developing reports, and troubleshooting data issues. To do well in this role, you need a very fine eye for detail, experience as a data analyst, and a deep understanding of the popular data analysis tools and databases.\\n\\nSpecific Responsibilities:\\nManaging master data, including creation, updates, and deletion;\\nHelping develop reports and analysis;\\nManaging and designing the reporting environment, including data sources, security, and metadata;\\nSupporting initiatives for data integrity and normalization;\\nAssessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems;\\nTroubleshooting the reporting database environment and reports;\\nTraining end-users on new reports and dashboards;\\nProviding technical expertise in data storage structures, data mining, and data cleansing.\\n\\nQualifications:\\nDegree in IT, Computer Science or Engineering, Statistics, Applied Mathematics or Business Analytics and related fields;\\n5 to 7 years of work experience in data analytics and data virtualization field;\\nStrong aptitude for numbers and comfortable handling large volume of data;\\nGood at programming skills in Python, R or SQL included machine learning;\\nExperience working with Elasticsearch and data virtualization tools like Kibana/Grafana;\\nEffective communication skills;\\nGood team player and adept at handling pressure',\n",
       " 'Job title\\n\\nSr NLP & Text Mining Data Scientist\\n\\nDepartment\\n\\nAnalytics & Data Science\\n\\nReport To\\nDeepthi Devarakonda / Simhan Ramakrishnan\\n\\nNo of yrs. of exp\\n\\n7+ years\\n\\nWork Location\\n\\nPune, MH, India\\n\\nNo of Positions\\n\\n1\\n\\nAssigned Recruiter\\n\\nTalent Partner\\n\\nVersion Control\\nVersion No.\\n\\nDate\\n\\nRemark\\n\\nUpdated by\\n\\n1.0\\n\\n5/4/2020\\n\\nInitial Version\\n\\nSR\\n\\nIt’s Time For A Change…\\nYour Future Evolves Here\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.\\nAre we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.\\n\\nPosition summary\\n\\nThe Sr. NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.\\nEssential functions\\n\\nThe Sr. NLP Text Mining Scientist / Engineer will have the opportunity to lead a team, shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.\\n7+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)\\nDevelop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs\\nGather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU\\nApply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms\\nOwn the Natural Language and Text Mining products — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services\\nWork closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals\\nProvide mentoring to other Data Scientist and Machine Learning Engineers\\nStrong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches\\nStrong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture\\nGood understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations\\nAdditional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics\\nExperience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala)\\nStrong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years\\nHands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)\\nThorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)\\nHands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 5+ years\\nUnderstanding business use cases and be able to translate them to team with a vision on how to implement\\nIdentify enhancements and build best practices that can help to improve the productivity of the team.\\n\\nNice to Have\\nMedical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)\\nLucene, Solr, Elastic Search experience\\nExperience with Kubernetes and dockers\\nExperience building REST API’s for AI work and knowledge of microservices architecture\\nParticipation in open source community projects\\n\\nAcademic Qualification:\\nMaster’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)\\nCompletion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics\\nA PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program\\nPublication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Job Description\\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 506,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com\\n\\nProject Role :Application Developer\\nProject Role Description :Design, build and configure applications to meet business process and application requirements.\\nManagement Level :9\\nWork Experience :6-8 years\\nWork location :Pune\\nMust Have Skills :Data Science,No Technology Specialization\\nGood To Have Skills :\\nJob Requirements :\\n\\nKey Responsibilities : A : Data Scientists to support the analysis of the data and the preparation of additional big data and data analysis technologies within the CRCO area of CS in Zurich, like data modelling, wrangling, pipelines implementation or building machine learning models on the Palantir Foundry stack B : to identify the best methodologies in analytics/Machine Learning for the specific problem to solve C : Ability to develop reliable, autonomous and scalable data pipelines\\n\\nTechnical Experience : A :Review and IT testing of methodology to match clients via name matching B : At least 5 years of experience in Data Analytics and related tools eg Python, R, Java/Scala, Spark and SQL, ideally combined with a technology background in big-data, non-relational data bases and expertise with Bash C : Experience working in agile environments D : Familiarity with assembling and analyzing data sets from disparate sources, applying quantitative methodologies, computational frameworks and systems\\n\\nProfessional Attributes : A : Excellent Communication Skill\\n\\nEducational Qualification : A : Minimum of 15 years full time education\\n\\nQualifications\\n15 years of full time education',\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " 'We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\\n\\nResponsibilities:\\nDesigning and deploying deep learning algorithms and predictive models\\nDevelop custom data models and algorithms to apply to data sets\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\\nDevelop processes and tools to monitor and analyze model performance and data accuracy\\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\\n\\nQualifications:\\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\\nAbility to drive a project and work both independently and in a team',\n",
       " 'Job Description\\nLooking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data science techniques, doing statistical analysis, text mining and building high quality prediction systems integrated with our products.\\nStrong Experience on : R , Python, AIML, Text Analystics, NLP.\\nQualification : Statistics / Mathematics\\nResponsibilities\\nAnalyze data using state-of-the-art methods\\nSelecting features, building and optimizing classifiers using machine learning techniques\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating automated anomaly detection systems and constant tracking of its performance\\nSkills and Qualifications\\nBachelor’s Degree OR Post Graduate degree in Statistics , Operations Research, Economics, Mathematics , Computer Science.\\n4+ years of experience in machine learning techniques and algorithms.\\nExcellent understanding of algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n3+ years of experience with common data science toolkits, such as R and Python . Excellence in at least one of these is highly desirable\\nExcellent understanding of neural networks, decision systems, and experience in text mining is a big plus.\\nVery good applied statistics skills, such as distributions, statistical testing, regression, etc.\\nExperience with data visualization tools such as Tableau would be desirable.\\nAbility to learn and build competencies in new tools and statistical techniques whenever required\\nAbility to explain and defend his/her ideas and analysis, while still able to understand the merits of others’ opinions.\\nStrong analytical and problem-solving skills\\nExcellent verbal & written communication skills\\nHighly motivated, organized, proactive self-starter and a team player.\\nData-oriented personality\\nAll Locations:\\nIND-Pune-Old Mumbai Pune Hwy',\n",
       " 'Job Brief\\nML Engineer\\nMandatory Skill - Python, Machine Learning, Data Science and Analystics\\nGood to have skills - AWS or Azure OR GCP, Kafka and Spark\\nExperiece Required - 3 to 8 Years',\n",
       " 'Job Location\\nMountain View, California or Pune, India\\nRole and Responsibilities\\nEngineering core machine learning capabilities in our IoT platform by building tools and high-performance infrastructure for running ML models at the edge.\\nCreating supervised and semi-supervised ML models for the platform.\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications.\\nExperience in Agile software development with strong programming experience in C++ or Python.\\nExperience in building and using high-speed data processing infrastructure and tools.\\nHave used or developed high performance C++ packages (e.g. LAPACK, BLAS, YOLO etc.)\\nSome experience with real-time stream processing data systems.\\nTraining in data mining or statistics, enough to understand the context of developing software to be used by data scientists.\\nAlgorithm experience in the families of predictive algorithms (regression, neural nets, decision trees) and clustering algorithms (k-means or other).\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive.\\nStrong experience with C++ development and high-performance computing.\\nCython programming or written python wrapper for C++.\\nExperience developing Machine Learning software infrastructure, algorithms and libraries.\\nTraining or experience in Deep Learning, such as Keras, TensorFlow, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network.\\nExperience with PMML or PFA or TFR is of interest (see www.DMG.org).\\nHow To Apply\\nTo apply, submit resume and cover letter to HR at jobs@foghorn.io.\\nIndicate how you meet core and bonus qualifications including two to four detailed paragraphs of three data mining projects you have deployed.',\n",
       " 'Design right ML & AI algorithms and manage the solution implementation end-to-end\\nManage client engagements and ensure project delivery as per client expectations\\nPresent solutions in intuitive and effective way to the audience\\nActively participate in all activities leading to career progression participating in sales pitches, training in house\\nresources, coaching staff on best practices, client relationship management etc.\\n\\nSkills & Qualifications:\\n5 to 9 years of experience of working on Data Science assignments\\nProgression from individual contributor to lead over the period of employment\\nKnowledge of data pre-processing steps uploading, creating master data set, extracting right data from external\\nsources, data quality checks and corrections and Database Management\\nGood grasp of Statistical / ML Algorithms ( KNN, Naive Bayes, SVM, Recommender systems, Random Forest, Decision Trees etc. )\\nExperience of implementation of two or more of Logistic Regression, Recommendation Engines, NLP/Text Analysis,\\nAnomaly Detection, Clustering, Random Forest etc. on a live project on Python\\nExposure to Deep Learning ( CNN, RNN, LSTM etc ) with experience in PoCs , projects, solutions\\nKnowledge of GAN (Generative Adversarial Networks)\\nComfortable with creating Visualizations on any one standard software\\nHigh learning orientation and openness to learn and implement solutions\\nExperience of working on large datasets. Knowledge of Spark or Hadoop is a plus\\nAbility to define solutions for vague problems\\nGood Project Management & Communication Skills both technical and non-technical audience.\\nTechnical Skills:\\nPython ( and python libraries like NumPy, SciPy, MatploitLib,Pandas, NLTK, Spacy ) ,\\nScikit Learn , Keras, Caffe, Tensorflow, CoreNLP/OpenNLP, OpenCV\\nBasic Database knowledge, SQL\\nEducation Type\\nB.E/B.Tech/BS-Computer Science\\nJob Type\\nFull Time-Regular\\nExperience Level\\nSenior Level\\nTotal Years of Exp\\n5-9',\n",
       " 'Employment type: Undefined term\\nFull-time/part-time position: Full time\\nJob Code USA/CA:\\nConsultant- Data analytics\\n\\n[[Pune]]\\n\\n\\nAt Konecranes, we believe that great customer experience is built on the people behind the Konecranes name – people committed to providing our customers with lifting equipment and services that lift their businesses. Everything we do, we do with passion and drive.\\nWe believe diversity drives business success and is the foundation for our growth. We welcome different backgrounds and skills that enrich our community and we promote a place where we can ALL be ourselves. This is what makes Konecranes a unique place to work.\\n\\nDesignation: Consultant – Data Analytics\\n\\nExperience: 1-3 years\\n\\nBase\\n\\nCompany Name: Konecranes and Demag Private Limited\\n\\nWebsite: http://www.konecranes.com\\n\\nJob description -\\nWhat we expect from you:\\nExcellent written and verbal communication in English.\\n1.5-3 Years of Production support and development experience in Business Intelligence and Analytics area (ETL / ELT).\\nStrong understanding of Databases (Microsoft SQL Server).\\nKnowledge on Data marts, Data vault, data loads (batch, incremental) and effective monitoring,\\nExperience on at least one end-to-end implementation, from data source system towards Business Intelligence and Analytics or Portals.\\nExperience with various optimizing techniques in improving the performance of the data loads and database.\\nKnowledge of Azure cloud-based data platforms and solutions.\\nGood to have Knowledge of DENODO data science tool.\\nKnowledge and understanding of ITIL processes and support activities.\\nMin 1-year experience on at least one support project.\\nExperience in handling and resolving Incidents based on priority and severity.\\nAzure certifications would be an added advantage\\nHands on knowledge Agile methodology & Devops way or working would be an added advantage\\n\\nYour responsibilities are:\\nHandling Service Requests and Incidents\\nResolving data load issues and be able to resolve them within limited time window.\\nAny adhoc request coming from other applications for monitoring / support in any environments.\\nProviding monthly report on Interfaces/system availability.\\nParticipate into Critical Incident resolution and communication process.\\nDevelop healthy professional customer relationship\\nAnalyze the repetitive Incidents and addressing the root causes in order to either reduce/ eliminate repetitive Incidents or enhance efficiency in handling those.\\nEnsure to fulfil the KPIs like SLA, TAT, Ageing, Quality Audits, etc. based on management’s expectations and guidance\\nAlign and realign actions based on customers’ feedbacks, inputs from management.\\nAssist peers, superiors, other IT staff members in day to day activities whenever appropriate.\\nDeliver any other tasks as per superior’s instructions and guidance\\nAwareness about ISO 14001, 45001 requirements’\\n\\nGeneral skills / requirements\\nCustomer service attitude\\nExcellent inter-personnel skills with a proven ability to work independently and in team environment as per situation\\nGood communication (verbal, written) and presentation skills, preferably exposed to interaction with global stakeholder\\nAnalytical and problem-solving mindset\\nKnowledge about ITIL and ITSM tool(s)\\nKonecranes, Inc. and its affiliates will not accept resumes from external recruiters or agencies without a Service Agreement and Agency Portal submission. Any resumes sent without a Service Agreement and Agency Portal submission with Konecranes, Inc. are void of any fees and free for internal use. Applicable Konecranes data protection obligations are the responsibility of the agency.\\nKonecranes is a world-leading group of Lifting Businesses™, serving a broad range of customers. We are truly a global company with 18,000 employees at 600 locations in 50 countries. For over 80 years, we have been dedicated to improving the efficiency and performance of businesses in all types of industries. We believe that sustainable growth is a result of a strong responsible performance. Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Other Protected Category.',\n",
       " 'Job Description\\nLooking for an experienced Data Scientist with hands-on experience in a variety of data analysis methods, ML, DL algorithms using Python.\\nExperience: 10+ years\\nLocation\\nPune/Bangalore(IND)\\nSan Jose/Aguora Hills(CA, USA)\\n\\nSend us your resume at careers@nutanxt.com',\n",
       " 'Location: Hyderabad\\n\\nJob Description:\\nTake responsibility for managing our master data set, developing reports, and troubleshooting data issues. To do well in this role, you need a very fine eye for detail, experience as a data analyst, and a deep understanding of the popular data analysis tools and databases.\\n\\nSpecific Responsibilities:\\nManaging master data, including creation, updates, and deletion;\\nHelping develop reports and analysis;\\nManaging and designing the reporting environment, including data sources, security, and metadata;\\nSupporting initiatives for data integrity and normalization;\\nAssessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems;\\nTroubleshooting the reporting database environment and reports;\\nTraining end-users on new reports and dashboards;\\nProviding technical expertise in data storage structures, data mining, and data cleansing.\\n\\nQualifications:\\nDegree in IT, Computer Science or Engineering, Statistics, Applied Mathematics or Business Analytics and related fields;\\n5 to 7 years of work experience in data analytics and data virtualization field;\\nStrong aptitude for numbers and comfortable handling large volume of data;\\nGood at programming skills in Python, R or SQL included machine learning;\\nExperience working with Elasticsearch and data virtualization tools like Kibana/Grafana;\\nEffective communication skills;\\nGood team player and adept at handling pressure',\n",
       " 'Job title\\n\\nSr NLP & Text Mining Data Scientist\\n\\nDepartment\\n\\nAnalytics & Data Science\\n\\nReport To\\nDeepthi Devarakonda / Simhan Ramakrishnan\\n\\nNo of yrs. of exp\\n\\n7+ years\\n\\nWork Location\\n\\nPune, MH, India\\n\\nNo of Positions\\n\\n1\\n\\nAssigned Recruiter\\n\\nTalent Partner\\n\\nVersion Control\\nVersion No.\\n\\nDate\\n\\nRemark\\n\\nUpdated by\\n\\n1.0\\n\\n5/4/2020\\n\\nInitial Version\\n\\nSR\\n\\nIt’s Time For A Change…\\nYour Future Evolves Here\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.\\nAre we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.\\n\\nPosition summary\\n\\nThe Sr. NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.\\nEssential functions\\n\\nThe Sr. NLP Text Mining Scientist / Engineer will have the opportunity to lead a team, shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.\\n7+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)\\nDevelop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs\\nGather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU\\nApply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms\\nOwn the Natural Language and Text Mining products — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services\\nWork closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals\\nProvide mentoring to other Data Scientist and Machine Learning Engineers\\nStrong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches\\nStrong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture\\nGood understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations\\nAdditional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics\\nExperience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala)\\nStrong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years\\nHands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)\\nThorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)\\nHands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 5+ years\\nUnderstanding business use cases and be able to translate them to team with a vision on how to implement\\nIdentify enhancements and build best practices that can help to improve the productivity of the team.\\n\\nNice to Have\\nMedical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)\\nLucene, Solr, Elastic Search experience\\nExperience with Kubernetes and dockers\\nExperience building REST API’s for AI work and knowledge of microservices architecture\\nParticipation in open source community projects\\n\\nAcademic Qualification:\\nMaster’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)\\nCompletion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics\\nA PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program\\nPublication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Job Description\\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 506,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com\\n\\nProject Role :Application Developer\\nProject Role Description :Design, build and configure applications to meet business process and application requirements.\\nManagement Level :9\\nWork Experience :6-8 years\\nWork location :Pune\\nMust Have Skills :Data Science,No Technology Specialization\\nGood To Have Skills :\\nJob Requirements :\\n\\nKey Responsibilities : A : Data Scientists to support the analysis of the data and the preparation of additional big data and data analysis technologies within the CRCO area of CS in Zurich, like data modelling, wrangling, pipelines implementation or building machine learning models on the Palantir Foundry stack B : to identify the best methodologies in analytics/Machine Learning for the specific problem to solve C : Ability to develop reliable, autonomous and scalable data pipelines\\n\\nTechnical Experience : A :Review and IT testing of methodology to match clients via name matching B : At least 5 years of experience in Data Analytics and related tools eg Python, R, Java/Scala, Spark and SQL, ideally combined with a technology background in big-data, non-relational data bases and expertise with Bash C : Experience working in agile environments D : Familiarity with assembling and analyzing data sets from disparate sources, applying quantitative methodologies, computational frameworks and systems\\n\\nProfessional Attributes : A : Excellent Communication Skill\\n\\nEducational Qualification : A : Minimum of 15 years full time education\\n\\nQualifications\\n15 years of full time education',\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " 'We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\\n\\nResponsibilities:\\nDesigning and deploying deep learning algorithms and predictive models\\nDevelop custom data models and algorithms to apply to data sets\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\\nDevelop processes and tools to monitor and analyze model performance and data accuracy\\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\\n\\nQualifications:\\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\\nAbility to drive a project and work both independently and in a team',\n",
       " 'Job Description\\nLooking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data science techniques, doing statistical analysis, text mining and building high quality prediction systems integrated with our products.\\nStrong Experience on : R , Python, AIML, Text Analystics, NLP.\\nQualification : Statistics / Mathematics\\nResponsibilities\\nAnalyze data using state-of-the-art methods\\nSelecting features, building and optimizing classifiers using machine learning techniques\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating automated anomaly detection systems and constant tracking of its performance\\nSkills and Qualifications\\nBachelor’s Degree OR Post Graduate degree in Statistics , Operations Research, Economics, Mathematics , Computer Science.\\n4+ years of experience in machine learning techniques and algorithms.\\nExcellent understanding of algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n3+ years of experience with common data science toolkits, such as R and Python . Excellence in at least one of these is highly desirable\\nExcellent understanding of neural networks, decision systems, and experience in text mining is a big plus.\\nVery good applied statistics skills, such as distributions, statistical testing, regression, etc.\\nExperience with data visualization tools such as Tableau would be desirable.\\nAbility to learn and build competencies in new tools and statistical techniques whenever required\\nAbility to explain and defend his/her ideas and analysis, while still able to understand the merits of others’ opinions.\\nStrong analytical and problem-solving skills\\nExcellent verbal & written communication skills\\nHighly motivated, organized, proactive self-starter and a team player.\\nData-oriented personality\\nAll Locations:\\nIND-Pune-Old Mumbai Pune Hwy',\n",
       " 'Job Brief\\nML Engineer\\nMandatory Skill - Python, Machine Learning, Data Science and Analystics\\nGood to have skills - AWS or Azure OR GCP, Kafka and Spark\\nExperiece Required - 3 to 8 Years',\n",
       " 'Job Location\\nMountain View, California or Pune, India\\nRole and Responsibilities\\nEngineering core machine learning capabilities in our IoT platform by building tools and high-performance infrastructure for running ML models at the edge.\\nCreating supervised and semi-supervised ML models for the platform.\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications.\\nExperience in Agile software development with strong programming experience in C++ or Python.\\nExperience in building and using high-speed data processing infrastructure and tools.\\nHave used or developed high performance C++ packages (e.g. LAPACK, BLAS, YOLO etc.)\\nSome experience with real-time stream processing data systems.\\nTraining in data mining or statistics, enough to understand the context of developing software to be used by data scientists.\\nAlgorithm experience in the families of predictive algorithms (regression, neural nets, decision trees) and clustering algorithms (k-means or other).\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive.\\nStrong experience with C++ development and high-performance computing.\\nCython programming or written python wrapper for C++.\\nExperience developing Machine Learning software infrastructure, algorithms and libraries.\\nTraining or experience in Deep Learning, such as Keras, TensorFlow, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network.\\nExperience with PMML or PFA or TFR is of interest (see www.DMG.org).\\nHow To Apply\\nTo apply, submit resume and cover letter to HR at jobs@foghorn.io.\\nIndicate how you meet core and bonus qualifications including two to four detailed paragraphs of three data mining projects you have deployed.',\n",
       " 'Design right ML & AI algorithms and manage the solution implementation end-to-end\\nManage client engagements and ensure project delivery as per client expectations\\nPresent solutions in intuitive and effective way to the audience\\nActively participate in all activities leading to career progression participating in sales pitches, training in house\\nresources, coaching staff on best practices, client relationship management etc.\\n\\nSkills & Qualifications:\\n5 to 9 years of experience of working on Data Science assignments\\nProgression from individual contributor to lead over the period of employment\\nKnowledge of data pre-processing steps uploading, creating master data set, extracting right data from external\\nsources, data quality checks and corrections and Database Management\\nGood grasp of Statistical / ML Algorithms ( KNN, Naive Bayes, SVM, Recommender systems, Random Forest, Decision Trees etc. )\\nExperience of implementation of two or more of Logistic Regression, Recommendation Engines, NLP/Text Analysis,\\nAnomaly Detection, Clustering, Random Forest etc. on a live project on Python\\nExposure to Deep Learning ( CNN, RNN, LSTM etc ) with experience in PoCs , projects, solutions\\nKnowledge of GAN (Generative Adversarial Networks)\\nComfortable with creating Visualizations on any one standard software\\nHigh learning orientation and openness to learn and implement solutions\\nExperience of working on large datasets. Knowledge of Spark or Hadoop is a plus\\nAbility to define solutions for vague problems\\nGood Project Management & Communication Skills both technical and non-technical audience.\\nTechnical Skills:\\nPython ( and python libraries like NumPy, SciPy, MatploitLib,Pandas, NLTK, Spacy ) ,\\nScikit Learn , Keras, Caffe, Tensorflow, CoreNLP/OpenNLP, OpenCV\\nBasic Database knowledge, SQL\\nEducation Type\\nB.E/B.Tech/BS-Computer Science\\nJob Type\\nFull Time-Regular\\nExperience Level\\nSenior Level\\nTotal Years of Exp\\n5-9',\n",
       " 'Employment type: Undefined term\\nFull-time/part-time position: Full time\\nJob Code USA/CA:\\nConsultant- Data analytics\\n\\n[[Pune]]\\n\\n\\nAt Konecranes, we believe that great customer experience is built on the people behind the Konecranes name – people committed to providing our customers with lifting equipment and services that lift their businesses. Everything we do, we do with passion and drive.\\nWe believe diversity drives business success and is the foundation for our growth. We welcome different backgrounds and skills that enrich our community and we promote a place where we can ALL be ourselves. This is what makes Konecranes a unique place to work.\\n\\nDesignation: Consultant – Data Analytics\\n\\nExperience: 1-3 years\\n\\nBase\\n\\nCompany Name: Konecranes and Demag Private Limited\\n\\nWebsite: http://www.konecranes.com\\n\\nJob description -\\nWhat we expect from you:\\nExcellent written and verbal communication in English.\\n1.5-3 Years of Production support and development experience in Business Intelligence and Analytics area (ETL / ELT).\\nStrong understanding of Databases (Microsoft SQL Server).\\nKnowledge on Data marts, Data vault, data loads (batch, incremental) and effective monitoring,\\nExperience on at least one end-to-end implementation, from data source system towards Business Intelligence and Analytics or Portals.\\nExperience with various optimizing techniques in improving the performance of the data loads and database.\\nKnowledge of Azure cloud-based data platforms and solutions.\\nGood to have Knowledge of DENODO data science tool.\\nKnowledge and understanding of ITIL processes and support activities.\\nMin 1-year experience on at least one support project.\\nExperience in handling and resolving Incidents based on priority and severity.\\nAzure certifications would be an added advantage\\nHands on knowledge Agile methodology & Devops way or working would be an added advantage\\n\\nYour responsibilities are:\\nHandling Service Requests and Incidents\\nResolving data load issues and be able to resolve them within limited time window.\\nAny adhoc request coming from other applications for monitoring / support in any environments.\\nProviding monthly report on Interfaces/system availability.\\nParticipate into Critical Incident resolution and communication process.\\nDevelop healthy professional customer relationship\\nAnalyze the repetitive Incidents and addressing the root causes in order to either reduce/ eliminate repetitive Incidents or enhance efficiency in handling those.\\nEnsure to fulfil the KPIs like SLA, TAT, Ageing, Quality Audits, etc. based on management’s expectations and guidance\\nAlign and realign actions based on customers’ feedbacks, inputs from management.\\nAssist peers, superiors, other IT staff members in day to day activities whenever appropriate.\\nDeliver any other tasks as per superior’s instructions and guidance\\nAwareness about ISO 14001, 45001 requirements’\\n\\nGeneral skills / requirements\\nCustomer service attitude\\nExcellent inter-personnel skills with a proven ability to work independently and in team environment as per situation\\nGood communication (verbal, written) and presentation skills, preferably exposed to interaction with global stakeholder\\nAnalytical and problem-solving mindset\\nKnowledge about ITIL and ITSM tool(s)\\nKonecranes, Inc. and its affiliates will not accept resumes from external recruiters or agencies without a Service Agreement and Agency Portal submission. Any resumes sent without a Service Agreement and Agency Portal submission with Konecranes, Inc. are void of any fees and free for internal use. Applicable Konecranes data protection obligations are the responsibility of the agency.\\nKonecranes is a world-leading group of Lifting Businesses™, serving a broad range of customers. We are truly a global company with 18,000 employees at 600 locations in 50 countries. For over 80 years, we have been dedicated to improving the efficiency and performance of businesses in all types of industries. We believe that sustainable growth is a result of a strong responsible performance. Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Other Protected Category.',\n",
       " 'Job Description\\nLooking for an experienced Data Scientist with hands-on experience in a variety of data analysis methods, ML, DL algorithms using Python.\\nExperience: 10+ years\\nLocation\\nPune/Bangalore(IND)\\nSan Jose/Aguora Hills(CA, USA)\\n\\nSend us your resume at careers@nutanxt.com',\n",
       " 'Location: Hyderabad\\n\\nJob Description:\\nTake responsibility for managing our master data set, developing reports, and troubleshooting data issues. To do well in this role, you need a very fine eye for detail, experience as a data analyst, and a deep understanding of the popular data analysis tools and databases.\\n\\nSpecific Responsibilities:\\nManaging master data, including creation, updates, and deletion;\\nHelping develop reports and analysis;\\nManaging and designing the reporting environment, including data sources, security, and metadata;\\nSupporting initiatives for data integrity and normalization;\\nAssessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems;\\nTroubleshooting the reporting database environment and reports;\\nTraining end-users on new reports and dashboards;\\nProviding technical expertise in data storage structures, data mining, and data cleansing.\\n\\nQualifications:\\nDegree in IT, Computer Science or Engineering, Statistics, Applied Mathematics or Business Analytics and related fields;\\n5 to 7 years of work experience in data analytics and data virtualization field;\\nStrong aptitude for numbers and comfortable handling large volume of data;\\nGood at programming skills in Python, R or SQL included machine learning;\\nExperience working with Elasticsearch and data virtualization tools like Kibana/Grafana;\\nEffective communication skills;\\nGood team player and adept at handling pressure',\n",
       " 'Job title\\n\\nSr NLP & Text Mining Data Scientist\\n\\nDepartment\\n\\nAnalytics & Data Science\\n\\nReport To\\nDeepthi Devarakonda / Simhan Ramakrishnan\\n\\nNo of yrs. of exp\\n\\n7+ years\\n\\nWork Location\\n\\nPune, MH, India\\n\\nNo of Positions\\n\\n1\\n\\nAssigned Recruiter\\n\\nTalent Partner\\n\\nVersion Control\\nVersion No.\\n\\nDate\\n\\nRemark\\n\\nUpdated by\\n\\n1.0\\n\\n5/4/2020\\n\\nInitial Version\\n\\nSR\\n\\nIt’s Time For A Change…\\nYour Future Evolves Here\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.\\nAre we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.\\n\\nPosition summary\\n\\nThe Sr. NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.\\nEssential functions\\n\\nThe Sr. NLP Text Mining Scientist / Engineer will have the opportunity to lead a team, shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.\\n7+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)\\nDevelop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs\\nGather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU\\nApply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms\\nOwn the Natural Language and Text Mining products — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services\\nWork closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals\\nProvide mentoring to other Data Scientist and Machine Learning Engineers\\nStrong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches\\nStrong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture\\nGood understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations\\nAdditional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics\\nExperience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala)\\nStrong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years\\nHands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)\\nThorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)\\nHands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 5+ years\\nUnderstanding business use cases and be able to translate them to team with a vision on how to implement\\nIdentify enhancements and build best practices that can help to improve the productivity of the team.\\n\\nNice to Have\\nMedical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)\\nLucene, Solr, Elastic Search experience\\nExperience with Kubernetes and dockers\\nExperience building REST API’s for AI work and knowledge of microservices architecture\\nParticipation in open source community projects\\n\\nAcademic Qualification:\\nMaster’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)\\nCompletion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics\\nA PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program\\nPublication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Job Description\\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 506,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com\\n\\nProject Role :Application Developer\\nProject Role Description :Design, build and configure applications to meet business process and application requirements.\\nManagement Level :9\\nWork Experience :6-8 years\\nWork location :Pune\\nMust Have Skills :Data Science,No Technology Specialization\\nGood To Have Skills :\\nJob Requirements :\\n\\nKey Responsibilities : A : Data Scientists to support the analysis of the data and the preparation of additional big data and data analysis technologies within the CRCO area of CS in Zurich, like data modelling, wrangling, pipelines implementation or building machine learning models on the Palantir Foundry stack B : to identify the best methodologies in analytics/Machine Learning for the specific problem to solve C : Ability to develop reliable, autonomous and scalable data pipelines\\n\\nTechnical Experience : A :Review and IT testing of methodology to match clients via name matching B : At least 5 years of experience in Data Analytics and related tools eg Python, R, Java/Scala, Spark and SQL, ideally combined with a technology background in big-data, non-relational data bases and expertise with Bash C : Experience working in agile environments D : Familiarity with assembling and analyzing data sets from disparate sources, applying quantitative methodologies, computational frameworks and systems\\n\\nProfessional Attributes : A : Excellent Communication Skill\\n\\nEducational Qualification : A : Minimum of 15 years full time education\\n\\nQualifications\\n15 years of full time education',\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " 'We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\\n\\nResponsibilities:\\nDesigning and deploying deep learning algorithms and predictive models\\nDevelop custom data models and algorithms to apply to data sets\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\\nDevelop processes and tools to monitor and analyze model performance and data accuracy\\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\\n\\nQualifications:\\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\\nAbility to drive a project and work both independently and in a team',\n",
       " 'Job Description\\nLooking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data science techniques, doing statistical analysis, text mining and building high quality prediction systems integrated with our products.\\nStrong Experience on : R , Python, AIML, Text Analystics, NLP.\\nQualification : Statistics / Mathematics\\nResponsibilities\\nAnalyze data using state-of-the-art methods\\nSelecting features, building and optimizing classifiers using machine learning techniques\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating automated anomaly detection systems and constant tracking of its performance\\nSkills and Qualifications\\nBachelor’s Degree OR Post Graduate degree in Statistics , Operations Research, Economics, Mathematics , Computer Science.\\n4+ years of experience in machine learning techniques and algorithms.\\nExcellent understanding of algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n3+ years of experience with common data science toolkits, such as R and Python . Excellence in at least one of these is highly desirable\\nExcellent understanding of neural networks, decision systems, and experience in text mining is a big plus.\\nVery good applied statistics skills, such as distributions, statistical testing, regression, etc.\\nExperience with data visualization tools such as Tableau would be desirable.\\nAbility to learn and build competencies in new tools and statistical techniques whenever required\\nAbility to explain and defend his/her ideas and analysis, while still able to understand the merits of others’ opinions.\\nStrong analytical and problem-solving skills\\nExcellent verbal & written communication skills\\nHighly motivated, organized, proactive self-starter and a team player.\\nData-oriented personality\\nAll Locations:\\nIND-Pune-Old Mumbai Pune Hwy',\n",
       " 'Job Brief\\nML Engineer\\nMandatory Skill - Python, Machine Learning, Data Science and Analystics\\nGood to have skills - AWS or Azure OR GCP, Kafka and Spark\\nExperiece Required - 3 to 8 Years',\n",
       " 'Job Location\\nMountain View, California or Pune, India\\nRole and Responsibilities\\nEngineering core machine learning capabilities in our IoT platform by building tools and high-performance infrastructure for running ML models at the edge.\\nCreating supervised and semi-supervised ML models for the platform.\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications.\\nExperience in Agile software development with strong programming experience in C++ or Python.\\nExperience in building and using high-speed data processing infrastructure and tools.\\nHave used or developed high performance C++ packages (e.g. LAPACK, BLAS, YOLO etc.)\\nSome experience with real-time stream processing data systems.\\nTraining in data mining or statistics, enough to understand the context of developing software to be used by data scientists.\\nAlgorithm experience in the families of predictive algorithms (regression, neural nets, decision trees) and clustering algorithms (k-means or other).\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive.\\nStrong experience with C++ development and high-performance computing.\\nCython programming or written python wrapper for C++.\\nExperience developing Machine Learning software infrastructure, algorithms and libraries.\\nTraining or experience in Deep Learning, such as Keras, TensorFlow, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network.\\nExperience with PMML or PFA or TFR is of interest (see www.DMG.org).\\nHow To Apply\\nTo apply, submit resume and cover letter to HR at jobs@foghorn.io.\\nIndicate how you meet core and bonus qualifications including two to four detailed paragraphs of three data mining projects you have deployed.',\n",
       " 'Design right ML & AI algorithms and manage the solution implementation end-to-end\\nManage client engagements and ensure project delivery as per client expectations\\nPresent solutions in intuitive and effective way to the audience\\nActively participate in all activities leading to career progression participating in sales pitches, training in house\\nresources, coaching staff on best practices, client relationship management etc.\\n\\nSkills & Qualifications:\\n5 to 9 years of experience of working on Data Science assignments\\nProgression from individual contributor to lead over the period of employment\\nKnowledge of data pre-processing steps uploading, creating master data set, extracting right data from external\\nsources, data quality checks and corrections and Database Management\\nGood grasp of Statistical / ML Algorithms ( KNN, Naive Bayes, SVM, Recommender systems, Random Forest, Decision Trees etc. )\\nExperience of implementation of two or more of Logistic Regression, Recommendation Engines, NLP/Text Analysis,\\nAnomaly Detection, Clustering, Random Forest etc. on a live project on Python\\nExposure to Deep Learning ( CNN, RNN, LSTM etc ) with experience in PoCs , projects, solutions\\nKnowledge of GAN (Generative Adversarial Networks)\\nComfortable with creating Visualizations on any one standard software\\nHigh learning orientation and openness to learn and implement solutions\\nExperience of working on large datasets. Knowledge of Spark or Hadoop is a plus\\nAbility to define solutions for vague problems\\nGood Project Management & Communication Skills both technical and non-technical audience.\\nTechnical Skills:\\nPython ( and python libraries like NumPy, SciPy, MatploitLib,Pandas, NLTK, Spacy ) ,\\nScikit Learn , Keras, Caffe, Tensorflow, CoreNLP/OpenNLP, OpenCV\\nBasic Database knowledge, SQL\\nEducation Type\\nB.E/B.Tech/BS-Computer Science\\nJob Type\\nFull Time-Regular\\nExperience Level\\nSenior Level\\nTotal Years of Exp\\n5-9',\n",
       " 'Employment type: Undefined term\\nFull-time/part-time position: Full time\\nJob Code USA/CA:\\nConsultant- Data analytics\\n\\n[[Pune]]\\n\\n\\nAt Konecranes, we believe that great customer experience is built on the people behind the Konecranes name – people committed to providing our customers with lifting equipment and services that lift their businesses. Everything we do, we do with passion and drive.\\nWe believe diversity drives business success and is the foundation for our growth. We welcome different backgrounds and skills that enrich our community and we promote a place where we can ALL be ourselves. This is what makes Konecranes a unique place to work.\\n\\nDesignation: Consultant – Data Analytics\\n\\nExperience: 1-3 years\\n\\nBase\\n\\nCompany Name: Konecranes and Demag Private Limited\\n\\nWebsite: http://www.konecranes.com\\n\\nJob description -\\nWhat we expect from you:\\nExcellent written and verbal communication in English.\\n1.5-3 Years of Production support and development experience in Business Intelligence and Analytics area (ETL / ELT).\\nStrong understanding of Databases (Microsoft SQL Server).\\nKnowledge on Data marts, Data vault, data loads (batch, incremental) and effective monitoring,\\nExperience on at least one end-to-end implementation, from data source system towards Business Intelligence and Analytics or Portals.\\nExperience with various optimizing techniques in improving the performance of the data loads and database.\\nKnowledge of Azure cloud-based data platforms and solutions.\\nGood to have Knowledge of DENODO data science tool.\\nKnowledge and understanding of ITIL processes and support activities.\\nMin 1-year experience on at least one support project.\\nExperience in handling and resolving Incidents based on priority and severity.\\nAzure certifications would be an added advantage\\nHands on knowledge Agile methodology & Devops way or working would be an added advantage\\n\\nYour responsibilities are:\\nHandling Service Requests and Incidents\\nResolving data load issues and be able to resolve them within limited time window.\\nAny adhoc request coming from other applications for monitoring / support in any environments.\\nProviding monthly report on Interfaces/system availability.\\nParticipate into Critical Incident resolution and communication process.\\nDevelop healthy professional customer relationship\\nAnalyze the repetitive Incidents and addressing the root causes in order to either reduce/ eliminate repetitive Incidents or enhance efficiency in handling those.\\nEnsure to fulfil the KPIs like SLA, TAT, Ageing, Quality Audits, etc. based on management’s expectations and guidance\\nAlign and realign actions based on customers’ feedbacks, inputs from management.\\nAssist peers, superiors, other IT staff members in day to day activities whenever appropriate.\\nDeliver any other tasks as per superior’s instructions and guidance\\nAwareness about ISO 14001, 45001 requirements’\\n\\nGeneral skills / requirements\\nCustomer service attitude\\nExcellent inter-personnel skills with a proven ability to work independently and in team environment as per situation\\nGood communication (verbal, written) and presentation skills, preferably exposed to interaction with global stakeholder\\nAnalytical and problem-solving mindset\\nKnowledge about ITIL and ITSM tool(s)\\nKonecranes, Inc. and its affiliates will not accept resumes from external recruiters or agencies without a Service Agreement and Agency Portal submission. Any resumes sent without a Service Agreement and Agency Portal submission with Konecranes, Inc. are void of any fees and free for internal use. Applicable Konecranes data protection obligations are the responsibility of the agency.\\nKonecranes is a world-leading group of Lifting Businesses™, serving a broad range of customers. We are truly a global company with 18,000 employees at 600 locations in 50 countries. For over 80 years, we have been dedicated to improving the efficiency and performance of businesses in all types of industries. We believe that sustainable growth is a result of a strong responsible performance. Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Other Protected Category.',\n",
       " 'Job Description\\nLooking for an experienced Data Scientist with hands-on experience in a variety of data analysis methods, ML, DL algorithms using Python.\\nExperience: 10+ years\\nLocation\\nPune/Bangalore(IND)\\nSan Jose/Aguora Hills(CA, USA)\\n\\nSend us your resume at careers@nutanxt.com',\n",
       " 'Location: Hyderabad\\n\\nJob Description:\\nTake responsibility for managing our master data set, developing reports, and troubleshooting data issues. To do well in this role, you need a very fine eye for detail, experience as a data analyst, and a deep understanding of the popular data analysis tools and databases.\\n\\nSpecific Responsibilities:\\nManaging master data, including creation, updates, and deletion;\\nHelping develop reports and analysis;\\nManaging and designing the reporting environment, including data sources, security, and metadata;\\nSupporting initiatives for data integrity and normalization;\\nAssessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems;\\nTroubleshooting the reporting database environment and reports;\\nTraining end-users on new reports and dashboards;\\nProviding technical expertise in data storage structures, data mining, and data cleansing.\\n\\nQualifications:\\nDegree in IT, Computer Science or Engineering, Statistics, Applied Mathematics or Business Analytics and related fields;\\n5 to 7 years of work experience in data analytics and data virtualization field;\\nStrong aptitude for numbers and comfortable handling large volume of data;\\nGood at programming skills in Python, R or SQL included machine learning;\\nExperience working with Elasticsearch and data virtualization tools like Kibana/Grafana;\\nEffective communication skills;\\nGood team player and adept at handling pressure',\n",
       " 'Job title\\n\\nSr NLP & Text Mining Data Scientist\\n\\nDepartment\\n\\nAnalytics & Data Science\\n\\nReport To\\nDeepthi Devarakonda / Simhan Ramakrishnan\\n\\nNo of yrs. of exp\\n\\n7+ years\\n\\nWork Location\\n\\nPune, MH, India\\n\\nNo of Positions\\n\\n1\\n\\nAssigned Recruiter\\n\\nTalent Partner\\n\\nVersion Control\\nVersion No.\\n\\nDate\\n\\nRemark\\n\\nUpdated by\\n\\n1.0\\n\\n5/4/2020\\n\\nInitial Version\\n\\nSR\\n\\nIt’s Time For A Change…\\nYour Future Evolves Here\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.\\nAre we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.\\n\\nPosition summary\\n\\nThe Sr. NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.\\nEssential functions\\n\\nThe Sr. NLP Text Mining Scientist / Engineer will have the opportunity to lead a team, shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.\\n7+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)\\nDevelop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs\\nGather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU\\nApply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms\\nOwn the Natural Language and Text Mining products — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services\\nWork closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals\\nProvide mentoring to other Data Scientist and Machine Learning Engineers\\nStrong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches\\nStrong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture\\nGood understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations\\nAdditional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics\\nExperience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala)\\nStrong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years\\nHands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)\\nThorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)\\nHands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 5+ years\\nUnderstanding business use cases and be able to translate them to team with a vision on how to implement\\nIdentify enhancements and build best practices that can help to improve the productivity of the team.\\n\\nNice to Have\\nMedical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)\\nLucene, Solr, Elastic Search experience\\nExperience with Kubernetes and dockers\\nExperience building REST API’s for AI work and knowledge of microservices architecture\\nParticipation in open source community projects\\n\\nAcademic Qualification:\\nMaster’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)\\nCompletion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics\\nA PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program\\nPublication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred',\n",
       " 'Job Description:\\n\\nRoles and Responsibilities :\\nWe are looking for a Natural Language Processing Engineer (Java, Python, OCR) to join our team\\nYou will be at interfacing with the latest research within NLP & Deep Learning.\\nDesigning experiments, testing hypotheses, and building models.\\nExpert programmer/engineer with Python or Java and has familiarity with OCR libraries.\\nExperience developing production ready solutions using agile methodology.\\nStrong Python developer with solid understanding of software design and architecture principles.\\nExperience in Python with frameworks: Flask, Numpy, pandas, nltk and scikit-learn\\nWorked with SQL and NoSQL databases and queues (Mongo, Kafka, Oracle DB)\\nExperience in building restful web-services and message oriented applications\\nIdeally used and built NLP and machine learning models\\nExperience with DevOps and/or MLOps\\nHardworking Individual with good analytical and technical skills.\\n\\n3.00-8.00 Years',\n",
       " \"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 7.5 million+ contracts worth more than $1 trillion, in 40+ languages and 90+ countries.\\n\\nWho we are: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination\\n\\nAbout the role :\\n\\nThe Principal Data Scientist is a detail oriented forward thinking individual who will utilize data mining, data analysis, machine learning and natural language processing to bring innovation and differentiated capabilities to the Icertis Contract Intelligence. You will be at ease with contemporary machine learning, natural language processing frameworks and quantitative approaches and will be able to critically evaluate and design, build, and support pipelines that can analyze contract document collections at scale. When no suitable approaches are available, is able to craft new and innovative machine learning and language processing solutions. Knowledge of enterprise level software architecture and components is a big plus though is not required. You will have strong verbal and written communication skills, be effective in interacting with technical and non-technical professionals, and be comfortable with team building and working in a team.\\n\\nThis opportunity is open for Icertis Everywhere - Full-time work from home and would not require relocation to Pune.\\nResponsibilities:\\nPartners with business stakeholders to translate business objectives into clearly defined analytical projects.\\nIdentify opportunities for text analytics and NLP to enhance the core product platform, select the best machine learning techniques to the specific business problem and then build the models that solve the problem.\\nOwn the end-end process, from recognizing the problem to implementing the solution.\\nDefine the variables and their inter-relationships and extract the data from our data repositories,leveraging infrastructure including Cloud computing solutions and relational database environments.\\nBuild predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.\\nSkills and Qualifications:\\n12 to 15 yrs' of experience.\\nAn advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.\\nExperience with text mining, parsing, and classification using state-of-the-art techniques.\\nExperience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.\\nAbility to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.\\nExperience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.\\nExcellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.\\nAbility to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.\\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\\n\\nIcertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.\\n\\nIf you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com\\nBy submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)\",\n",
       " 'Software engineer with experience in NLP and Machine Learning. You will join our team of NLP, ML experts to work on our cutting edge AI NLP Product, building deep learning, NLP modules for various features of the product. You will also work closely with the product deployment team and help build custom capabilities relevant to different business/industry functions.\\nTo succeed in this role, you should possess outstanding skills in deep learning techniques, Sequence to sequence, LSTMs, RNNs, CNNs, machine learning methods, text representation techniques, language models etc.\\nWhat we look for: -\\nAdvanced proficiency in the following:\\n1. Python\\n2. Natural Language Processing\\n3. Deep Learning\\n4. Machine Learning\\n5. Numpy, Scipy, Pandas\\n6. Data Science\\n7. MongoDB\\n8. NoSQL\\n9. SQL\\n10. Big Data\\nExperience 0-4 years (yes, freshers w/ the right aptitude and logical thinking are welcome!)\\nSelf driven individual with a drive to learn the latest in the technology.\\nExceptional team player.\\nAbility to clearly communicate thoughts, and collaborate on Concepts and Ideas for the product.\\nGood understanding and knowledge of enterprise PDLC.\\nResearch mindset with the courage to try things and learn from them.',\n",
       " 'Job Description\\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 506,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com\\n\\nProject Role :Application Developer\\nProject Role Description :Design, build and configure applications to meet business process and application requirements.\\nManagement Level :9\\nWork Experience :6-8 years\\nWork location :Pune\\nMust Have Skills :Data Science,No Technology Specialization\\nGood To Have Skills :\\nJob Requirements :\\n\\nKey Responsibilities : A : Data Scientists to support the analysis of the data and the preparation of additional big data and data analysis technologies within the CRCO area of CS in Zurich, like data modelling, wrangling, pipelines implementation or building machine learning models on the Palantir Foundry stack B : to identify the best methodologies in analytics/Machine Learning for the specific problem to solve C : Ability to develop reliable, autonomous and scalable data pipelines\\n\\nTechnical Experience : A :Review and IT testing of methodology to match clients via name matching B : At least 5 years of experience in Data Analytics and related tools eg Python, R, Java/Scala, Spark and SQL, ideally combined with a technology background in big-data, non-relational data bases and expertise with Bash C : Experience working in agile environments D : Familiarity with assembling and analyzing data sets from disparate sources, applying quantitative methodologies, computational frameworks and systems\\n\\nProfessional Attributes : A : Excellent Communication Skill\\n\\nEducational Qualification : A : Minimum of 15 years full time education\\n\\nQualifications\\n15 years of full time education',\n",
       " 'Job Location – Pune – India\\nRequired experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial\\nInnoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.\\nOur products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.\\nWe automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.\\nYou are the right person in our team if you can:\\nUnderstand Biological data, molecular biology, computational biology, proteomics and genomics data\\nShould have a very fair understanding of Adverse Events and Toxicity\\nApplication of Machine Learning or Deep Learning experience in biological data\\nSound understanding of uses of NLP in biological data\\nHands on experience of Applied Statistics in Life Science data\\nUnderstand R, Python, Weka, Spark and latest technologies in data sciences\\nKnowledge of Proteins, Drugs, Clinical trials and Literatures databases is required\\nWe need you to have:\\nBTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy\\nTo excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:\\nGood presentation and communication skills\\nStrong leadership qualities. Ready to own the work\\nExperience in CRO or Pharma is desirable\\nWorking experience on Adverse Events and Toxicity module\\nGood analytical and reasoning skills\\nTrack record of managing small team is an advantage\\nUnderstanding of Biological data and databases is a plus\\nKnowledge of databases like Proteins, Drugs and Literatures databases is desirable\\nResearch paper publications in good journals\\nInnoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.',\n",
       " \"About us:\\nClimate Connect Ltd. applies Artificial Intelligence (AI) forecasting techniques such as Neural Networks, Support Vector Machines and Gradient Boosting, to a range of opportunities within the evolving energy ecosystem. Climate Connect was founded in 2010 by Cambridge University alumni, after rapid growth the young company now has a team of 40+ people spread across 3 main locations: Delhi (India), Pune (India), Amsterdam (NL). We also run a carbon market intelligence platform, CaliforniaCarbon.info, and so have strong business interests and are firmly embedded in the energy networks on the US West Coast.\\nWe build forecasting and optimisation software for renewable energy and storage technologies to enable asset owners to see greater returns from their investments. This may be achieved through smart analytics to improve operational efficiency; dynamic forecast to reduce the costs of variable production; or when aligned with our proprietary price forecasting, increase revenue by selling directly though to markets. As such, we recruit across a range of different skill sets: engineers, software developers, pure mathematicians, meteorologists, economists, and those with a commercial understanding of energy markets.\\nIn sum, we build software that removes middle-men within the current energy paradigm, and returns value to the owners of generative and distributive capacity. Across almost every sector: transport, housing, even food, AI is having a revolutionary and localising effect, Climate Connect is at the epicentre of this transformation in energy.\\nOtherwise, it is important for candidates to understand Climate Connect’s working environment. The vast majority of the company’s team is under 30, we have 6 different nationalities, and we have no time for ‘corporate culture’. Our philosophy to working hours and locations is entirely output focused, we allow our team to function to best suit their productivity be it working from home, at night, or on an impromptu hiking trip to the Himalayas! Team members often see business meetings spread over India, or indeed America, as opportunities to mix work and travel to give the richest working experience possible.\\nThe Role:\\nClimate Connect is looking for an Energy Machine Learning Engineer to assist in developing forecasting models for energy generation, load, and market prices. The Ideal candidate will have experience in developing mathematical algorithms and a broad knowledge of statistics, machine learning, optimization, and financial mathematics. Strong programming skills round out the ideal candidate's profile. The Machine Learning Engineer will be an integral part of our Climate Connect team, therefore responsible for:\\nDeveloping and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.\\nDeveloping and testing algorithms using our price forecasts, and customers' energy portfolio.\\nLeading software engineering team in deploying the developed models tailored to specific customer needs.\\nParticipating in the software development process, testing, and debugging required to support the deployed models.\\nDesired Skills:\\nAdvanced knowledge of Python.\\nExperience in working with libraries like Numpy, Pandas, sk-learn, tensorflow, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.\\nKnowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.\\nExperience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.\\nComfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.\\nComfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.\\nDemonstrate ability to transform theoretical knowledge to practical, real-world situations.\\nBe results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.\\nProven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.\\nExcellent English communication skills; the ability to convey your message to team members and other stakeholders\\nMust be willing to work in a very flexible start-up environment.\\nGood to have working knowledge in PHP and other frontend technologies like Angular.\\nGood to have knowledge of backend technologies Message Queues, IPC.\\nGood to have knowledge of working with cloud providers like AWS and DigitalOcean.\\nCandidates who do not possess above skills in full time roles, but did internships and voluntary work to learn the skills, will be considered.\\nQualification:\\nBS or MS degree in Computer Science, Engineering, Mathematics, Physics, Economics or other quantitative discipline.\\nExperience:\\n0 to 3 years.\\nLocation:\\nPune, India\\nRemuneration:\\nCompetitive\\nApplication:\\nPlease send your CV (no longer than two pages) and cover letter to hr@climate-connect.com.\",\n",
       " 'We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\\n\\nResponsibilities:\\nDesigning and deploying deep learning algorithms and predictive models\\nDevelop custom data models and algorithms to apply to data sets\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\\nDevelop processes and tools to monitor and analyze model performance and data accuracy\\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\\n\\nQualifications:\\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\\nAbility to drive a project and work both independently and in a team',\n",
       " 'Job Description\\nLooking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data science techniques, doing statistical analysis, text mining and building high quality prediction systems integrated with our products.\\nStrong Experience on : R , Python, AIML, Text Analystics, NLP.\\nQualification : Statistics / Mathematics\\nResponsibilities\\nAnalyze data using state-of-the-art methods\\nSelecting features, building and optimizing classifiers using machine learning techniques\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating automated anomaly detection systems and constant tracking of its performance\\nSkills and Qualifications\\nBachelor’s Degree OR Post Graduate degree in Statistics , Operations Research, Economics, Mathematics , Computer Science.\\n4+ years of experience in machine learning techniques and algorithms.\\nExcellent understanding of algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\n3+ years of experience with common data science toolkits, such as R and Python . Excellence in at least one of these is highly desirable\\nExcellent understanding of neural networks, decision systems, and experience in text mining is a big plus.\\nVery good applied statistics skills, such as distributions, statistical testing, regression, etc.\\nExperience with data visualization tools such as Tableau would be desirable.\\nAbility to learn and build competencies in new tools and statistical techniques whenever required\\nAbility to explain and defend his/her ideas and analysis, while still able to understand the merits of others’ opinions.\\nStrong analytical and problem-solving skills\\nExcellent verbal & written communication skills\\nHighly motivated, organized, proactive self-starter and a team player.\\nData-oriented personality\\nAll Locations:\\nIND-Pune-Old Mumbai Pune Hwy',\n",
       " 'Job Brief\\nML Engineer\\nMandatory Skill - Python, Machine Learning, Data Science and Analystics\\nGood to have skills - AWS or Azure OR GCP, Kafka and Spark\\nExperiece Required - 3 to 8 Years',\n",
       " 'Job Location\\nMountain View, California or Pune, India\\nRole and Responsibilities\\nEngineering core machine learning capabilities in our IoT platform by building tools and high-performance infrastructure for running ML models at the edge.\\nCreating supervised and semi-supervised ML models for the platform.\\nCore Qualifications\\nCandidates must meet ALL of the following qualifications.\\nExperience in Agile software development with strong programming experience in C++ or Python.\\nExperience in building and using high-speed data processing infrastructure and tools.\\nHave used or developed high performance C++ packages (e.g. LAPACK, BLAS, YOLO etc.)\\nSome experience with real-time stream processing data systems.\\nTraining in data mining or statistics, enough to understand the context of developing software to be used by data scientists.\\nAlgorithm experience in the families of predictive algorithms (regression, neural nets, decision trees) and clustering algorithms (k-means or other).\\nBonus Qualifications\\nAny of the following extra qualifications will make a candidate more competitive.\\nStrong experience with C++ development and high-performance computing.\\nCython programming or written python wrapper for C++.\\nExperience developing Machine Learning software infrastructure, algorithms and libraries.\\nTraining or experience in Deep Learning, such as Keras, TensorFlow, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network.\\nExperience with PMML or PFA or TFR is of interest (see www.DMG.org).\\nHow To Apply\\nTo apply, submit resume and cover letter to HR at jobs@foghorn.io.\\nIndicate how you meet core and bonus qualifications including two to four detailed paragraphs of three data mining projects you have deployed.',\n",
       " 'Design right ML & AI algorithms and manage the solution implementation end-to-end\\nManage client engagements and ensure project delivery as per client expectations\\nPresent solutions in intuitive and effective way to the audience\\nActively participate in all activities leading to career progression participating in sales pitches, training in house\\nresources, coaching staff on best practices, client relationship management etc.\\n\\nSkills & Qualifications:\\n5 to 9 years of experience of working on Data Science assignments\\nProgression from individual contributor to lead over the period of employment\\nKnowledge of data pre-processing steps uploading, creating master data set, extracting right data from external\\nsources, data quality checks and corrections and Database Management\\nGood grasp of Statistical / ML Algorithms ( KNN, Naive Bayes, SVM, Recommender systems, Random Forest, Decision Trees etc. )\\nExperience of implementation of two or more of Logistic Regression, Recommendation Engines, NLP/Text Analysis,\\nAnomaly Detection, Clustering, Random Forest etc. on a live project on Python\\nExposure to Deep Learning ( CNN, RNN, LSTM etc ) with experience in PoCs , projects, solutions\\nKnowledge of GAN (Generative Adversarial Networks)\\nComfortable with creating Visualizations on any one standard software\\nHigh learning orientation and openness to learn and implement solutions\\nExperience of working on large datasets. Knowledge of Spark or Hadoop is a plus\\nAbility to define solutions for vague problems\\nGood Project Management & Communication Skills both technical and non-technical audience.\\nTechnical Skills:\\nPython ( and python libraries like NumPy, SciPy, MatploitLib,Pandas, NLTK, Spacy ) ,\\nScikit Learn , Keras, Caffe, Tensorflow, CoreNLP/OpenNLP, OpenCV\\nBasic Database knowledge, SQL\\nEducation Type\\nB.E/B.Tech/BS-Computer Science\\nJob Type\\nFull Time-Regular\\nExperience Level\\nSenior Level\\nTotal Years of Exp\\n5-9']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Titles']=titles\n",
    "df['Companies']=companies\n",
    "df['Locations']=locations\n",
    "df['Links']=links\n",
    "df['Ratings']=ratings\n",
    "df['Salaries']=salaries\n",
    "df['Descriptions']=descriptions\n",
    "df['Urgent Hiring']=Hir\n",
    "df[\"time\"]=time\n",
    "df[\"date\"]=dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Links</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Salaries</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Urgent Hiring</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=e8478862cdc148...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Title:Data Scientist\\nLocation: Pune\\nProj...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:24</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science part time job/internship at Pune</td>\n",
       "      <td>Exa Mobility India Private Limited</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=1cc82c46271c86...</td>\n",
       "      <td>None</td>\n",
       "      <td>₹10,000 - ₹20,000 a month</td>\n",
       "      <td>About the company:\\nWe are a research and prod...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:25</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Vertscend Automation Pvt Ltd</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/company/vertscend-automa...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>₹6,00,000 - ₹9,00,000 a year</td>\n",
       "      <td>Responsibilities and Duties\\nKnowledge of Deep...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:25</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>3RI TECHNOLOGIES</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=23d8604e5369a8...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>No of Positions – 2\\n\\nExperience – Fresher\\n\\...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:25</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>Michelin</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=607eba399767a6...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Manager - Data Scientist\\n- - - - - - - - - - ...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:26</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Qualys</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=31f41e374f5371...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>None</td>\n",
       "      <td>We are looking for a Lead Data Scientist who w...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:49</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Wolters Kluwer</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=1965194f7b81d3...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Description\\nLooking for a data scientist ...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:50</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ML Engineer_Calsoft</td>\n",
       "      <td>Calsoft</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=c30a0ec690d465...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Brief\\nML Engineer\\nMandatory Skill - Pyth...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:50</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Foghorn Systems</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=6e12a46832aa73...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Location\\nMountain View, California or Pun...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:50</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Machine Learning Developer</td>\n",
       "      <td>QuEST Global Engineering</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>https://in.indeed.com/rc/clk?jk=54528c691a50ac...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>None</td>\n",
       "      <td>Design right ML &amp; AI algorithms and manage the...</td>\n",
       "      <td>none</td>\n",
       "      <td>19:05:50</td>\n",
       "      <td>20:12:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Titles  \\\n",
       "0                                   Data Scientist   \n",
       "1    Data Science part time job/internship at Pune   \n",
       "2                            Senior Data Scientist   \n",
       "3                                     Data Science   \n",
       "4                         Manager - Data Scientist   \n",
       "..                                             ...   \n",
       "100                            Lead Data Scientist   \n",
       "101                          Senior Data Scientist   \n",
       "102                            ML Engineer_Calsoft   \n",
       "103                      Machine Learning Engineer   \n",
       "104                     Machine Learning Developer   \n",
       "\n",
       "                              Companies          Locations  \\\n",
       "0                              Barclays  Pune, Maharashtra   \n",
       "1    Exa Mobility India Private Limited  Pune, Maharashtra   \n",
       "2          Vertscend Automation Pvt Ltd  Pune, Maharashtra   \n",
       "3                      3RI TECHNOLOGIES  Pune, Maharashtra   \n",
       "4                              Michelin  Pune, Maharashtra   \n",
       "..                                  ...                ...   \n",
       "100                              Qualys  Pune, Maharashtra   \n",
       "101                      Wolters Kluwer  Pune, Maharashtra   \n",
       "102                             Calsoft  Pune, Maharashtra   \n",
       "103                     Foghorn Systems  Pune, Maharashtra   \n",
       "104            QuEST Global Engineering  Pune, Maharashtra   \n",
       "\n",
       "                                                 Links Ratings  \\\n",
       "0    https://in.indeed.com/rc/clk?jk=e8478862cdc148...     3.9   \n",
       "1    https://in.indeed.com/rc/clk?jk=1cc82c46271c86...    None   \n",
       "2    https://in.indeed.com/company/vertscend-automa...     4.0   \n",
       "3    https://in.indeed.com/rc/clk?jk=23d8604e5369a8...     5.0   \n",
       "4    https://in.indeed.com/rc/clk?jk=607eba399767a6...     4.0   \n",
       "..                                                 ...     ...   \n",
       "100  https://in.indeed.com/rc/clk?jk=31f41e374f5371...     3.7   \n",
       "101  https://in.indeed.com/rc/clk?jk=1965194f7b81d3...     3.6   \n",
       "102  https://in.indeed.com/rc/clk?jk=c30a0ec690d465...     3.4   \n",
       "103  https://in.indeed.com/rc/clk?jk=6e12a46832aa73...    None   \n",
       "104  https://in.indeed.com/rc/clk?jk=54528c691a50ac...     3.3   \n",
       "\n",
       "                         Salaries  \\\n",
       "0                            None   \n",
       "1       ₹10,000 - ₹20,000 a month   \n",
       "2    ₹6,00,000 - ₹9,00,000 a year   \n",
       "3                            None   \n",
       "4                            None   \n",
       "..                            ...   \n",
       "100                          None   \n",
       "101                          None   \n",
       "102                          None   \n",
       "103                          None   \n",
       "104                          None   \n",
       "\n",
       "                                          Descriptions Urgent Hiring  \\\n",
       "0    Job Title:Data Scientist\\nLocation: Pune\\nProj...          none   \n",
       "1    About the company:\\nWe are a research and prod...          none   \n",
       "2    Responsibilities and Duties\\nKnowledge of Deep...          none   \n",
       "3    No of Positions – 2\\n\\nExperience – Fresher\\n\\...          none   \n",
       "4    Manager - Data Scientist\\n- - - - - - - - - - ...          none   \n",
       "..                                                 ...           ...   \n",
       "100  We are looking for a Lead Data Scientist who w...          none   \n",
       "101  Job Description\\nLooking for a data scientist ...          none   \n",
       "102  Job Brief\\nML Engineer\\nMandatory Skill - Pyth...          none   \n",
       "103  Job Location\\nMountain View, California or Pun...          none   \n",
       "104  Design right ML & AI algorithms and manage the...          none   \n",
       "\n",
       "         time      date  \n",
       "0    19:05:24  20:12:27  \n",
       "1    19:05:25  20:12:27  \n",
       "2    19:05:25  20:12:27  \n",
       "3    19:05:25  20:12:27  \n",
       "4    19:05:26  20:12:27  \n",
       "..        ...       ...  \n",
       "100  19:05:49  20:12:27  \n",
       "101  19:05:50  20:12:27  \n",
       "102  19:05:50  20:12:27  \n",
       "103  19:05:50  20:12:27  \n",
       "104  19:05:50  20:12:27  \n",
       "\n",
       "[105 rows x 10 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('indeed data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
